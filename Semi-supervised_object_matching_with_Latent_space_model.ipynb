{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2399fa25d70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ライブラリの読み込み\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot  as plt\n",
    "import numpy.matlib\n",
    "import scipy.linalg\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizers\n",
    "from scipy.stats import norm\n",
    "from numpy.random import *\n",
    "from scipy import optimize\n",
    "\n",
    "np.random.seed(9837)\n",
    "torch.manual_seed(9837)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多項分布の乱数を生成する関数\n",
    "def rmnom(pr, n, k, pattern):\n",
    "    if pattern==1:\n",
    "        z_id = np.array(np.argmax(np.cumsum(pr, axis=1) >= np.random.uniform(0, 1, n)[:, np.newaxis], axis=1), dtype=\"int\")\n",
    "        Z = np.diag(np.repeat(1, k))[z_id, ]\n",
    "        return z_id, Z\n",
    "    z_id = np.array(np.argmax((np.cumsum(pr, axis=1) >= np.random.uniform(0, 1, n)[:, np.newaxis]), axis=1), dtype=\"int\")\n",
    "    return z_id\n",
    "\n",
    "# ディリクリ分布の乱数を生成する関数\n",
    "def Dirichlet(alpha, n):\n",
    "    x = torch.Tensor(np.random.dirichlet(alpha, n))\n",
    "    return x\n",
    "\n",
    "# 切断ポアソン分布の乱数を生成する関数\n",
    "def rtpois(mu, a, b, n, flag=0):\n",
    "    FA = scipy.stats.poisson.cdf(a, mu)\n",
    "    FB = scipy.stats.poisson.cdf(b, mu)\n",
    "    x = np.array(scipy.stats.poisson.ppf(np.random.uniform(0, 1, n)*(FB-FA)+FA, mu), dtype=\"int\")\n",
    "    if flag==1:\n",
    "        x = torch.Tensor(x)\n",
    "    return x\n",
    "\n",
    "# 多変量正規分布の乱数を生成する関数\n",
    "def Multivariate_normal(mu, Cov, n):\n",
    "    x = torch.Tensor(np.random.multivariate_normal(mu, Cov, n).reshape(-1))\n",
    "    return x\n",
    "\n",
    "# 正規分布の乱数を生成する関数\n",
    "def Normal(mu, Sigma):\n",
    "    x = torch.Tensor(np.random.normal(mu, Sigma))\n",
    "    return x\n",
    "\n",
    "# 逆ウィシャート分布の乱数を生成する関数\n",
    "def Inv_Wishart(Sn, IW_R):\n",
    "    x = torch.Tensor(scipy.stats.invwishart.rvs(Sn, IW_R, 1))\n",
    "    return x\n",
    "\n",
    "# 切断正規分布の乱数を生成する関数\n",
    "def rtnorm(mu, sigma, a, b, n, flag=1):\n",
    "    FA = norm.cdf(a, mu, sigma)\n",
    "    FB = norm.cdf(b, mu, sigma)\n",
    "    if flag==1:\n",
    "        y = torch.Tensor(norm.ppf(np.random.uniform(0, 1, n)*(FB-FA)+FA, mu, sigma))\n",
    "    else:\n",
    "        y = norm.ppf(np.random.uniform(0, 1, n)*(FB-FA)+FA, mu, sigma)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入力データの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの生成\n",
    "# データの定義\n",
    "modes = 3   #モード数\n",
    "r = 1   # ノイズ語のトピック数\n",
    "d1 = 4000; d2 = 4000\n",
    "seg1 = 1000; seg2 = 250; seg3 = 250\n",
    "w1 = 2000; w2 = 500\n",
    "d = d1 + d2\n",
    "seg = seg1 + seg2 + seg3 \n",
    "w = w1 + w2\n",
    "\n",
    "# レコード数を定義\n",
    "max_seg = 6\n",
    "m1 = rtpois(2.75, 1, max_seg, d1)\n",
    "m2 = rtpois(2.75, 1, max_seg, d2)\n",
    "Lambda1 = np.random.gamma(40.0, 1/0.2, w)\n",
    "Lambda2 = np.random.gamma(60.0, 1/0.25, d1)\n",
    "Lambda3 = np.random.gamma(60.0, 1/0.2, d2)\n",
    "f1 = np.random.poisson(Lambda1, w)\n",
    "pt1 = np.random.poisson(Lambda2, d1)\n",
    "pt2 = np.random.poisson(Lambda3, d2)\n",
    "F = np.sum(f1)\n",
    "N1 = np.sum(pt1)\n",
    "N2 = np.sum(pt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語の割当インデックス\n",
    "index_w1 = np.arange(w1)\n",
    "index_w2 = np.arange(w1, w)\n",
    "type_id = np.repeat(0, w)\n",
    "type_id[index_w2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDとインデックスを作成\n",
    "# IDの定義\n",
    "wd1 = np.repeat(np.arange(w), f1)\n",
    "d_id1 = np.repeat(np.arange(d1), pt1)\n",
    "d_id2 = np.repeat(np.arange(d2), pt2)\n",
    "\n",
    "# インデックスの定義\n",
    "w_list1 = [i for i in range(w)]\n",
    "d_list1 = [i for i in range(d1)]\n",
    "d_list2 = [i for i in range(d2)] \n",
    "for i in range(w):\n",
    "    w_list1[i] = np.array(np.where(wd1==i)[0], dtype=\"int\")\n",
    "for i in range(d1):\n",
    "    d_list1[i] = np.array(np.where(d_id1==i)[0], dtype=\"int\")\n",
    "for i in range(d2):\n",
    "    d_list2[i] = np.array(np.where(d_id2==i)[0], dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 共起wordの生成\n",
    "# 多項分布からtopicを生成\n",
    "topic = 30\n",
    "theta_topic = np.random.dirichlet(np.repeat(0.2, topic), w)\n",
    "phi_word = np.random.dirichlet(np.repeat(0.2, w), topic)\n",
    "z = rmnom(theta_topic[wd1, ], F, topic, 0)\n",
    "\n",
    "# トピックからwordを生成\n",
    "# データの生成\n",
    "wd2 = np.repeat(0, F)\n",
    "for i in range(w):\n",
    "    index = w_list1[i]\n",
    "    words = rmnom(phi_word[z[index], ], f1[i], w, 0)\n",
    "    if np.sum(words==i)==0:\n",
    "        wd2[index] = words\n",
    "        next\n",
    "    while True:\n",
    "        index_dup = np.where(words==i)[0]\n",
    "        words[index_dup] = rmnom(phi_word[z[index][index_dup], ], index_dup.shape[0], w, 0)\n",
    "        if np.sum(words==i)==0:\n",
    "            wd2[index] = words\n",
    "            break\n",
    "\n",
    "# インデックスの定義\n",
    "w_list2 = [i for i in range(w)]\n",
    "f2 = np.repeat(0, w)\n",
    "for i in range(w):\n",
    "    w_list2[i] = np.array(np.where(wd2==i)[0], dtype=\"int\")\n",
    "    f2[i] = w_list2[i].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文書segmentの生成\n",
    "# パラメータを定義\n",
    "theta_topic1 = np.random.dirichlet(np.repeat(0.2, topic), d1)\n",
    "theta_topic2 = np.random.dirichlet(np.repeat(0.2, topic), d2)\n",
    "phi_segment1 = np.zeros((topic, seg)); phi_segment2 = np.zeros((topic, seg))\n",
    "phi_segment1[:, np.arange(seg1+seg2)] = np.random.dirichlet(np.repeat(0.5, seg1+seg2), topic)\n",
    "phi_segment2[:, np.append(np.arange(seg1), np.arange(seg1+seg2, seg))] = np.random.dirichlet(np.repeat(0.5, seg1+seg3), topic)\n",
    "\n",
    "# 多項分布からtopicとsegmentを生成\n",
    "# データの格納用配列\n",
    "z1 = np.full((d1, max_seg), topic)\n",
    "seg_dt1 = np.full((d1, max_seg), seg+r)\n",
    "\n",
    "for i in range(d1):\n",
    "    # topicを生成\n",
    "    while True:\n",
    "        z_vec = np.argmax(np.random.multinomial(1, theta_topic1[i, ], m1[i]), axis=1)\n",
    "        if m1[i]==np.unique(z_vec).shape[0]:\n",
    "            break\n",
    "    z1[i, np.arange(m1[i])] = z_vec\n",
    "\n",
    "    # segmentを生成\n",
    "    while True:\n",
    "        if m1[i] > 1:\n",
    "            seg_vec = rmnom(phi_segment1[z_vec, ], m1[i], seg, 0)\n",
    "        else:\n",
    "            seg_vec = np.argmax(np.random.multinomial(1, phi_segment1[z_vec, ].reshape(-1), m1[i]))\n",
    "        if m1[i]==np.unique(seg_vec).shape[0]:\n",
    "            break\n",
    "    seg_dt1[i, np.arange(m1[i])] = seg_vec\n",
    "     \n",
    "# データの格納用配列    \n",
    "z2 = np.full((d2, max_seg), topic)\n",
    "seg_dt2 = np.full((d2, max_seg), seg+r)\n",
    "\n",
    "for i in range(d2):\n",
    "    # topicを生成\n",
    "    while True:\n",
    "        z_vec = np.argmax(np.random.multinomial(1, theta_topic2[i, ], m2[i]), axis=1)\n",
    "        if m2[i]==np.unique(z_vec).shape[0]:\n",
    "            break\n",
    "    z2[i, np.arange(m2[i])] = z_vec\n",
    "\n",
    "    # segmentを生成\n",
    "    while True:\n",
    "        if m2[i] > 1:\n",
    "            seg_vec = rmnom(phi_segment2[z_vec, ], m2[i], seg, 0)\n",
    "        else:\n",
    "            seg_vec = np.argmax(np.random.multinomial(1, phi_segment2[z_vec, ].reshape(-1), m2[i]))\n",
    "        if m2[i]==np.unique(seg_vec).shape[0]:\n",
    "            break\n",
    "    seg_dt2[i, np.arange(m2[i])] = seg_vec\n",
    "    \n",
    "# ノイズ語のトピックを結合\n",
    "joint_dt1 = np.hstack((np.full((d1, r), np.arange(seg, seg+r)), seg_dt1))\n",
    "joint_dt2 = np.hstack((np.full((d2, r), np.arange(seg, seg+r)), seg_dt2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語と対応するsegmentの生成\n",
    "# segment割当確率を定義\n",
    "eta1 = np.repeat(15.0/r, r); eta2 = 50.0\n",
    "pi1 = np.zeros((d1, max_seg + r))\n",
    "pi2 = np.zeros((d2, max_seg + r))\n",
    "for i in range(d1):\n",
    "    pi1[i, np.arange(r + m1[i])] = np.random.dirichlet(np.append(eta1, np.repeat(eta2/m1[i], m1[i])))\n",
    "for i in range(d2):\n",
    "    pi2[i, np.arange(r + m2[i])] = np.random.dirichlet(np.append(eta1, np.repeat(eta2/m2[i], m2[i])))\n",
    "pit1 = pi1.copy()\n",
    "pit2 = pi2.copy()\n",
    "    \n",
    "# 多項分布からsegmentを生成\n",
    "seg_id1 = np.max(joint_dt1[d_id1, ] * rmnom(pi1[d_id1, ], N1, max_seg + r, 1)[1], axis=1)\n",
    "seg_id2 = np.max(joint_dt2[d_id2, ] * rmnom(pi2[d_id2, ], N2, max_seg + r, 1)[1], axis=1)\n",
    "joint_long1 = joint_dt1[d_id1, ]\n",
    "joint_long2 = joint_dt2[d_id2, ]\n",
    "\n",
    "# インデックスを定義\n",
    "seg_record1 = [j for j in range(max_seg)]\n",
    "seg_record2 = [j for j in range(max_seg)]\n",
    "seg_list1 = [i for i in range(seg+r)]\n",
    "seg_list2 = [i for i in range(seg+r)]\n",
    "seg_target1 = [i for i in range(seg+r)]\n",
    "seg_target2 = [i for i in range(seg+r)]\n",
    "for j in range(max_seg):\n",
    "    seg_record1[j] = np.array(np.where(joint_long1[:, r+j] < seg)[0], dtype=\"int\")\n",
    "    seg_record2[j] = np.array(np.where(joint_long2[:, r+j] < seg)[0], dtype=\"int\")\n",
    "for i in range(seg+r):\n",
    "    if i < seg:\n",
    "        seg_list1[i] = np.array(np.where(joint_long1[:, r:]==i)[0], dtype=\"int\")\n",
    "        seg_list2[i] = np.array(np.where(joint_long2[:, r:]==i)[0], dtype=\"int\")\n",
    "    else:\n",
    "        seg_list1[i] = np.arange(N1)\n",
    "        seg_list2[i] = np.arange(N2)\n",
    "for i in range(seg+r):\n",
    "    seg_target1[i] = np.array(np.where(seg_id1==i)[0], dtype=\"int\")\n",
    "    seg_target2[i] = np.array(np.where(seg_id2==i)[0], dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7cd524b27437>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mindex2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseg_target2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mseg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mword_id1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrmnom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphi_word1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mword_id2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrmnom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphi_word1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# パラメータを定義\n",
    "theta_topic = np.random.dirichlet(np.repeat(0.2, topic), seg + r)\n",
    "phi_word1 = np.zeros((topic, w)); phi_word2 = np.zeros((topic, w))\n",
    "phi_word1[:, index_w1] = np.random.dirichlet(np.repeat(0.25, w1), topic)\n",
    "phi_word2[:, index_w2] = np.random.dirichlet(np.repeat(0.5, w2), topic)\n",
    "\n",
    "# 多項分布からトピックを生成\n",
    "z1 = rmnom(theta_topic[seg_id1, ], N1, topic, 0)\n",
    "z2 = rmnom(theta_topic[seg_id2, ], N2, topic, 0)\n",
    "\n",
    "# トピックから補助データの単語を生成\n",
    "word_id1 = np.repeat(0, N1)\n",
    "word_id2 = np.repeat(0, N2)\n",
    "for i in range(seg+r):\n",
    "    index1 = seg_target1[i]\n",
    "    index2 = seg_target2[i]\n",
    "    if i < seg:\n",
    "        word_id1[index1] = rmnom(phi_word1[z1[index1], ], index1.shape[0], w, 0)\n",
    "        word_id2[index2] = rmnom(phi_word1[z2[index2], ], index2.shape[0], w, 0)\n",
    "    else:\n",
    "        word_id1[index1] = rmnom(phi_word2[z1[index1], ], index1.shape[0], w, 0)\n",
    "        word_id2[index2] = rmnom(phi_word2[z2[index2], ], index2.shape[0], w, 0)\n",
    "        \n",
    "# インデックスを定義\n",
    "word_list1 = [i for i in range(w)]\n",
    "word_list2 = [i for i in range(w)]\n",
    "word_n1 = np.repeat(0, w)\n",
    "word_n2 = np.repeat(0, w)\n",
    "for i in range(w):\n",
    "    word_list1[i] = np.array(np.where(word_id1==i)[0], dtype=\"int\")\n",
    "    word_list2[i] = np.array(np.where(word_id2==i)[0], dtype=\"int\")\n",
    "    word_n1[i] = word_list1[i].shape[0]\n",
    "    word_n2[i] = word_list2[i].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 応答変数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# パラメータの事前分布を定義\n",
    "# 潜在次元数を選択\n",
    "k1 = 12\n",
    "k2 = 7\n",
    "k = k1 + k2\n",
    "seg_k1 = 7\n",
    "seg_k2 = 5\n",
    "noise_k1 = 4\n",
    "noise_k2 = 3\n",
    "k_vec = np.repeat(1.0, k)\n",
    "\n",
    "# 潜在因子のブロックを定義\n",
    "seg_index = np.append(np.arange(seg_k1), np.arange(k1, k1+seg_k2))\n",
    "noise_index = np.append(np.arange(seg_k1, k1), np.arange(k1+seg_k2, k))\n",
    "seg_block1 = np.repeat(seg_index, seg_k1+seg_k2).reshape(seg_k1+seg_k2, seg_k1+seg_k2)\n",
    "seg_block2 = np.repeat(seg_index, seg_k1+seg_k2).reshape(seg_k1+seg_k2, seg_k1+seg_k2, order=\"F\")\n",
    "noise_block1 = np.repeat(noise_index, noise_k1+noise_k2).reshape(noise_k1+noise_k2, noise_k1+noise_k2)\n",
    "noise_block2 = np.repeat(noise_index, noise_k1+noise_k2).reshape(noise_k1+noise_k2, noise_k1+noise_k2, order=\"F\")\n",
    "\n",
    "# 期待値の事前分布を定義\n",
    "types = 2\n",
    "alpha1 = np.repeat(0.0, k1); alpha2 = np.repeat(0.0, k2)\n",
    "alpha_block = np.zeros((k, k))\n",
    "alpha_block[seg_block1, seg_block2] = 0.0\n",
    "alpha_block[noise_block1, noise_block2] = 0.0\n",
    "\n",
    "# バイアス項の事前分布を定義\n",
    "Sigma = 1.0 \n",
    "tau_a = np.array([0.5])\n",
    "tau_b = np.array([0.7])\n",
    "tau_c = np.array([0.7])\n",
    "taut_a = tau_a.copy()\n",
    "taut_b = tau_b.copy()\n",
    "taut_c = tau_c.copy()\n",
    "\n",
    "# 事前分布の共分散を定義\n",
    "Cov_u1 = np.zeros((k1, k1, types)); Cov_u2 = np.zeros((k2, k2, types))\n",
    "Cov_g1 = np.zeros((k1, k1, types)); Cov_g2 = np.zeros((k2, k2, types))\n",
    "Cov_u1[:, :, 0] = np.diag(np.append(np.repeat(0.6, seg_k1), np.repeat(0.01, noise_k1)))\n",
    "Cov_u1[:, :, 1] = np.diag(np.append(np.repeat(0.01, seg_k1), np.repeat(0.35, noise_k1)))\n",
    "Cov_u2[:, :, 0] = np.diag(np.append(np.repeat(0.4, seg_k2), np.repeat(0.01, noise_k2)))\n",
    "Cov_u2[:, :, 1] = np.diag(np.append(np.repeat(0.01, seg_k2), np.repeat(0.3, noise_k2)))\n",
    "Cov_g1[:, :, 0] = np.diag(np.append(np.repeat(0.6, seg_k1), np.repeat(0.01, noise_k1)))\n",
    "Cov_g1[:, :, 1] = np.diag(np.append(np.repeat(0.01, seg_k1), np.repeat(0.35, noise_k1)))\n",
    "Cov_g2[:, :, 0] = np.diag(np.append(np.repeat(0.4, seg_k2), np.repeat(0.01, noise_k2)))\n",
    "Cov_g2[:, :, 1] = np.diag(np.append(np.repeat(0.01, seg_k2), np.repeat(0.3, noise_k2)))\n",
    "Cov = np.full((k, k), 0.1)\n",
    "Cov[seg_block1, seg_block2] = 0.6\n",
    "Cov[noise_block1, noise_block2] = 0.3\n",
    "Covt_u1 = Cov_u1.copy(); Covt_u2 = Cov_u2.copy()\n",
    "Covt_g1 = Cov_g1.copy(); Covt_g2 = Cov_g2.copy()\n",
    "Covt = Cov.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 応答変数を生成\n",
    "# 妥当な値が生成されるまで繰り返す\n",
    "rp = 0\n",
    "while True:\n",
    "\n",
    "    # パラメータの生成\n",
    "    # バイアスパラメータの生成\n",
    "    alpha_a = np.random.normal(-0.5, 1.0, 1)\n",
    "    alpha_b = np.random.normal(-0.5, 1.0, 1)\n",
    "    alpha_c = np.random.normal(-0.5, 1.0, 1)\n",
    "    beta_a = np.random.normal(0.0, tau_a, w)\n",
    "    beta_b = np.random.normal(0.0, tau_b, w)\n",
    "    beta_c = np.random.normal(0.0, tau_c, w)\n",
    "\n",
    "    # モデルパラメータの生成\n",
    "    theta = np.vstack((np.random.multivariate_normal(alpha1, Cov_u1[:, :, 0], seg),\n",
    "                       np.random.multivariate_normal(alpha1, Cov_u1[:, :, 1], r)))\n",
    "    theta_b = np.vstack((np.random.multivariate_normal(alpha2, Cov_u2[:, :, 0], seg),\n",
    "                         np.random.multivariate_normal(alpha2, Cov_u2[:, :, 1], r)))\n",
    "    theta_c = np.vstack((np.random.multivariate_normal(alpha2, Cov_u2[:, :, 0], seg),\n",
    "                         np.random.multivariate_normal(alpha2, Cov_u2[:, :, 1], r)))\n",
    "    gamma = np.vstack((np.random.multivariate_normal(alpha1, Cov_g1[:, :, 0], w1),\n",
    "                       np.random.multivariate_normal(alpha1, Cov_g1[:, :, 1], w2)))\n",
    "    gamma_a = np.vstack((np.random.multivariate_normal(alpha2, Cov_g2[:, :, 0], w1),\n",
    "                         np.random.multivariate_normal(alpha2, Cov_g2[:, :, 1], w2)))\n",
    "    gamma_b = np.vstack((np.random.multivariate_normal(alpha2, Cov_g2[:, :, 0], w1),\n",
    "                         np.random.multivariate_normal(alpha2, Cov_g2[:, :, 1], w2)))\n",
    "    gamma_c = np.vstack((np.random.multivariate_normal(alpha2, Cov_g2[:, :, 0], w1),\n",
    "                         np.random.multivariate_normal(alpha2, Cov_g2[:, :, 1], w2)))\n",
    "    omega_a = np.random.normal(alpha_block.reshape(-1), Cov.reshape(-1), k*k).reshape(k, k)\n",
    "    omega_b = np.random.normal(alpha_block.reshape(-1), Cov.reshape(-1), k*k).reshape(k, k)\n",
    "    omega_c = np.random.normal(alpha_block.reshape(-1), Cov.reshape(-1), k*k).reshape(k, k)\n",
    "\n",
    "\n",
    "    # 単語共起データの応答変数を生成\n",
    "    # 期待値を定義\n",
    "    joint_gamma = np.hstack((gamma, gamma_a))\n",
    "    uv = np.dot(np.dot(joint_gamma, omega_a)[wd1, ] * joint_gamma[wd2, ], k_vec)\n",
    "    uvt = uv.copy()\n",
    "    \n",
    "    # 正規分布から潜在変数を生成\n",
    "    mu = alpha_a + beta_a[wd1] + beta_a[wd2] + uv\n",
    "    U = np.random.normal(mu, Sigma)\n",
    "    y = np.array(U > 0, dtype=\"int\")\n",
    "    Prob = scipy.stats.norm.cdf(mu)\n",
    "    Prob[Prob==0.0] = 10.0 ** -10; Prob[Prob==1.0] = 0.999999\n",
    "    Util = U.copy()\n",
    "    \n",
    "    # 補助データの応答変数を生成\n",
    "    # 期待値を定義\n",
    "    joint_theta = np.hstack((theta, theta_b))\n",
    "    joint_gamma = np.hstack((gamma, gamma_b))\n",
    "    uv1 = np.dot(np.dot(joint_theta, omega_b)[seg_id1, ] * joint_gamma[word_id1, ], k_vec)\n",
    "    uvt1 = uv1.copy()\n",
    "    \n",
    "    # 正規分布から潜在変数を生成\n",
    "    mu1 = alpha_b + beta_b[word_id1] + uv1\n",
    "    U1 = np.random.normal(mu1, Sigma)\n",
    "    y1 = np.array(U1 > 0, dtype=\"int\")\n",
    "    Prob1 = scipy.stats.norm.cdf(mu1)\n",
    "    Prob1[Prob1==0.0] = 10.0 ** -10; Prob1[Prob1==1.0] = 0.999999\n",
    "    Util1 = U1.copy()\n",
    "    \n",
    "    # ドメインデータの応答変数を生成\n",
    "    # 期待値を定義\n",
    "    joint_theta = np.hstack((theta, theta_c))\n",
    "    joint_gamma = np.hstack((gamma, gamma_c))\n",
    "    uv2 = np.dot(np.dot(joint_theta, omega_c)[seg_id2, ] * joint_gamma[word_id2, ], k_vec)\n",
    "    uvt2 = uv2.copy()\n",
    "    \n",
    "    # 正規分布から潜在変数を生成\n",
    "    mu2 = alpha_c + beta_c[word_id2] + uv2\n",
    "    U2 = np.random.normal(mu2, Sigma)\n",
    "    y2 = np.array(U2 > 0, dtype=\"int\")\n",
    "    Prob2 = scipy.stats.norm.cdf(mu2)\n",
    "    Prob2[Prob2==0.0] = 10.0 ** -10; Prob2[Prob2==1.0] = 0.999999\n",
    "    Util2 = U2.copy()\n",
    "    \n",
    "    # break判定\n",
    "    means = [np.mean(y), np.mean(y1), np.mean(y2)]\n",
    "    print([rp, np.round(np.mean(y), 3), np.round(np.mean(y1), 3), np.round(np.mean(y2), 3)])\n",
    "    if (np.max(means) < 0.5) & (np.min(means) > 0.35):\n",
    "        break\n",
    "    else:\n",
    "        rp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対数尤度の基準値\n",
    "# 単語共起モデルの対数尤度\n",
    "LLst = np.sum(y*np.log(np.mean(y)) + (1-y)*np.log(1-np.mean(y)))\n",
    "LLbest = np.sum(y*np.log(Prob) + (1-y)*np.log(1-Prob))\n",
    "print(np.round([LLst, LLbest], 1))\n",
    "\n",
    "# 補助データモデルの対数尤度\n",
    "LLst1 = np.sum(y1*np.log(np.mean(y1)) + (1-y1)*np.log(1-np.mean(y1)))\n",
    "LLbest1 = np.sum(y1*np.log(Prob1) + (1-y1)*np.log(1-Prob1))\n",
    "print(np.round([LLst1, LLbest1], 1))\n",
    "\n",
    "# ドメインデータモデルの対数尤度\n",
    "LLst2 = np.sum(y2*np.log(np.mean(y2)) + (1-y2)*np.log(1-np.mean(y2)))\n",
    "LLbest2 = np.sum(y2*np.log(Prob2) + (1-y2)*np.log(1-Prob2))\n",
    "print(np.round([LLst2, LLbest2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語共起モデルの生成データを可視化\n",
    "title = \"単語共起モデルの\"\n",
    "q1 = 0.1; q2 = 99.9\n",
    "dt = [beta_a, uv, mu, Prob]\n",
    "fig_range = np.append(np.array([np.min(beta_a), np.percentile(uv, q1), np.percentile(mu, q1), 0]), \n",
    "                      np.array([np.max(beta_a), np.percentile(uv, q2), np.percentile(mu, q2), 1.0])).reshape(2, len(dt))\n",
    "colorlist = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]\n",
    "legend = [title + \"バイアス項の分布\", title + \"特徴ベクトル和の分布\", title + \"期待値の分布\",  title + \"応答確率の分布\"]\n",
    "fig = plt.figure(figsize=(12.5, 7.0))\n",
    "for j in range(len(dt)):\n",
    "    ax = fig.add_subplot(2, 2, j+1)\n",
    "    ax.hist(dt[j],  bins=25, range=(fig_range[0, j], fig_range[1, j]), color=colorlist[j])\n",
    "    plt.title(legend[j], fontsize=12.5)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 補助データモデルの生成データを可視化\n",
    "title = \"補助データモデルの\"\n",
    "q1 = 0.1; q2 = 99.9\n",
    "dt = [beta_b, uv1, mu1, Prob1]\n",
    "fig_range = np.append(np.array([np.min(beta_b), np.percentile(uv1, q1), np.percentile(mu1, q1), 0]), \n",
    "                      np.array([np.max(beta_b), np.percentile(uv1, q2), np.percentile(mu1, q2), 1.0])).reshape(2, len(dt))\n",
    "colorlist = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]\n",
    "legend = [title + \"バイアス項の分布\", title + \"特徴ベクトル和の分布\", title + \"期待値の分布\",  title + \"応答確率の分布\"]\n",
    "fig = plt.figure(figsize=(12.5, 7.0))\n",
    "for j in range(len(dt)):\n",
    "    ax = fig.add_subplot(2, 2, j+1)\n",
    "    ax.hist(dt[j],  bins=25, range=(fig_range[0, j], fig_range[1, j]), color=colorlist[j])\n",
    "    plt.title(legend[j], fontsize=12.5)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ドメインデータモデルの生成データを可視化\n",
    "title = \"ドメインデータモデルの\"\n",
    "q1 = 0.1; q2 = 99.9\n",
    "dt = [beta_c, uv2, mu2, Prob2]\n",
    "fig_range = np.append(np.array([np.min(beta_c), np.percentile(uv2, q1), np.percentile(mu2, q1), 0]), \n",
    "                      np.array([np.max(beta_c), np.percentile(uv2, q2), np.percentile(mu2, q2), 1.0])).reshape(2, len(dt))\n",
    "colorlist = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]\n",
    "legend = [title + \"バイアス項の分布\", title + \"特徴ベクトル和の分布\", title + \"期待値の分布\",  title + \"応答確率の分布\"]\n",
    "fig = plt.figure(figsize=(12.5, 7.0))\n",
    "for j in range(len(dt)):\n",
    "    ax = fig.add_subplot(2, 2, j+1)\n",
    "    ax.hist(dt[j],  bins=25, range=(fig_range[0, j], fig_range[1, j]), color=colorlist[j])\n",
    "    plt.title(legend[j], fontsize=12.5)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成したパラメータをコピーする\n",
    "# バイアスパラメータをコピー\n",
    "alphat_a = alpha_a.copy()\n",
    "alphat_b = alpha_b.copy()\n",
    "alphat_c = alpha_c.copy()\n",
    "betat_a = beta_a.copy()\n",
    "betat_b = beta_b.copy()\n",
    "betat_c = beta_c.copy()\n",
    "\n",
    "# モデルパラメータをコピー\n",
    "thetat = theta.copy()\n",
    "thetat_b = theta_b.copy()\n",
    "thetat_c = theta_c.copy()\n",
    "gammat = gamma.copy()\n",
    "gammat_a = gamma_a.copy()\n",
    "gammat_b = gamma_b.copy()\n",
    "gammat_c = gamma_c.copy()\n",
    "omegat_a = omega_a.copy()\n",
    "omegat_b = omega_b.copy()\n",
    "omegat_c = omega_c.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised object matching with Latent space modelを推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アルゴリズムの設定\n",
    "R = 2000\n",
    "keep = 2\n",
    "burnin = 500\n",
    "skeep = int(burnin/keep)\n",
    "iters = 0\n",
    "disp = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの定義\n",
    "# 定数の定義\n",
    "seg_weights = 1.0\n",
    "N = torch.Tensor([F, N1, N2])\n",
    "k_vec = torch.Tensor([1.0]).repeat(k)\n",
    "seg_vec = torch.Tensor([1.0]).repeat(r + max_seg)\n",
    "\n",
    "# numpy配列をtorch配列に変換\n",
    "y = torch.Tensor(y)\n",
    "y1 = torch.Tensor(y1)\n",
    "y2 = torch.Tensor(y2)\n",
    "S1 = torch.Tensor(np.array(joint_long1!=seg+r, dtype=\"int\"))\n",
    "S2 = torch.Tensor(np.array(joint_long2!=seg+r, dtype=\"int\"))\n",
    "\n",
    "# パラメータインデックスを定義\n",
    "index_k1 = np.arange(k1)\n",
    "index_k2 = np.arange(k1, k)\n",
    "index_allocation1 = np.repeat(np.arange(k), k)\n",
    "index_allocation2 = np.tile(np.arange(k), k)\n",
    "index_y11 = np.array(np.where(y1==1)[0], dtype=\"int\")\n",
    "index_y10 = np.array(np.where(y1==0)[0], dtype=\"int\")\n",
    "index_y21 = np.array(np.where(y2==1)[0], dtype=\"int\")\n",
    "index_y20 = np.array(np.where(y2==0)[0], dtype=\"int\")\n",
    "\n",
    "# データ割当のインデックス\n",
    "seg_allocation1 = np.hstack((np.arange(1, k+1), np.repeat(0, k2)))\n",
    "seg_allocation2 = np.hstack((np.arange(1, k1+1), np.repeat(0, k2), np.arange(k1+1, k+1)))\n",
    "word_allocation = np.hstack((np.arange(k+3), np.repeat(1, 2*k2)))\n",
    "word_allocation1 = np.hstack((np.arange(k1+3), np.repeat(0, k2), np.arange(k1+3, k+3), np.repeat(0, k2)))\n",
    "word_allocation2 = np.hstack((np.arange(k1+3), np.repeat(0, 2*k2), np.arange(k1+3, k+3)))\n",
    "\n",
    "# 切片を定義\n",
    "zeros1 = torch.Tensor([0.0]).repeat(N1)[:, np.newaxis]\n",
    "zeros2 = torch.Tensor([0.0]).repeat(N2)[:, np.newaxis]\n",
    "intercept = torch.cat([torch.Tensor([1.0]).repeat(F)[:, np.newaxis], \n",
    "                       torch.Tensor([0.0]).repeat(F)[:, np.newaxis],\n",
    "                       torch.Tensor([0.0]).repeat(F)[:, np.newaxis]], dim=1)\n",
    "intercept1 = torch.cat([torch.Tensor([0.0]).repeat(N1)[:, np.newaxis], \n",
    "                        torch.Tensor([1.0]).repeat(N1)[:, np.newaxis],\n",
    "                        torch.Tensor([0.0]).repeat(N1)[:, np.newaxis]], dim=1)\n",
    "intercept2 = torch.cat([torch.Tensor([0.0]).repeat(N2)[:, np.newaxis], \n",
    "                        torch.Tensor([0.0]).repeat(N2)[:, np.newaxis],\n",
    "                        torch.Tensor([1.0]).repeat(N2)[:, np.newaxis]], dim=1)\n",
    "\n",
    "#切断領域を定義\n",
    "rho = 10.0\n",
    "a = (1-y)*(-rho) + y*0\n",
    "b = y*rho + (1-y)*0\n",
    "a1 = (1-y1)*(-rho) + y1*0\n",
    "b1 = y1*rho + (1-y1)*0\n",
    "a2 = (1-y2)*(-rho) + y2*0\n",
    "b2 = y2*rho + (1-y2)*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事前分布の設定\n",
    "# 階層モデルの事前分布\n",
    "V1 = 0.1 * torch.diag(torch.Tensor([1.0]).repeat(k1+2*k2))\n",
    "V2 = 0.1 * torch.diag(torch.Tensor([1.0]).repeat(k1+modes*k2+modes))\n",
    "nu = 1\n",
    "s0 = 0.1\n",
    "v0 = 0.1\n",
    "\n",
    "# モデルパラメータの事前分布\n",
    "tau = 100.0\n",
    "eta = 0.1\n",
    "alpha = torch.Tensor([0.0])\n",
    "alpha1 = torch.Tensor([0.0]).repeat(k1+2*k2)\n",
    "alpha2 = torch.Tensor([0.0]).repeat(k1+3*k2+3)\n",
    "alpha3 = torch.diag(torch.Tensor([0.0]).repeat(k)).reshape(-1)\n",
    "Cov = torch.diag((torch.Tensor([0.1]).repeat(k*k).reshape(k, k) + torch.diag(torch.Tensor([0.1]).repeat(k))).reshape(-1))\n",
    "inv_Cov = torch.inverse(Cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの真値\n",
    "# 分散共分散行列の真値\n",
    "Cov_u = torch.diag(torch.Tensor([0.5]).repeat(k1+modes*k2+modes))\n",
    "Cov_g = torch.diag(torch.Tensor([0.25]).repeat(k1+2*k2))\n",
    "inv_Cov_u = torch.inverse(Cov_u)\n",
    "inv_Cov_g = torch.inverse(Cov_g)\n",
    "\n",
    "# バイアスパラメータの真値\n",
    "pi1 = torch.Tensor(pit1)\n",
    "pi2 = torch.Tensor(pit2)\n",
    "alpha_a = torch.Tensor([alpha_a])\n",
    "alpha_b = torch.Tensor([alpha_b])\n",
    "alpha_c = torch.Tensor([alpha_c])\n",
    "beta_a = torch.Tensor(beta_a)\n",
    "beta_b = torch.Tensor(beta_b)\n",
    "beta_c = torch.Tensor(beta_c)\n",
    "\n",
    "# モデルパラメータの真値\n",
    "Sigma = 1.0\n",
    "theta = torch.Tensor(thetat)\n",
    "theta_b = torch.Tensor(thetat_b)\n",
    "theta_c = torch.Tensor(thetat_c)\n",
    "gamma = torch.Tensor(gammat)\n",
    "gamma_a = torch.Tensor(gammat_a)\n",
    "gamma_b = torch.Tensor(gammat_b)\n",
    "gamma_c = torch.Tensor(gammat_c)\n",
    "omega_a = torch.Tensor(omegat_a)\n",
    "omega_b = torch.Tensor(omegat_b)\n",
    "omega_c = torch.Tensor(omegat_c)\n",
    "\n",
    "# パラメータを定義\n",
    "beta_long1 = beta_a[wd1]; beta_long2 = beta_b[wd2]\n",
    "beta_word1 = beta_b[word_id1]\n",
    "beta_word2 = beta_c[word_id2]\n",
    "joint_theta1 = torch.cat([theta, theta_b], dim=1)\n",
    "joint_theta2 = torch.cat([theta, theta_c], dim=1)\n",
    "joint_gamma = torch.cat([gamma, gamma_a], dim=1)\n",
    "joint_gamma1 = torch.cat([gamma, gamma_b], dim=1)\n",
    "joint_gamma2 = torch.cat([gamma, gamma_c], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの初期値\n",
    "# 分散共分散行列の初期値\n",
    "Cov_u = torch.diag(torch.Tensor([0.1]).repeat(k1+modes*k2+modes))\n",
    "Cov_g = torch.diag(torch.Tensor([0.1]).repeat(k1+2*k2))\n",
    "inv_Cov_u = torch.inverse(Cov_u)\n",
    "inv_Cov_g = torch.inverse(Cov_g)\n",
    "\n",
    "# バイアスパラメータの初期値\n",
    "eta1 = np.repeat(20.0/r, r)\n",
    "eta2 = 40.0\n",
    "pi1 = torch.zeros((d1, max_seg + r))\n",
    "pi2 = torch.zeros((d2, max_seg + r))\n",
    "for i in range(d1):\n",
    "    pi1[i, np.arange(r + m1[i])] = torch.Tensor(np.random.dirichlet(np.append(eta1, np.repeat(eta2/m1[i], m1[i]))))\n",
    "for i in range(d2):\n",
    "    pi2[i, np.arange(r + m2[i])] = torch.Tensor(np.random.dirichlet(np.append(eta1, np.repeat(eta2/m2[i], m2[i]))))\n",
    "alpha_a = torch.Tensor([-0.5])\n",
    "alpha_b = torch.Tensor([-0.5])\n",
    "alpha_c = torch.Tensor([-0.5])\n",
    "beta_a = torch.Tensor(np.random.normal(0.0, 0.5, w))\n",
    "beta_b = torch.Tensor(np.random.normal(0.0, 0.5, w))\n",
    "beta_c = torch.Tensor(np.random.normal(0.0, 0.5, w))\n",
    "\n",
    "# モデルパラメータの初期値\n",
    "Sigma = 1.0\n",
    "theta = torch.Tensor(np.random.normal(0.0, 0.3, (seg+r)*k1).reshape(seg+r, k1))\n",
    "theta_b = torch.Tensor(np.random.normal(0.0, 0.3, (seg+r)*k2).reshape(seg+r, k2))\n",
    "theta_c = torch.Tensor(np.random.normal(0.0, 0.3, (seg+r)*k2).reshape(seg+r, k2))\n",
    "gamma = torch.Tensor(np.random.normal(0.0, 0.3, w*k1).reshape(w, k1))\n",
    "gamma_a = torch.Tensor(np.random.normal(0.0, 0.3, w*k2).reshape(w, k2))\n",
    "gamma_b = torch.Tensor(np.random.normal(0.0, 0.3, w*k2).reshape(w, k2))\n",
    "gamma_c = torch.Tensor(np.random.normal(0.0, 0.3, w*k2).reshape(w, k2))\n",
    "omega_a = torch.diag(torch.Tensor([0.5]).repeat(k))\n",
    "omega_b = torch.diag(torch.Tensor([0.5]).repeat(k))\n",
    "omega_c = torch.diag(torch.Tensor([0.5]).repeat(k))\n",
    "\n",
    "# パラメータを定義\n",
    "beta_long1 = beta_a[wd1]; beta_long2 = beta_b[wd2]\n",
    "beta_word1 = beta_b[word_id1]\n",
    "beta_word2 = beta_c[word_id2]\n",
    "joint_theta1 = torch.cat([theta, theta_b], dim=1)\n",
    "joint_theta2 = torch.cat([theta, theta_c], dim=1)\n",
    "joint_gamma = torch.cat([gamma, gamma_a], dim=1)\n",
    "joint_gamma1 = torch.cat([gamma, gamma_b], dim=1)\n",
    "joint_gamma2 = torch.cat([gamma, gamma_c], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの格納用配列\n",
    "# バーンインのインデッククを定義\n",
    "RS = np.arange(skeep, int(R/keep))\n",
    "rs = RS.shape[0]\n",
    "\n",
    "# 事前分布の格納用配列\n",
    "COV_U = torch.zeros((k1+modes*k2+modes, k1+modes*k2+modes, rs))\n",
    "COV_G = torch.zeros((k1+2*k2, k1+2*k2, rs))\n",
    "\n",
    "# バイアスパラメータの格納用配列\n",
    "PI1 = torch.zeros((seg, r+max_seg, rs))\n",
    "PI2 = torch.zeros((seg, r+max_seg, rs))\n",
    "ALPHA_A = torch.zeros((rs))\n",
    "ALPHA_B = torch.zeros((rs))\n",
    "ALPHA_C = torch.zeros((rs))\n",
    "BETA_A = torch.zeros((rs, w))\n",
    "BETA_B = torch.zeros((rs, w))\n",
    "BETA_C = torch.zeros((rs, w))\n",
    "\n",
    "# モデルパラメータの格納用配列\n",
    "THETA = torch.zeros((seg+r, k1, rs))\n",
    "THETA_B = torch.zeros((seg+r, k2, rs))\n",
    "THETA_C = torch.zeros((seg+r, k2, rs))\n",
    "GAMMA = torch.zeros((w, k1, rs))\n",
    "GAMMA_A = torch.zeros((w, k2, rs))\n",
    "GAMMA_B = torch.zeros((w, k2, rs))\n",
    "GAMMA_C = torch.zeros((w, k2, rs))\n",
    "OMEGA_A = torch.zeros((k, k, rs))\n",
    "OMEGA_B = torch.zeros((k, k, rs))\n",
    "OMEGA_C = torch.zeros((k, k, rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ギブスサンプリングでパラメータをサンプリング\n",
    "start_time = time.time()\n",
    "for rp in range(R):\n",
    "    \n",
    "    # ベイズの定理よりsegmentをサンプリング\n",
    "    # パラメータの定数を定義\n",
    "    joint_theta1 = torch.cat([theta, theta_b], dim=1)\n",
    "    joint_theta2 = torch.cat([theta, theta_c], dim=1)\n",
    "    joint_gamma1 = torch.cat([gamma, gamma_b], dim=1)[word_id1, ]\n",
    "    joint_gamma2 = torch.cat([gamma, gamma_c], dim=1)[word_id2, ]\n",
    "    uv_deploy1 = torch.mm(joint_theta1, omega_b)\n",
    "    uv_deploy2 = torch.mm(joint_theta2, omega_c)\n",
    "\n",
    "    # segmentの全パターンの期待値を定義\n",
    "    joint_mu1 = torch.zeros((N1, max_seg + r)); joint_mu2 = torch.zeros((N2, max_seg + r))\n",
    "    joint_uv1 = torch.zeros((N1, max_seg + r)); joint_uv2 = torch.zeros((N2, max_seg + r))\n",
    "    joint_uv1[:, :r] = torch.mm(joint_gamma1, uv_deploy1[seg:, ].T)\n",
    "    joint_uv2[:, :r] = torch.mm(joint_gamma2, uv_deploy2[seg:, ].T)\n",
    "    joint_uv1[:, :r] = alpha_b + beta_word1[:, np.newaxis] + joint_uv1[:, :r]\n",
    "    joint_uv2[:, :r] = alpha_c + beta_word2[:, np.newaxis] + joint_uv2[:, :r]\n",
    "    for j in range(max_seg):\n",
    "        index1 = seg_record1[j]\n",
    "        index2 = seg_record2[j]\n",
    "        joint_uv1[index1, r+j] = torch.mv(uv_deploy1[joint_long1[index1, r+j], ] * joint_gamma1[index1, ] , k_vec)\n",
    "        joint_uv2[index2, r+j] = torch.mv(uv_deploy2[joint_long2[index2, r+j], ] * joint_gamma2[index2, ] , k_vec)\n",
    "        joint_mu1[index1, r+j] = alpha_b + beta_word1[index1] + joint_uv1[index1, r+j]\n",
    "        joint_mu2[index2, r+j] = alpha_c + beta_word2[index2] + joint_uv2[index2, r+j]\n",
    "\n",
    "    # 事後分布を定義\n",
    "    logit1 = torch.zeros((N1, max_seg + r)); logit2 = torch.zeros((N2, max_seg + r))\n",
    "    logit1[index_y10, ] = S1[index_y10, ] * torch.exp(-seg_weights*joint_mu1[index_y10, ])\n",
    "    logit1[index_y11, ] = S1[index_y11, ] * torch.exp(seg_weights*joint_mu1[index_y11, ])\n",
    "    logit2[index_y20, ] = S2[index_y20, ] * torch.exp(-seg_weights*joint_mu2[index_y20, ])\n",
    "    logit2[index_y21, ] = S2[index_y21, ] * torch.exp(seg_weights*joint_mu2[index_y21, ])\n",
    "    Posterior1 = pi1[d_id1, ] * (logit1 / torch.mv(logit1, seg_vec)[:, np.newaxis])\n",
    "    Posterior2 = pi2[d_id2, ] * (logit2 / torch.mv(logit2, seg_vec)[:, np.newaxis])\n",
    "\n",
    "    # 多項分布からsegmentを生成\n",
    "    Prob1 = Posterior1 / torch.mv(Posterior1, seg_vec)[:, np.newaxis]\n",
    "    Prob2 = Posterior2 / torch.mv(Posterior2, seg_vec)[:, np.newaxis]\n",
    "    Zi1 = torch.Tensor(rmnom(Prob1.numpy(), N1, r + max_seg, 1)[1])\n",
    "    Zi2 = torch.Tensor(rmnom(Prob2.numpy(), N2, r + max_seg, 1)[1])\n",
    "\n",
    "    # 新しいsegmentのidを定義\n",
    "    new_seg1 = torch.mv(Zi1 * torch.Tensor(joint_long1), seg_vec).int().numpy()\n",
    "    new_seg2 = torch.mv(Zi2 * torch.Tensor(joint_long2), seg_vec).int().numpy()\n",
    "    \n",
    "    \n",
    "    # 切断正規分布より潜在変数を生成\n",
    "    # 期待値の定義\n",
    "    joint_gamma = torch.cat([gamma, gamma_a], dim=1)\n",
    "    uv = torch.mv(torch.mm(joint_gamma, omega_a)[wd1, ] * joint_gamma[wd2, ], k_vec)\n",
    "    uv1 = torch.mv(Zi1 * joint_uv1, seg_vec)\n",
    "    uv2 = torch.mv(Zi2 * joint_uv2, seg_vec)\n",
    "    mu = alpha_a + beta_long1 + beta_long2 + uv\n",
    "    mu1 = alpha_b + beta_word1 + uv1\n",
    "    mu2 = alpha_c + beta_word2 + uv2\n",
    "\n",
    "    # 潜在変数を生成\n",
    "    U = rtnorm(mu, Sigma, a, b, F, 1)\n",
    "    U1 = rtnorm(mu1, Sigma, a1, b1, N1, 1)\n",
    "    U2 = rtnorm(mu2, Sigma, a2, b2, N2, 1)\n",
    "    \n",
    "    # infを置き換え\n",
    "    index = np.where(torch.isinf(U)==True)[0]\n",
    "    index1 = np.where(torch.isinf(U1)==True)[0]\n",
    "    index2 = np.where(torch.isinf(U2)==True)[0] \n",
    "    if len(index) > 0:\n",
    "        U[index] = y[index]*rtnorm(0, Sigma, 0, 1, len(index), 1) + (1-y[index])*rtnorm(0, Sigma, -1, 0, len(index), 1)\n",
    "    if len(index1) > 0:\n",
    "        U1[index1] = y1[index1]*rtnorm(0, Sigma, 0, 1, len(index1), 1) + (1-y1[index1])*rtnorm(0, Sigma, -1, 0, len(index1), 1)\n",
    "    if len(index2) > 0:\n",
    "        U2[index2] = y2[index2]*rtnorm(0, Sigma, 0, 1, len(index2), 1) + (1-y2[index2])*rtnorm(0, Sigma, -1, 0, len(index2), 1)\n",
    "\n",
    "\n",
    "    # 期待値パラメータをサンプリング\n",
    "    # モデル誤差を定義\n",
    "    Sigma_sq = Sigma ** 2\n",
    "    er = U - beta_long1 - beta_long2 - uv\n",
    "    er1 = U1 - beta_word1 - uv1\n",
    "    er2 = U2 - beta_word2 - uv2\n",
    "    er_y = torch.Tensor([torch.sum(er), torch.sum(er1), torch.sum(er2)])\n",
    "\n",
    "    # 正規分布から期待値をサンプリング\n",
    "    weights = tau / (Sigma_sq / N + tau)\n",
    "    alpha_mu = weights * (er_y / N)\n",
    "    Posterior = Normal(alpha_mu, weights*Sigma_sq/N)\n",
    "    alpha_a = Posterior[0]\n",
    "    alpha_b = Posterior[1]\n",
    "    alpha_c = Posterior[2]\n",
    "\n",
    "\n",
    "    # segmentパラメータをサンプリング\n",
    "    # モデル誤差を定義\n",
    "    er1 = U1 - alpha_b - beta_word1\n",
    "    er2 = U2 - alpha_c - beta_word2\n",
    "\n",
    "    # 新しい入力変数を生成\n",
    "    joint_gamma1 = torch.cat([gamma, gamma_b], dim=1)\n",
    "    joint_gamma2 = torch.cat([gamma, gamma_c], dim=1)\n",
    "    X1 = torch.cat([zeros1, torch.mm(joint_gamma1, omega_b.T)[word_id1, ]], dim=1)[:, seg_allocation1]\n",
    "    X2 = torch.cat([zeros2, torch.mm(joint_gamma2, omega_c.T)[word_id2, ]], dim=1)[:, seg_allocation2]\n",
    "\n",
    "    # segmentごとに事後分布をサンプリング\n",
    "    for i in range(seg+r):\n",
    "\n",
    "        # データを定義\n",
    "        index1 = seg_list1[i][new_seg1[seg_list1[i]]==i]\n",
    "        index2 = seg_list2[i][new_seg2[seg_list2[i]]==i]\n",
    "        x = torch.cat([X1[index1, ], X2[index2, ]], dim=0)\n",
    "        er_y = torch.cat([er1[index1], er2[index2]], dim=0)\n",
    "\n",
    "        # 事後分布を定義\n",
    "        xy = torch.mv(x.T, er_y)\n",
    "        xxv = torch.mm(x.T, x) + inv_Cov_g\n",
    "        inv_xxv = torch.inverse(xxv)\n",
    "        theta_mu = torch.mv(inv_xxv, xy + torch.mv(inv_Cov_g, alpha1))\n",
    "\n",
    "        # 事後分布をサンプリング\n",
    "        Posterior = Multivariate_normal(theta_mu, Sigma_sq*inv_xxv, 1)\n",
    "        theta[i, ] = Posterior[index_k1]\n",
    "        theta_b[i, ] = Posterior[index_k2]\n",
    "        theta_c[i, ] = Posterior[k:]\n",
    "\n",
    "    # パラメータを更新\n",
    "    joint_theta1 = torch.cat([theta, theta_b], dim=1)\n",
    "    joint_theta2 = torch.cat([theta, theta_c], dim=1)\n",
    "\n",
    "\n",
    "    # wordパラメータをサンプリング\n",
    "    # モデル誤差を定義\n",
    "    er11 = U - alpha_a - beta_long2\n",
    "    er12 = U - alpha_a - beta_long1\n",
    "    er1 = U1 - alpha_b\n",
    "    er2 = U2 - alpha_c\n",
    "\n",
    "    # 新しい入力変数を定義\n",
    "    X11 = torch.cat([intercept, torch.mm(joint_gamma, omega_a.T)[wd2, ]], dim=1)[:, word_allocation]\n",
    "    X12 = torch.cat([intercept, torch.mm(joint_gamma, omega_a)[wd1, ]], dim=1)[:, word_allocation]\n",
    "    X1 = torch.cat([intercept1, torch.mm(joint_theta1, omega_b)[new_seg1, ]], dim=1)[:, word_allocation1]\n",
    "    X2 = torch.cat([intercept2, torch.mm(joint_theta2, omega_c)[new_seg2, ]], dim=1)[:, word_allocation2]\n",
    "\n",
    "    # wordごとに事後分布をサンプリング\n",
    "    Posterior = torch.zeros((w, k1+modes*k2+modes))\n",
    "    for i in range(w):\n",
    "        # データを定義\n",
    "        index11 = w_list1[i]; index12 = w_list2[i]\n",
    "        index1 = word_list1[i]\n",
    "        index2 = word_list2[i]\n",
    "        x = torch.cat([X11[index11, ], X12[index12, ], X1[index1, ], X2[index2, ]], dim=0)\n",
    "        er_y = torch.cat([er11[index11], er12[index12], er1[index1], er2[index2]], dim=0)\n",
    "\n",
    "        # 事後分布をサンプリング\n",
    "        xy = torch.mv(x.T, er_y)\n",
    "        xxv = torch.mm(x.T, x) + inv_Cov_u\n",
    "        inv_xxv = torch.inverse(xxv)\n",
    "        gamma_mu = torch.mv(inv_xxv, xy + torch.mv(inv_Cov_u, alpha2))\n",
    "        Posterior[i, ] = Multivariate_normal(gamma_mu, Sigma_sq*inv_xxv, 1)\n",
    "\n",
    "    # パラメータの抽出\n",
    "    beta_a = Posterior[:, 0]\n",
    "    beta_b = Posterior[:, 1]\n",
    "    beta_c = Posterior[:, 2]\n",
    "    gamma = Posterior[:, modes:k1+modes]\n",
    "    gamma_a = Posterior[:, k1+modes:k1+k2+modes]\n",
    "    gamma_b = Posterior[:, k1+k2+modes:k1+2*k2+modes]\n",
    "    gamma_c = Posterior[:, k1+2*k2+modes:k1+modes*k2+modes]\n",
    "\n",
    "    # パラメータを更新\n",
    "    beta_long1 = beta_a[wd1]\n",
    "    beta_long2 = beta_a[wd2]\n",
    "    beta_word1 = beta_b[word_id1]\n",
    "    beta_word2 = beta_c[word_id2]\n",
    "    joint_gamma = torch.cat([gamma, gamma_a], dim=1)\n",
    "    joint_gamma1 = torch.cat([gamma, gamma_b], dim=1)\n",
    "    joint_gamma2 = torch.cat([gamma, gamma_c], dim=1)\n",
    "\n",
    "\n",
    "    # 双線形回帰行列をサンプリング\n",
    "    # モデル誤差を定義\n",
    "    er = U - alpha_a - beta_long1 - beta_long2\n",
    "    er1 = U1 - alpha_b - beta_word1\n",
    "    er2 = U2 - alpha_c - beta_word2\n",
    "\n",
    "    # 新しい入力変数を定義\n",
    "    x = joint_gamma[:, index_allocation1][wd1, ] * joint_gamma[:, index_allocation2][wd2, ]\n",
    "    x1 = joint_theta1[:, index_allocation1][new_seg1, ] * joint_gamma1[:, index_allocation2][word_id1, ]\n",
    "    x2 = joint_theta2[:, index_allocation1][new_seg2, ] * joint_gamma2[:, index_allocation2][word_id2, ]\n",
    "\n",
    "    # 事後分布のパラメータを定義\n",
    "    xy = torch.mv(x.T, er)\n",
    "    xy1 = torch.mv(x1.T, er1)\n",
    "    xy2 = torch.mv(x2.T, er2)\n",
    "    inv_xxv = torch.inverse(torch.mm(x.T, x) + inv_Cov)\n",
    "    inv_xxv1 = torch.inverse(torch.mm(x1.T, x1) + inv_Cov)\n",
    "    inv_xxv2 = torch.inverse(torch.mm(x2.T, x2) + inv_Cov)\n",
    "    omega_mu = torch.mv(inv_xxv, xy + torch.mv(inv_Cov, alpha3))\n",
    "    omega_mu1 = torch.mv(inv_xxv1, xy1 + torch.mv(inv_Cov, alpha3))\n",
    "    omega_mu2 = torch.mv(inv_xxv2, xy2 + torch.mv(inv_Cov, alpha3))\n",
    "\n",
    "    # 事後分布をサンプリング\n",
    "    omega_a = Multivariate_normal(omega_mu, Sigma_sq*inv_xxv, 1).reshape(k, k)\n",
    "    omega_b = Multivariate_normal(omega_mu1, Sigma_sq*inv_xxv1, 1).reshape(k, k)\n",
    "    omega_c = Multivariate_normal(omega_mu2, Sigma_sq*inv_xxv2, 1).reshape(k, k)\n",
    "    \n",
    "    \n",
    "    # 階層モデルの分散共分散行列を推定\n",
    "    # wordパラメータの分散共分散行列を定義\n",
    "    # データの定義\n",
    "    beta_word = torch.cat([beta_a[:, np.newaxis], beta_b[:, np.newaxis], beta_c[:, np.newaxis]], dim=1)\n",
    "    gamma_word = torch.cat([beta_word, gamma, gamma_a, gamma_b, gamma_c], dim=1)\n",
    "    er = gamma_word - torch.mean(gamma_word, axis=0)\n",
    "\n",
    "    # 逆ウィシャート分布から事後分布をサンプリング\n",
    "    IW_R = torch.mm(er.T, er) + V2\n",
    "    Sn = w + nu\n",
    "    Cov_u = torch.diag(torch.diag(Inv_Wishart(Sn, IW_R)))\n",
    "    inv_Cov_u = torch.inverse(Cov_u)\n",
    "\n",
    "    # segmentパラメータの分散共分散行列\n",
    "    # データの定義\n",
    "    theta_seg = torch.cat([theta, theta_b, theta_c], dim=1)\n",
    "    er = theta_seg - torch.mean(theta_seg, axis=0)\n",
    "\n",
    "    # 逆ウィシャート分布から事後分布をサンプリング\n",
    "    IW_R = torch.mm(er.T, er) + V1\n",
    "    Sn = seg + r + nu\n",
    "    Cov_g = torch.diag(torch.diag(Inv_Wishart(Sn, IW_R)))\n",
    "    inv_Cov_g = torch.inverse(Cov_g)\n",
    "    \n",
    "\n",
    "    # segment割当確率の事前分布をサンプリング\n",
    "    # segmentごとに割当確率を生成\n",
    "    for i in range(seg):\n",
    "        # 事後分布のパラメータ\n",
    "        index1 = d_list1[i]\n",
    "        index2 = d_list2[i]\n",
    "        wsum1 = torch.sum(Zi1[index1, ], axis=0)[:r+m1[i]] + eta\n",
    "        wsum2 = torch.sum(Zi2[index2, ], axis=0)[:r+m2[i]] + eta\n",
    "\n",
    "        # ディリクリ分布から事後分布をサンプリング\n",
    "        pi1[i, :r+m1[i]] = Dirichlet(wsum1, 1).reshape(-1)\n",
    "        pi2[i, :r+m2[i]] = Dirichlet(wsum2, 1).reshape(-1)\n",
    "\n",
    "\n",
    "    # サンプリング結果の保存と表示\n",
    "    if (rp%keep==0) & (rp >= burnin):\n",
    "        mkeep = int(rp/keep) - skeep\n",
    "        \n",
    "        # 事前分布の保存\n",
    "        COV_U[:, :, mkeep] = Cov_u\n",
    "        COV_G[:, :, mkeep] = Cov_g\n",
    "        PI1[:, :, mkeep] = pi1\n",
    "        PI2[:, :, mkeep] = pi2\n",
    "        \n",
    "        # バイアスパラメータの保存\n",
    "        ALPHA_A[mkeep] = alpha_a\n",
    "        ALPHA_B[mkeep] = alpha_b\n",
    "        ALPHA_C[mkeep] = alpha_c\n",
    "        BETA_A[mkeep, ] = beta_a\n",
    "        BETA_B[mkeep, ] = beta_b\n",
    "        BETA_C[mkeep, ] = beta_c\n",
    "        \n",
    "        # モデルパラメータの保存\n",
    "        THETA[:, :, mkeep] = theta\n",
    "        THETA_B[:, :, mkeep] = theta_b\n",
    "        THETA_C[:, :, mkeep] = theta_c\n",
    "        GAMMA[:, :, mkeep] = gamma\n",
    "        GAMMA_A[:, :, mkeep] = gamma_a\n",
    "        GAMMA_B[:, :, mkeep] = gamma_b\n",
    "        GAMMA_C[:, :, mkeep] = gamma_c\n",
    "        OMEGA_A[:, :, mkeep] = omega_a\n",
    "        OMEGA_B[:, :, mkeep] = omega_b\n",
    "        OMEGA_C[:, :, mkeep] = omega_c\n",
    "        \n",
    "\n",
    "    # 対数尤度の更新とパラメータの表示\n",
    "    if rp%disp==0:\n",
    "        # 対数尤度の更新\n",
    "        # 期待値を定義\n",
    "        uv = torch.sum(torch.mm(joint_gamma, omega_a)[wd1, ] * joint_gamma[wd2, ], axis=1)\n",
    "        uv1 = torch.sum(torch.mm(joint_theta1, omega_b)[new_seg1, ] * joint_gamma1[word_id1, ], axis=1)\n",
    "        uv2 = torch.sum(torch.mm(joint_theta2, omega_c)[new_seg2, ] * joint_gamma2[word_id2, ], axis=1)\n",
    "        mu = alpha_a + beta_long1 + beta_long2 + uv\n",
    "        mu1 = alpha_b + beta_word1 + uv1\n",
    "        mu2 = alpha_c + beta_word2 + uv2\n",
    "\n",
    "        # 応答確率を定義\n",
    "        Prob = scipy.stats.norm.cdf(mu)\n",
    "        Prob1 = scipy.stats.norm.cdf(mu1)\n",
    "        Prob2 = scipy.stats.norm.cdf(mu2)\n",
    "        Prob[Prob==0.0] = 10.0 ** -10; Prob[Prob==1.0] = 0.999999\n",
    "        Prob1[Prob1==0.0] = 10.0 ** -10; Prob1[Prob1==1.0] = 0.999999\n",
    "        Prob2[Prob2==0.0] = 10.0 ** -10; Prob2[Prob2==1.0] = 0.999999\n",
    "        \n",
    "        # 対数尤度の計算\n",
    "        LL = np.sum(y.numpy()*np.log(Prob) + (1-y.numpy())*np.log(1-Prob))\n",
    "        LL1 = np.sum(y1.numpy()*np.log(Prob1) + (1-y1.numpy())*np.log(1-Prob1))\n",
    "        LL2 = np.sum(y2.numpy()*np.log(Prob2) + (1-y2.numpy())*np.log(1-Prob2))\n",
    "\n",
    "        # segment割当の正答率\n",
    "        acc1 = np.mean((new_seg1==seg_id1)[y1==1])\n",
    "        acc2 = np.mean((new_seg2==seg_id2)[y2==1])\n",
    "\n",
    "        # 経過時間を取得\n",
    "        intermediate_time = time.time()\n",
    "        elapsed_time = (intermediate_time - start_time) / 60\n",
    "\n",
    "        # サンプリング結果を表示\n",
    "        print(rp)\n",
    "        print(\"経過時間: {}\".format(elapsed_time))\n",
    "        print(np.round([acc1, acc2], 3))\n",
    "        print(np.round([LL, LLst, LLbest], 1))\n",
    "        print(np.round([LL1, LLst1, LLbest1], 1))\n",
    "        print(np.round([LL2, LLst2, LLbest2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment割当確率の事前分布をサンプリング\n",
    "# y=1の潜在変数のみ抽出\n",
    "W1 = y1[:, np.newaxis] * Zi1\n",
    "W2 = y2[:, np.newaxis] * Zi2\n",
    "\n",
    "# segmentごとに割当確率を生成\n",
    "for i in range(seg):\n",
    "    # 事後分布のパラメータ\n",
    "    index1 = d_list1[i]\n",
    "    index2 = d_list2[i]\n",
    "    wsum1 = torch.sum(W1[index1, ], axis=0)[:r+m1[i]] + eta\n",
    "    wsum2 = torch.sum(W2[index2, ], axis=0)[:r+m2[i]] + eta\n",
    "\n",
    "    # ディリクリ分布から事後分布をサンプリング\n",
    "    pi1[i, :r+m1[i]] = Dirichlet(wsum1, 1).reshape(-1)\n",
    "    pi2[i, :r+m2[i]] = Dirichlet(wsum2, 1).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 期待値を定義\n",
    "uv = torch.sum(torch.mm(joint_gamma, omega_a)[wd1, ] * joint_gamma[wd2, ], axis=1)\n",
    "uv1 = torch.sum(torch.mm(joint_theta1, omega_b)[new_seg1, ] * joint_gamma1[word_id1, ], axis=1)\n",
    "uv2 = torch.sum(torch.mm(joint_theta2, omega_c)[new_seg2, ] * joint_gamma2[word_id2, ], axis=1)\n",
    "mu = alpha_a + beta_long1 + beta_long2 + uv\n",
    "mu1 = alpha_b + beta_word1 + uv1\n",
    "mu2 = alpha_c + beta_word2 + uv2\n",
    "\n",
    "# 応答確率を定義\n",
    "Prob = scipy.stats.norm.cdf(mu)\n",
    "Prob1 = scipy.stats.norm.cdf(mu1)\n",
    "Prob2 = scipy.stats.norm.cdf(mu2)\n",
    "Prob[Prob==0.0] = 10.0 ** -10; Prob[Prob==1.0] = 0.999999\n",
    "Prob1[Prob1==0.0] = 10.0 ** -10; Prob1[Prob1==1.0] = 0.999999\n",
    "Prob2[Prob2==0.0] = 10.0 ** -10; Prob2[Prob2==1.0] = 0.999999\n",
    "\n",
    "# 対数尤度の計算\n",
    "LL = np.sum(y.numpy()*np.log(Prob) + (1-y.numpy())*np.log(1-Prob))\n",
    "LL1 = np.sum(y1.numpy()*np.log(Prob1) + (1-y1.numpy())*np.log(1-Prob1))\n",
    "LL2 = np.sum(y2.numpy()*np.log(Prob2) + (1-y2.numpy())*np.log(1-Prob2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
