{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリの読み込み\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot  as plt\n",
    "import numpy.matlib\n",
    "import scipy.linalg\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizers\n",
    "from scipy.stats import norm\n",
    "from numpy.random import *\n",
    "from scipy import optimize\n",
    "\n",
    "np.random.seed(9837)\n",
    "torch.manual_seed(9837)\n",
    "pd.set_option(\"display.max_rows\", 250)\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多項分布の乱数を生成する関数\n",
    "def rmnom(pr, n, k, pattern):\n",
    "    if pattern==1:\n",
    "        z_id = np.array(np.argmax(np.cumsum(pr, axis=1) >= np.random.uniform(0, 1, n)[:, np.newaxis], axis=1), dtype=\"int\")\n",
    "        Z = np.diag(np.repeat(1, k))[z_id, ]\n",
    "        return z_id, Z\n",
    "    z_id = np.array(np.argmax((np.cumsum(pr, axis=1) >= np.random.uniform(0, 1, n)[:, np.newaxis]), axis=1), dtype=\"int\")\n",
    "    return z_id\n",
    "\n",
    "# ディリクリ分布の乱数を生成する関数\n",
    "def Dirichlet(alpha, n):\n",
    "    x = torch.Tensor(np.random.dirichlet(alpha, n))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力データの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの設定\n",
    "types = 2\n",
    "min_word = 5\n",
    "max_word = 50\n",
    "k11 = 5   # topic wordのsyntax数\n",
    "k12 = 7   # general wordのsyntax数\n",
    "k1 = k11 + k12   # syntax数\n",
    "k21 = 15   # topic wordのトピック数\n",
    "k22 = 10   # general wordのトピック数\n",
    "k2 = k21 + k22   # topic数\n",
    "k3 = 15   # word classのトピック数\n",
    "d = 5000   # 文書数\n",
    "v11 = 1000  # topic wordのvocabulary数\n",
    "v12 = 400   # general wordのvocabulary数\n",
    "v1 = v11 + v12   # vocabulary数\n",
    "v2 = 100   # word class数\n",
    "pt = np.random.poisson(np.random.gamma(12.5, 1.0, d), d)\n",
    "pt[pt < 5] = 5\n",
    "M = np.sum(pt)\n",
    "w = np.random.poisson(np.random.gamma(17.5, 1.5, np.sum(pt)), np.sum(pt))\n",
    "w[w < min_word] = min_word\n",
    "N = np.sum(w)\n",
    "\n",
    "# データベクトルを定義\n",
    "k_vec1 = np.repeat(1.0, k1)\n",
    "k_vec2 = np.repeat(1.0, k2)\n",
    "k_vec21 = np.repeat(1.0, k21)\n",
    "k_vec22 = np.repeat(1.0, k22)\n",
    "index_k11 = np.arange(k11)\n",
    "index_k12 = np.arange(k12) + k11\n",
    "index_k21 = np.arange(k21)\n",
    "index_k22 = np.arange(k22) + k21\n",
    "index_v11 = np.arange(v11)\n",
    "index_v12 = np.arange(v12) + v11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDとインデックスを定義\n",
    "# IDの定義\n",
    "m = np.repeat(0, d)\n",
    "doc_list = []\n",
    "d_id = []\n",
    "doc_id = np.repeat(np.arange(d), pt)\n",
    "for i in range(d):\n",
    "    doc_list.append(np.where(doc_id==i)[0].astype(\"int\"))\n",
    "    m[i] = np.sum(w[doc_list[i]])\n",
    "    d_id.append(np.repeat(i, m[i]))\n",
    "d_id = np.hstack((d_id))\n",
    "sentence_id = np.repeat(np.arange(M), w)\n",
    "pt_id = np.hstack(([np.arange(w[i]) for i in range(M)]))\n",
    "\n",
    "# 文書のインデックスを定義\n",
    "d_list = []\n",
    "sentence_list = []\n",
    "for i in range(d):\n",
    "    d_list.append(np.where(d_id==i)[0].astype(\"int\"))\n",
    "for i in range(M):\n",
    "    sentence_list.append(np.where(sentence_id==i)[0].astype(\"int\"))\n",
    "    \n",
    "# 語順のインデックスを定義\n",
    "max_pt = np.max(pt_id) + 1\n",
    "pt_list = []\n",
    "pt_n = np.repeat(0, max_pt)\n",
    "for j in range(max_pt):\n",
    "    pt_list.append(np.array(np.where(pt_id==j)[0], dtype=\"int\"))\n",
    "    pt_n[j] = pt_list[j].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメータと応答変数を生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事前分布の定義\n",
    "# HMMの事前分布を定義\n",
    "alpha1 = np.repeat(1.0, k1)\n",
    "alpha2 = np.append(np.repeat(0.5, k1), 5.0)\n",
    "\n",
    "# トピック分布の事前分布\n",
    "beta1 = np.append(np.repeat(0.2, k21), np.repeat(0.15, k22))\n",
    "beta2 = np.append(np.repeat(0.1, k21), np.repeat(0.2, k22))\n",
    "\n",
    "# 単語分布の事前分布\n",
    "max_word = 30\n",
    "gamma11 = np.full((k1, v11), 0.01)\n",
    "gamma12 = np.full((k1, v12), 0.005)\n",
    "gamma11[index_k11, ] = 0.05\n",
    "gamma12[index_k12, ] = 0.05\n",
    "gamma1 = np.hstack((gamma11, gamma12))\n",
    "gamma21 = np.full((k2, v11), 0.0025)\n",
    "gamma22 = np.full((k2, v12), 0.001)\n",
    "gamma21[index_k21, ] = 0.025\n",
    "gamma22[index_k22, ] = 0.025\n",
    "gamma2 = np.hstack((gamma21, gamma22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータを生成\n",
    "# HMMの推移確率を生成\n",
    "pi1 = np.append(np.random.dirichlet(alpha1, 1), 0.0).reshape(-1)\n",
    "while True:\n",
    "    pi2 = np.random.dirichlet(alpha2, k1+1)\n",
    "    if (np.mean(pi2[:, k1]) > 0.45) & (np.mean(pi2[:, k1]) < 0.6):\n",
    "        break\n",
    "pit1 = pi1.copy(); pit2 = pi2.copy()\n",
    "\n",
    "# ディリクリ分布からトピック分布を生成\n",
    "kappa = np.random.normal(0, 0.75, v1)\n",
    "theta = np.vstack((np.random.dirichlet(beta1, v11), \n",
    "                   np.random.dirichlet(beta2, v12)))\n",
    "kappat = kappa.copy(); thetat = theta.copy()\n",
    "\n",
    "# 単語分布の事前分布\n",
    "psi = np.array([np.random.dirichlet(gamma1[j, ], 1).reshape(-1) for j in range(k1)])\n",
    "phi = np.array([np.random.dirichlet(gamma2[j, ], 1).reshape(-1) for j in range(k2)])\n",
    "psit = psi.copy(); phit = phi.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 応答変数を生成\n",
    "# 生成したデータの格納用配列\n",
    "S = np.zeros((N, k1+1), dtype=\"int\")\n",
    "s = np.repeat(0, N)\n",
    "Z = np.zeros((N, k2), dtype=\"int\")\n",
    "z = np.repeat(-1, N)\n",
    "word_id = np.repeat(0, N).astype(\"int16\")\n",
    "word_long = np.full((N, max_pt), -1, dtype=\"int16\")\n",
    "attention_id = np.repeat(-1, N).astype(\"int16\")\n",
    "\n",
    "# トピックと単語を生成\n",
    "for j in range(max_pt):\n",
    "\n",
    "    # 語順に応じた生成を実行\n",
    "    if j==0:\n",
    "        \n",
    "        # 語順が先頭の単語を生成\n",
    "        # 多項分布からsyntaxを生成\n",
    "        index = pt_list[j]\n",
    "        S[index, ] = np.random.multinomial(1, pi1, pt_n[j])\n",
    "        s[index] = np.dot(S[index, ], np.arange(k1+1))\n",
    "\n",
    "        # 単語を生成\n",
    "        word_id[index] = rmnom(psi[s[index], ], pt_n[j], v1, 0)\n",
    "        word_long[index, j] = word_id[index, ]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # 語順が2単語目以降の単語を生成\n",
    "        # 多項分布からsyntaxを生成\n",
    "        index = pt_list[j]\n",
    "        res = rmnom(pi2[s[index-1], ], pt_n[j], k1+1, 1)\n",
    "        S[index, ] = res[1]\n",
    "        s[index] = res[0]\n",
    "\n",
    "        # 単語履歴を更新\n",
    "        for q in range(j):\n",
    "            word_long[index, q] = word_long[index-1, q]\n",
    "        if j < max_word:\n",
    "            index_col = np.arange(j)\n",
    "        else:\n",
    "            index_col = np.arange(j-max_word, j)\n",
    "\n",
    "        # attentionの単語を選択\n",
    "        index_hmm = index[np.array(np.where(res[1][:, k1]==0)[0], dtype=\"int\")]\n",
    "        index_attention = index[np.array(np.where(res[1][:, k1]==1)[0], dtype=\"int\")]  \n",
    "        m1 = index_hmm.shape[0]\n",
    "        m2 = index_attention.shape[0]\n",
    "        \n",
    "        if m2 > 0:\n",
    "            candidate_word = word_long[index_attention-1, ][:, index_col]\n",
    "            logit = kappa[candidate_word, ]\n",
    "            prob = np.exp(logit) / np.sum(np.exp(logit), axis=1)[:, np.newaxis]\n",
    "            word = np.sum(candidate_word * rmnom(prob, m2, prob.shape[1], 1)[1], axis=1)\n",
    "            attention_id[index_attention] = word\n",
    "\n",
    "            # attentionからトピックを生成\n",
    "            res = rmnom(theta[word, ], word.shape[0], k2, 1)\n",
    "            Z[index_attention, ] = res[1]\n",
    "            z[index_attention] = res[0]\n",
    "\n",
    "        # 単語を生成\n",
    "        word_id[index_hmm] = rmnom(psi[s[index_hmm], ], m1, v1, 0)\n",
    "        word_id[index_attention] = rmnom(phi[z[index_attention], ], m2, v1, 0)\n",
    "        word_long[index, j] = word_id[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一部データに教師をつける\n",
    "supervised_prob = 0.25\n",
    "index_y = np.where(s==k1)[0].astype(\"int\")\n",
    "y = np.repeat(0, N)\n",
    "y[index_y] = np.random.binomial(1, 0.25, index_y.shape[0])\n",
    "wd = word_id[index_y]\n",
    "\n",
    "# attentionの単語集合をセット\n",
    "attention_set = np.full((N, max_word), -1, dtype=\"int16\")\n",
    "for j in range(1, max_pt):\n",
    "    index = pt_list[j]\n",
    "    if j < max_word:\n",
    "        index_col = np.arange(max_word)\n",
    "    else:\n",
    "        index_col = np.arange(j-max_word, j)\n",
    "    attention_set[index, ] = word_long[index-1, ][:, index_col]\n",
    "word_set = attention_set.copy()\n",
    "word_set[y==1] = -1\n",
    "\n",
    "# 単語集合のインデックスを定義\n",
    "set_list = [j for j in range(max_word+1)]\n",
    "set_id = [j for j in range(max_word+1)] \n",
    "set_list[0] = np.array([])\n",
    "set_id[0] = np.array([]) \n",
    "for j in range(max_word):\n",
    "    set_list[j+1] = np.array(np.where(word_set[:, j]!=-1)[0], dtype=\"int\")\n",
    "    set_id[j+1] = word_set[set_list[j+1], j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised Self Attention LDAを推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アルゴリズムの設定\n",
    "R = 2000\n",
    "keep = 2\n",
    "burnin = 500\n",
    "skeep = int(burnin/keep)\n",
    "iters = 0\n",
    "disp = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インデックスの設定\n",
    "# 先頭と末尾のインデックスを作成\n",
    "max_pt = np.max(pt_id) + 1\n",
    "index_t11 = np.where(pt_id==0)[0].astype(\"int\")\n",
    "index_t12 = np.repeat(0, d)\n",
    "for i in range(d):\n",
    "    index_t12[i] = np.max(d_list[i])\n",
    "    \n",
    "# 中間のインデックスを作成\n",
    "index_list_t21 = [j for j in range(max_pt-1)]\n",
    "index_list_t22 = [j for j in range(max_pt-1)]\n",
    "for j in range(1, max_pt):\n",
    "    index_list_t21[j-1] = np.where(pt_id==j)[0].astype(\"int\") - 1\n",
    "    index_list_t22[j-1] = np.where(pt_id==j)[0].astype(\"int\")\n",
    "index_t21 = np.sort(np.array(list(itertools.chain(*[index_list_t21[j] for j in range(max_pt-1)]))))\n",
    "index_t22 = np.sort(np.array(list(itertools.chain(*[index_list_t22[j] for j in range(max_pt-1)]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの事前分布を定義\n",
    "# HMMの事前分布を定義\n",
    "alpha1 = np.repeat(1.0, k1)\n",
    "alpha2 = np.append(np.repeat(0.5, k1), 5.0)\n",
    "\n",
    "# トピック分布の事前分布\n",
    "beta1 = 0.1\n",
    "beta2 = 0.1\n",
    "\n",
    "# 単語分布の事前分布\n",
    "gamma1 = 0.05\n",
    "gamma2 = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの真値\n",
    "# 推移確率とトピック分布の真値\n",
    "pi1 = pit1.copy()\n",
    "pi2 = pit2.copy()\n",
    "kappa = kappat.copy()\n",
    "theta = thetat.copy()\n",
    "\n",
    "# 単語分布の真値\n",
    "psi1 = psit[:, index_v11] / np.sum(psit[:, index_v11], axis=1)[:, np.newaxis]\n",
    "psi2 = psit[:, index_v12] / np.sum(psit[:, index_v12], axis=1)[:, np.newaxis]\n",
    "psi = np.hstack((psi1, psi2))\n",
    "phi1 = phit[:, index_v11] / np.sum(phit[:, index_v11], axis=1)[:, np.newaxis]\n",
    "phi2 = phit[:, index_v12] / np.sum(phit[:, index_v12], axis=1)[:, np.newaxis]\n",
    "phi = np.hstack((phi1, phi2))\n",
    "\n",
    "# 潜在変数の真値\n",
    "Si = S.copy()\n",
    "Zi = Z.copy()\n",
    "s = np.dot(Si, np.arange(k1+1))\n",
    "z = np.dot(Zi, np.arange(k2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの初期値\n",
    "# 推移確率とトピック分布の初期値\n",
    "pi1 = np.append(np.random.dirichlet(alpha1, 1), 0.0).reshape(-1)\n",
    "pi2 = np.random.dirichlet(alpha2, k1+1)\n",
    "kappa = np.random.normal(0, 0.75, v1)\n",
    "theta = np.vstack((np.random.dirichlet(np.repeat(beta1, k2), v11), \n",
    "                   np.random.dirichlet(np.repeat(beta2, k2), v12)))\n",
    "\n",
    "# 単語分布の初期値\n",
    "psi1 = np.random.dirichlet(np.repeat(1.0, v11), k1)\n",
    "psi2 = np.random.dirichlet(np.repeat(1.0, v12), k1)\n",
    "psi = np.hstack((psi1, psi2))\n",
    "phi1 = np.random.dirichlet(np.repeat(1.0, v11), k2)\n",
    "phi2 = np.random.dirichlet(np.repeat(1.0, v12), k2)\n",
    "phi = np.hstack((psi1, psi2))\n",
    "\n",
    "# 潜在変数の初期値\n",
    "Si = np.random.multinomial(1, np.random.dirichlet(np.repeat(1.0, k1+1), 1).reshape(-1), N)\n",
    "Zi = np.random.multinomial(1, np.random.dirichlet(np.repeat(1.0, k2), 1).reshape(-1), N)\n",
    "Si[index_y, ] = 0\n",
    "Si[index_y, k1] = 1\n",
    "s = np.dot(Si, np.arange(k1+1))\n",
    "z = np.dot(Zi, np.arange(k2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメータをサンプリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事後分布を定義\n",
    "# syntaxとトピックの尤度を定義\n",
    "phi_long = (phi.T)[word_id, ]\n",
    "Lho1 = (psi.T)[word_id, ]   # syntaxごとの尤度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(1, max_word+1):\n",
    "    theta[set_id[j], ] * phi_long[set_list[j], ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00080195, 0.00399579, 0.00102145, ..., 0.00428589, 0.00989484,\n",
       "       0.01790802])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = 1\n",
    "np.dot(theta[set_id[j], ] * phi_long[set_list[j], ], k_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      1,       2,       4, ..., 1642451, 1642452, 1642453])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_list[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
