{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Tracking and Document Modeling with nested CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##多項分布の乱数を生成する関数\n",
    "def rmnom(pr, n, k, pattern):\n",
    "    if pattern==1:\n",
    "        z_id = np.array(np.argmax(np.cumsum(pr, axis=1) >= np.random.uniform(0, 1, n)[:, np.newaxis], axis=1), dtype=\"int\")\n",
    "        Z = np.diag(np.repeat(1, k))[z_id, ]\n",
    "        return z_id, Z\n",
    "    z_id = np.argmax((np.cumsum(pr, axis=1) >= np.random.uniform(0, 1, n)[:, np.newaxis]), axis=1)\n",
    "    return z_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####User Tracking and Document Modeling with nCRF#####\n",
    "# ライブラリの読み込み\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot  as plt\n",
    "import numpy.matlib\n",
    "import scipy.linalg\n",
    "import itertools\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy import special\n",
    "from scipy import sparse\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from numpy.random import *\n",
    "\n",
    "#np.random.seed(98537)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 無限次元のディリクレ分布\n",
    "## a. ノンパラメトリックベイズモデル\n",
    "ノンパラメトリックベイズモデルの中心的な役割を果たすのは**ディレクリ過程混合モデル**です。このモデルは有限混合モデルを**無限混合モデル**に拡張したものとみなすことができます。\n",
    "まず有限混合モデルについてはあらかじめ決められたクラス数$K$に分割するようなクラスタリングの確率モデルの1つです。  \n",
    "モデルの事後分布は\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\bf z\\rm_{1:n},\\bf \\theta\\rm_{1:K} | \\bf x\\rm_{1:n}) \\propto \\prod_{i=1}^{n} p(\\bf x\\rm_{i}|\\bf \\theta_{z_\\rm{i}}) \\rm p(\\bf z\\rm_{i}|\\bf \\pi\\rm_{0}) \\prod_{k=1}^{K}p(\\bf \\theta\\rm_{k}|\\alpha_{0}) \\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "となります。$n$はレコード数、$K$はクラス数を表します。\n",
    "対して、無限混合モデルはクラス数$K$を$\\infty$次元に拡張して\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\bf z\\rm_{1:n},\\bf \\theta\\rm_{1:\\infty} | \\bf x\\rm_{1:n}) \\propto \\prod_{i=1}^{n} p(\\bf x\\rm_{i}|\\bf \\theta_{z_\\rm{i}}) \\rm p(\\bf z\\rm_{i}|\\bf \\pi\\rm_{0}) \\prod_{k=1}^{\\infty}p(\\bf \\theta\\rm_{\\infty}|\\alpha_{0}) \\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "となります。このモデルの利点は有限混合モデルと異なり、あらかじめクラス数を決めなくて良いという利点がありデータからクラス数をデータから推定することができます。  \n",
    "クラス数を$k$次元から$\\infty$次元に拡張するときのクラスタリングは**中華料理店過程(Chinese Restaurant Process)** で定式化することができます。\n",
    "## b. 中華料理店過程\n",
    "### i. 概要と定式化\n",
    "中華料理店過程は無限混合モデルのディリクレ分布の無限次元を定式化するための方法です。  \n",
    "ディリクレ分布のパラメータは次元数が有限の場合$\\sum_{j=1}^{k}\\pi_{j}=1$が満たされます。これを無限次元に拡張しても$\\sum_{j=1}^{\\infty}\\pi_{j}=1$が満たされなければいけません。しかし無限次元の$\\pi$は扱いが難しいので、これを周辺化して\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\bf z\\rm_{i}=k | \\bf z\\rm_{1:n}^{\\backslash i},\\bf\\pi\\rm_{0}) = \\frac{n_{k}^{\\backslash i} + \\alpha/K}{n-1+\\alpha} \\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "とします。ただし$n_{k}^{\\backslash i}$はクラス$k$に割り当てられたレコードiを取り除いた頻度、$K$はクラス数、$\\alpha$はディリクレ事前分布のパラメータ(ディリクレ過程の文脈では集中度パラメータ)を表します。  \n",
    "もし、$k$が$1:K$の集合にない場合の(3)は以下の式で表されます。\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\bf z\\rm_{i}=K+1 | \\bf z\\rm_{1:n}^{\\backslash i},\\bf\\pi\\rm_{0}) = \\frac{\\alpha/K}{n-1+\\alpha} \\tag{4}\n",
    "\\end{equation}\n",
    "\n",
    "これは$1:K$を既存クラスと考えると$K+1$は新しいクラスと解釈できます。  \n",
    "$\\bf z\\rm_{1:n}^{\\backslash i}$に現れる$\\{1,2,\\cdots,K\\}$の集合を$K^{+}\\bf(z\\rm_{1:n}^{\\backslash i})$と表現したとき新しいクラス$k\\not\\in K^{+}\\bf(z\\rm_{1:n}^{\\backslash i})$が選択される確率は(4)から\n",
    "\n",
    "\\begin{equation}\n",
    "p(z_{i} \\not\\in K^{+}\\bf(z\\rm_{1:n}^{\\backslash i})|\\bf z\\rm_{1:n}^{\\backslash i}) = \\bigl(1 - \\frac{|K^{+}(\\bf z\\rm_{1:n}^{\\backslash i})|}{K}\\bigr)\\frac{\\alpha}{n-1+\\alpha} \\tag{5}\n",
    "\\end{equation}\n",
    "\n",
    "となり、さらに$K$を$\\infty$とすると既存クラスの選択確率と新しいクラスの選択確率の事前分布は\n",
    "\n",
    "\\begin{equation}  \n",
    "y_{i} =\n",
    "  \\begin{cases}\n",
    "      p(z_{i} \\in K^{+}\\bf(z\\rm_{1:n}^{\\backslash i})|\\bf z\\rm_{1:n}^{\\backslash i}) = \\frac{n_{k}^{\\backslash i}}{n-1+\\alpha} \\\\\n",
    "      p(z_{i} \\not\\in K^{+}\\bf(z\\rm_{1:n}^{\\backslash i})|\\bf z\\rm_{1:n}^{\\backslash i}) = \\frac{\\alpha}{n-1+\\alpha} \\tag{6}\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "となり、(6)の定式化を中華料理店過程と言います。\n",
    "\n",
    "結局、(6)より$z_{i}$のサンプリング確率は\n",
    "\n",
    "\\begin{equation}  \n",
    "p(z_{i}=k|\\bf x\\rm_{1:n},\\bf z\\rm_{1:n}^{\\backslash i}) =\n",
    "  \\begin{cases}\n",
    "      p(\\bf x\\rm_{i}|\\bf \\theta_{z_\\rm{i}})\\frac{n_{k}^{\\backslash i}}{n-1+\\alpha}& \\quad \\text{if } k\\in K^{+}(z_{1:n}^{\\backslash i}) \\\\\n",
    "      p(\\bf x\\rm_{i}|\\bf \\theta_{z_\\rm{i}})\\frac{\\alpha}{n-1+\\alpha} \\tag{7}\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "となります。\n",
    "  \n",
    "**中華料理店過程の模式図**\n",
    "![title](https://www.researchgate.net/profile/Timothy_Odonnell/publication/38005164/figure/fig2/AS:293881708724225@1447078267743/A-series-of-possible-distributions-generated-by-the-Chinese-restaurant-process-Shown-is.png)\n",
    "\n",
    "### ⅲ. ディリクレ過程\n",
    "1.のchinese restaurant processの背後には**ディリクレ過程**と呼ばれる確率過程が存在します。これを\n",
    "\\begin{equation}\n",
    "    G \\sim DP\\bigl(\\alpha, H_{0}(\\bf \\theta \\rm|\\eta)\\bigr) \\tag{8}\n",
    "\\end{equation}\n",
    "と表現します。この式の$\\alpha$を集中度パラメータ、$H_{0}(\\bf \\theta|\\rm \\eta)$を基底分布と呼び、この基底分布は無限次元の離散分布になっています。\n",
    "これは$\\theta$の生成過程として定義でき、基底分布と集中度パラメータに応じて$\\theta$が生成されます。このディリクレ過程の構成方法の1つとして前述した中華料理店過程があります。\n",
    "他にも、棒折り過程と呼ばれる方法でディリクレ過程を構成することもできます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Nested and Franchise\n",
    "## a. Chinese Restaurant Franchise Process\n",
    "### i. 階層ディリクレ過程\n",
    "前述したディリクレ過程では1人のユーザーに対して、1つのトピックしか生成できませんので、Latent Dirichlet Allocation(LDA)のように1人のユーザーに複数のトピックを持つようなモデルでは対応することができません。\n",
    "そこでディリクレ過程を階層化した**階層ディリクレ過程**を用いることで対応することができます。階層ディリクレ過程の生成過程は以下の通りです。\n",
    "\\begin{equation}\n",
    "    G_{0} \\sim DP(\\alpha, H) \\\\\n",
    "    G_{i} \\sim DP(\\alpha^{\\prime}, G_{0}) \\tag{9}\n",
    "\\end{equation}\n",
    "(9)の意味するところは$G_{0}$をディリクレ過程から生成し、さらに$G_{0}$からユーザー単位でディリクレ過程を生成することでLDAのような1人が複数のトピックを持つ状況に対応しています。\n",
    "\n",
    "### ⅱ. 中華料理店フランチャイズ過程\n",
    "階層ディリクレ過程は**中華料理店フランチャイズ過程**で構成することができます。\n",
    "中華料理店フランチャイズ過程は以下の3つの事前分布でトピックを生成します。\n",
    "- ユーザーごとの既存のトピックを生成する確率\n",
    "- ユーザーごとの新しいトピックを生成する確率(他のユーザーでは同じトピックが生成済み)\n",
    "- ユーザー全体の全く新しいトピックを生成する確率  \n",
    "\n",
    "これらの事前確率はユーザーごとのパラメータとグローバルのパラメータが階層的に共有されています。  \n",
    "この3つの事前分布を数式として書き下すと以下のようになります。\n",
    "\\begin{equation}  \n",
    "p(z_{dn}=k|\\bf x, \\rm \\alpha,\\beta) \\sim\n",
    "  \\begin{cases}\n",
    "      \\frac{n_{k}^{d}}{n^{d}+\\alpha} + \\frac{\\alpha}{n^{d}+\\alpha}\\frac{n_{k}}{n + \\beta} \\quad \\text{if ユーザーの既存トピック} \\\\\n",
    "      \\frac{\\alpha}{n^{d}+\\alpha}\\frac{n_{k}}{n + \\beta} \\quad \\text{if ユーザーの新トピック} \\\\\n",
    "      \\frac{\\alpha}{n^{d}+\\alpha}\\frac{\\beta}{n + \\beta} \\quad \\text{if 全体の新トピック} \\\\ \\tag{10}\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "なお、$k$はトピック、$n$はグローバルのレコード数、$n^{u}$はユーザーuのレコード数、$\\alpha$はユーザ単位の集中度パラメータ、$\\beta$はグローバルでの集中度パラメータになります。\n",
    "(10)を見ると、ユーザーのパラメータとグローバルのパラメータが共有されている事がわかり、階層モデルを構成していることが確認できます。  \n",
    "また、「ユーザーの既存トピック」 > 「ユーザーの新トピック」 > 「全体の新トピック」の順で事前確率が高いです。\n",
    "\n",
    "**中華料理店フランチャイズ過程の模式図**\n",
    "![title](https://www.researchgate.net/publication/221404031/figure/fig1/AS:340512163811332@1458195834587/The-recurrent-Chinese-restaurant-franchise-RCRF-precoces-The-figure-shows-a.png)\n",
    "\n",
    "\n",
    "\n",
    "## b. Latent Dirichlet Allocation(LDA)について\n",
    "### ⅰ. LDAを用いるモチベーション\n",
    "トピック分析に用いる手法として、一般的なクラスタリング法であるk-means法や混合多項分布モデルなどが用いられますが、これらの手法は1人のユーザーが1つだけのトピックを持つと仮定しています。しかし、1人のユーザーは様々なトピックに基づいて行動を行います。例えば買い物行動を例に取ると食品や衣料品やアウトドア用品を買ったりなど1人のユーザーが様々な行動を取ります。この場合1人のユーザーが1つのトピックを持つと仮定した場合「食品×衣料品」や「衣料品×アウトドア用品」などの組み合わせトピックを用意する必要があります。仮に食品や衣料品などを独立したトピックとしたとき、独立したトピックが10個あれば、55個のトピックを用意する必要があります。  \n",
    "しかし、LDAは1人につき1つだけトピックを持つという仮定を緩和してユーザーが複数のトピックを持つことを許したモデルです。トピックモデルはユーザーごとにトピック分布$\\bf \\theta_{d}\\rm =(\\theta_{d1},\\theta_{d2},\\cdots,\\theta_{dk})$を持つことで少ないトピックでユーザの多様な行動を表現することができます。\n",
    "\n",
    "### ⅱ. LDAのベイズ的生成過程\n",
    "LDAはベイズモデルの一種であり、パラメータに対してディリクレ事前分布を持ちます。パラメータは主に2つ存在し、前述したユーザーに対するトピック分布と場所に対するそれぞれのトピック$k$に関する場所分布です。LDAのベイズ的な生成過程は以下のようになります。\n",
    "\n",
    "#### LDAの生成過程\n",
    "- For トピック $k=1,\\cdots,K$  \n",
    "    (a) 場所分布を生成 $\\phi_{k} \\sim Dirichlet(\\beta)$  \n",
    "  \n",
    "  \n",
    "- For ユーザー $d=1,\\cdots,D$  \n",
    "    (a) トピック分布を生成 $\\theta_{d} \\sim Dirichlet(\\alpha)$    \n",
    "    - For 場所 $n=1,\\cdots,N_{d}$  \n",
    "    (a) トピックを生成 $z_{dn} \\sim Categorical(\\theta_{d})$  \n",
    "    (b) 場所を生成 $w_{dn} \\sim Categorical(\\phi_{z_{dn}})$  \n",
    "  \n",
    "この生成過程はユーザーのトピック分布からトピックを生成され、生成されたトピックに応じて行く場所を決定するというモデルになります。なおLDAの基本的なモデルは場所の行った順番は考慮していないことに考慮してください。(順番も考慮するモデルもあります。)  \n",
    "LDAの概念図は以下の画像を参照してください。(もともと自然言語処理のために開発された経緯があるので、例が自然言語処理です。)\n",
    "![title](https://blog.albert2005.co.jp/wp-content/uploads/2015/09/topic_v2.png)\n",
    "\n",
    "また、パラメータに対して事前分布を置かないモデルも存在し、確率的潜在的意味解析(PLSA)と呼ばれます。\n",
    "\n",
    "### ⅲ. LDAのグラフィカルモデル\n",
    "LDAのグラフィカルモデルは以下のようになります。\n",
    "![title](http://drive.google.com/uc?export=download&id=1uPP6u_qeke685hy05VOJSV_bvAiBFqsH)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## c. Nested Chinese Restaulant Franchise model\n",
    "### i. トピックの階層化\n",
    "通常、Latent Dirichlet Allocationは並列的にトピックが構成されており、通常トピック間に相関を考慮していません。しかし、あるトピックが他のトピックに似ているという仮定をモデルに加えたい場合もあるでしょう。トピック間の相関を組み込む方法は複数ありますが、ここでは階層的にトピックを構成することにします。\n",
    "階層化したトピックは以下のようになります。\n",
    "\n",
    "![title](https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/2f14e3b459dc78868851c372ae00a74519c3e1f4/7-Figure2-1.png)\n",
    "\n",
    "\n",
    "### ⅱ. 入れ子型中華料理店フランチャイズ過程\n",
    "階層的にトピックを構成する際のモデル化として事前にトピックを決め打ちすることもできますが、1階層目はともかく2階層目は1階層目のトピック1つ1つに対してトピック数を決めなければならず、人手で決め打ちするのは困難になってきます。さらに深い階層が必要であればなおさらです。\n",
    "この問題に対して、階層構造を生成する確率過程として**nested Chinese Restaulant Process**と呼ばれるモデルがあります。これは名前の通り中華料理店過程を拡張したものです。このモデルはユーザーがトピックを持つとは仮定せず、**ユーザーが1つのノードパスを持つ**ことを仮定してモデルを構成することで階層的にトピックを構成することができます。  \n",
    "しかし、このnested Chinese Restaulant Processでは中華料理店過程と同じように1人のユーザーが1つのノードしか持つことができません。そこでnested Chinese Restaulant ProcessとChinese Restaulant Franchiseを組み合わせることで新たな確率モデルである**nested Chinese Restaulant Franchise**を構成します。  \n",
    "\n",
    "### ⅲ. 事前分布の構成\n",
    "nested Chinese Restaulant Franchiseは親ノード$v$から子ノード$w$が生成される確率を事前確率として定式化します。\n",
    "#### 1階層目から2階層目へのノードの生成\n",
    "親ノードを$v_{1}$、子ノードを$w_{1, k}$として\n",
    "\\begin{equation}  \n",
    "p(v_{1} \\to w_{1, k}) \\sim\n",
    "  \\begin{cases}\n",
    "      \\frac{n_{w_{1, k}}^{d}}{n^{d}+\\alpha} + \\frac{\\alpha}{n^{d}+\\alpha}\\frac{n_{w_{1, k}}}{n + \\beta} \\quad \\text{if ユーザーの既存ノード} \\\\\n",
    "      \\frac{\\alpha}{n^{d}+\\alpha}\\frac{n_{w_{1, k}}}{n + \\beta} \\quad \\text{if ユーザーの新ノード} \\\\\n",
    "      \\frac{\\alpha}{n^{d}+\\alpha}\\frac{\\beta}{n + \\beta} \\quad \\text{if 全体の新ノード} \\\\ \\tag{10}\n",
    "  \\end{cases}\n",
    "\\end{equation}  \n",
    "\n",
    "となります。1階層目が1つのノードしか持たないためChinese Restaulant Franchiseと同じ構成となります。\n",
    "\n",
    "#### 2階層目から3階層目へのノードの生成\n",
    "上記で生成した子ノード$w_{1, k}$を親ノード$v_{2, k}$とし、その子ノードを$w_{2, k^{\\prime}}$とし、\n",
    "\n",
    "\\begin{equation}  \n",
    "p(v_{2, k} \\to w_{2, k^{\\prime}}) \\sim\n",
    "  \\begin{cases}\n",
    "      \\frac{n_{vw}^{d}}{n_{v}^{d}+\\alpha} + \\frac{\\alpha}{n_{v}^{d}+\\alpha}\\frac{n_{vw}}{n_{v} + \\beta} \\quad \\text{if } w \\in C^{d}(v) \\\\\n",
    "      \\frac{\\alpha}{n_{v}^{d}+\\alpha}\\frac{n_{vw}}{n_{v} + \\beta} \\quad \\text{if } w \\not\\in C^{d}(v) \\text{ and } w \\in C(v) \\\\\n",
    "      \\frac{\\alpha}{n_{v}^{d}+\\alpha}\\frac{\\beta}{n_{v} + \\beta} \\quad \\text{if } w \\not\\in C(v) \\\\ \\tag{11}\n",
    "  \\end{cases}\n",
    "\\end{equation}  \n",
    "\n",
    "となります(ノードの添字は省略)。この事前分布を用いることで2階層目の特定の親ノードから子ノードをユーザーごとに生成していくことが可能となります。\n",
    "この事前分布に尤度関数の積を取ると階層構造のある任意のノンパラメトリックベイズな統計・機械学習モデルを作成することができます。\n",
    "\n",
    "**nested Chinese Restaulant Franchiseの模式図**\n",
    "    ![title](https://yahoo.jp/box/-P_grR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####データの生成####\n",
    "##データの設定\n",
    "geo = 2\n",
    "levels = 2\n",
    "k1 = 5\n",
    "k2 = np.array([4, 4, 5, 5, 6])\n",
    "topic = 15\n",
    "hh = 3500\n",
    "v = 1000   #語彙数\n",
    "Lambda = np.random.gamma(15.0, 1/0.25, hh)\n",
    "pt = np.random.poisson(Lambda, hh); pt[pt < 10] = 10\n",
    "pt_vec = pt[:, np.newaxis]\n",
    "N = np.sum(pt)\n",
    "w = np.random.poisson(np.random.gamma(10.0, 1/0.75, N)); w[w < 5] = 5\n",
    "f = np.sum(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##IDとインデックスを作成\n",
    "#IDを作成\n",
    "u_id = np.repeat(np.arange(hh), pt)\n",
    "d_id = np.repeat(np.arange(N), w)\n",
    "\n",
    "#インデックスを作成\n",
    "u_list = [i for i in range(hh)]\n",
    "d_list = [i for i in range(N)]\n",
    "d_vec = [i for i in range(N)]\n",
    "for i in range(hh):\n",
    "    u_list[i] = np.array(np.where(u_id==i)[0], dtype=\"int\")\n",
    "for i in range(N):\n",
    "    d_list[i] = np.array(np.where(d_id==i)[0], dtype=\"int\")\n",
    "    d_vec[i] = np.repeat(1, d_list[i].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####パラメータとデータの生成####\n",
    "rp = 0\n",
    "while True:\n",
    "    rp = rp + 1\n",
    "    print(rp)\n",
    "    \n",
    "    ##ノード分布を生成\n",
    "    #グローバルノード分布を生成\n",
    "    G1 = np.random.dirichlet(np.repeat(3.0, k1), 1).reshape(-1)\n",
    "    G2 = [np.random.dirichlet(np.repeat(2.5, k2[j]), 1).reshape(-1)  for j in range(k1)]\n",
    "    GT1 = G1.copy(); GT2 = G2.copy()\n",
    "\n",
    "    #ローカルノード分布を生成\n",
    "    alpha1 = 2.0\n",
    "    theta1 = np.random.dirichlet(alpha1*G1, hh)\n",
    "    theta2 = [np.random.dirichlet(alpha1*G2[j], hh) for j in range(k1)]\n",
    "    thetat1 = theta1.copy(); thetat2 = theta2.copy()\n",
    "\n",
    "    \n",
    "    ##モデルパラメータを生成\n",
    "    #トピック分布を生成\n",
    "    er = 0.01\n",
    "    alpha2 = 2.5\n",
    "    gamma_global = np.zeros((k1, topic))\n",
    "    gamma = [j for j in range(k1)]\n",
    "    for j in range(k1):\n",
    "        gamma_global[j, ] = np.random.dirichlet(np.repeat(0.3, topic), 1)\n",
    "        gamma[j] = np.random.dirichlet(alpha2*gamma_global[j, ]+er, k2[j])\n",
    "    gammat_global = gamma_global.copy()\n",
    "    gammat = gamma.copy()\n",
    "\n",
    "    #location分布を生成\n",
    "    min_point = -7.5; max_point = 7.5\n",
    "    target_range = np.array([-2.75, 2.75])\n",
    "    longitude = np.array([min_point, max_point]); latitude = np.array([min_point, max_point])\n",
    "    mu_global = np.append(np.random.uniform(longitude[0], longitude[1], k1), \n",
    "                          np.random.uniform(latitude[0], latitude[1], k1)).reshape(k1, geo, order=\"F\")\n",
    "    mu = [i for i in range(k1)]\n",
    "    Cov = [i for i in range(k1)]\n",
    "    for i in range(k1):\n",
    "        mu0 = np.zeros((k2[i], geo))\n",
    "        Cov0 = np.zeros((geo, geo, k2[i]))\n",
    "        for j in range(k2[i]):\n",
    "            mu0[j, ] = mu_global[i, ] + np.random.uniform(target_range[0], target_range[1], geo)\n",
    "            cov_temp = np.diag(np.random.uniform(0.2, 0.7, geo))\n",
    "            value = np.random.uniform(-0.6, 0.6, 1) * np.prod(np.sqrt(np.diag(cov_temp)))\n",
    "            cov_temp[0, 1] = value; cov_temp[1, 0] = value\n",
    "            Cov0[:, :, j] = cov_temp\n",
    "        mu[i] = mu0\n",
    "        Cov[i] = Cov0\n",
    "    mut_global = mu_global.copy()\n",
    "    mut = mu.copy(); Covt = Cov.copy()\n",
    "\n",
    "    #単語分布を生成\n",
    "    m = 25\n",
    "    beta = np.repeat(0.025, v)\n",
    "    phi = np.random.dirichlet(beta, topic)\n",
    "    index_v = np.array(range(v))[np.max(phi, axis=0) <= (topic*m)/f]\n",
    "    for j in range(index_v.shape[0]):\n",
    "        phi[np.argmax(np.random.multinomial(1, np.repeat(1/topic, topic), 1)), index_v[j]] = (topic*m)/f\n",
    "    phi = phi / np.sum(phi, axis=1).reshape(topic, 1)\n",
    "    phit = phi.copy()\n",
    "\n",
    "\n",
    "    ##潜在変数を生成\n",
    "    #多項分布から潜在ノードを生成\n",
    "    R1 = rmnom(theta1[u_id, ], N, k1, 1)[1]\n",
    "    r1 = np.dot(R1, np.arange(k1))\n",
    "    R2 = np.zeros((N, np.max(k2)), dtype=\"int8\")\n",
    "    r2 = np.repeat(0, N)\n",
    "    index_r1 = [j for j in range(k1)]\n",
    "    n = np.repeat(0, k1)\n",
    "    for j in range(k1):\n",
    "        index_r1[j] = np.array(np.where(r1==j)[0], dtype=\"int\")\n",
    "        n[j] = index_r1[j].shape[0]\n",
    "        R2[index_r1[j], :k2[j]] = rmnom(theta2[j][u_id[index_r1[j]], ] ,n[j], k2[j], 1)[1]\n",
    "        r2[index_r1[j]] = np.dot(R2[index_r1[j], :k2[j]], np.arange(k2[j]))\n",
    "    r = np.array(np.hstack((r1[:, np.newaxis], r2[:, np.newaxis])), dtype=\"int16\")\n",
    "\n",
    "    #トピック分布を生成\n",
    "    r_vec = r[d_id, ]\n",
    "    index_r2 = [j for j in range(k1)]\n",
    "    gamma_dt = np.zeros((f, topic))\n",
    "    for j in range(k1):\n",
    "        index_r2[j] = np.array(np.where(r_vec[:, 0]==j)[0], dtype=\"int\")\n",
    "        gamma_dt[index_r2[j], ] = gamma[j][r_vec[index_r2[j], 1], ]\n",
    "\n",
    "    #多項分布からトピックを生成\n",
    "    out = rmnom(gamma_dt, f, topic, 1)\n",
    "    Z = out[1]\n",
    "    z_vec = np.array(out[0], dtype=\"int16\")\n",
    "\n",
    "\n",
    "    ##データを生成\n",
    "    #多変量正規分布からlocationを生成\n",
    "    no = np.arange(N)\n",
    "    y = np.zeros((N, geo))\n",
    "    for i in range(k1):\n",
    "        index1 = index_r1[i]\n",
    "        for j in range(k2[i]):\n",
    "            index2 = np.where(r[index1, 1]==j)[0]\n",
    "            y[index1[index2], ] = np.random.multivariate_normal(mu[i][j, ], Cov[i][:, :, j], index2.shape[0])\n",
    "\n",
    "    #多項分布から単語を生成\n",
    "    wd = np.array(np.repeat(0, f), dtype=\"int16\")\n",
    "    for i in range(N):\n",
    "        index = d_list[i]\n",
    "        wd[index] = rmnom(phi[z_vec[index], ], w[i], v, 0)\n",
    "\n",
    "    #単語がすべて生成されればbreak\n",
    "    if np.unique(wd).shape[0]==v:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locatio分布を可視化\n",
    "colorlist = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]\n",
    "fig = plt.figure(figsize=(12.0, 6.0))\n",
    "for j in range(k1):\n",
    "    index = index_r1[j]\n",
    "    ax = fig.add_subplot(2, 3, j+1)\n",
    "    ax.scatter(y[index, 0], y[index, 1], s=1, c=colorlist[j], alpha=0.25, linewidths=\"1\", edgecolors=colorlist[j])\n",
    "    plt.title(\"location point\", fontsize=12.5)\n",
    "    plt.xlabel(\"longitude\")\n",
    "    plt.ylabel(\"latitude\")\n",
    "ax = fig.add_subplot(2, 3, k1+1)\n",
    "ax.scatter(y[:, 0], y[:, 1], s=1, c=colorlist[k1+1], alpha=0.25, linewidths=\"1\", edgecolors=colorlist[k1+1])\n",
    "plt.title(\"location point\", fontsize=12.5)\n",
    "plt.xlabel(\"longitude\")\n",
    "plt.ylabel(\"latitude\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#単語のインデックスを作成\n",
    "wd_list = [i for i in range(v)]\n",
    "wd_vec = [i for i in range(v)]\n",
    "word_freq = np.repeat(0, v)\n",
    "for i in range(v):\n",
    "    wd_list[i] = np.array(np.where(wd==i)[0], dtype=\"int\")\n",
    "    wd_vec[i] = np.repeat(1, wd_list[i].shape[0])\n",
    "    word_freq[i] = wd_list[i].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. User Tracking and Document model\n",
    "## a. モデル概要\n",
    "nested Chinese Restaulant Franchiseを用いて、統計モデルの実装を行います。\n",
    "モデルとして、ユーザーが訪れた場所とそこで行ったtweetの同時分布のトピックモデルを考えます。つまりユーザーが訪れた場所によってtweetの内容が変化すると仮定したモデルになります。  \n",
    "例えば、場所を階層構造に拡張することでいえば、東京を親ノードとした場合、その子ノードに渋谷、新宿などの地域をさらにこの子ノードを親として、例えば渋谷なら代々木や原宿や渋谷周辺などというような子ノードを生成することで階層構造の場所分布を自動的に抽出することが可能になります。  \n",
    "tweetは生成されたノードそれぞれで固有のトピック分布を持つことで場所ごとにどのようなトピックの単語が現れやすいかを解析することができます。  \n",
    "  \n",
    "nested Chinese Restaulant Franchiseの仮定に基づき、ユーザーごとにノード構造が異なると仮定しますが、ユーザー全体では同じノード構造を共有しています。さらにそれぞれのノードには場所とtweetのトピック分布に対する異なるパラメータを持っており、これらのパラメータは親ノードのパラメータを共有することで子ノード同士が相関を持つ構造になっています。  \n",
    "つまり、globalなノード分布が$G_{0} \\sim DP(\\alpha, H)$から生成され、ユーザーごとのlocalなノード分布が$G_{u} \\sim DP(\\beta, G_{0})$から生成されるイメージです。\n",
    "\n",
    "![title](https://yahoo.jp/box/-P_grR)\n",
    "\n",
    "\n",
    "参考にした論文は以下のurlにあります。  \n",
    "http://proceedings.mlr.press/v28/ahmed13.pdf\n",
    "\n",
    "## b. 生成過程\n",
    "上記で議論したモデルの生成過程は以下の通りです。\n",
    "#### 生成過程\n",
    "- For each tweet $d$ written by user $u$\n",
    "    - (a) Sample a node $r_{d} \\sim nCRF(\\alpha, \\beta, u)$ \n",
    "    - (b) If node $r_{d}$ is a globally new node theta\n",
    "        - ⅰ. $\\mu_{r_{d}} \\sim N(\\mu_{\\pi(r_{d})}, \\Sigma_{\\pi(r_{d})})$\n",
    "        - ⅱ. $\\phi_{r_{d}} \\sim Dirichlet(\\omega\\phi_{\\pi(r_{d})})$\n",
    "        - ⅲ. $\\theta_{r_{d}} \\sim Dirichlet(\\lambda\\theta_{\\pi(r_{d})})$\n",
    "    - (c) Sample a location $l_{d} \\sim N(\\mu_{r_{d}}, \\Sigma_{r_{d}})$\n",
    "    - (d) For each word $w_{d, i}$\n",
    "        - ⅰ. Sample a topic $z_{d, i} \\sim Categorical(\\theta_{r_{d}})$\n",
    "        - ⅱ. Sample a word $w_{d, i} \\sim Categorical(\\phi_{z_{d, i}})$ \n",
    "          \n",
    "なお生成過程中に現れる$\\pi(*)$は親ノードの分布を表しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####マルコフ連鎖モンテカルロ法でパラメータを推定####\n",
    "##多変量正規分布の密度関数\n",
    "def dmv(x, mu, Cov, k):\n",
    "    er = x - mu\n",
    "    Cov_inv = np.linalg.inv(Cov) \n",
    "    LLo = 1 / (np.sqrt(pow((2 * np.pi), k) * np.linalg.det(Cov))) * np.exp(-1/2 * np.dot(np.dot(er, Cov_inv) *er, np.ones(k)))\n",
    "    return(LLo)\n",
    "\n",
    "##アルゴリズムの設定\n",
    "max_k1 = 7\n",
    "R = 2000\n",
    "keep = 2\n",
    "burnin = int(500/keep)\n",
    "iter = 0\n",
    "disp = 10\n",
    "target_iter = 50\n",
    "sample_rate = np.repeat(1/N, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##事前分布の設定\n",
    "#nCRFの集中度パラメータ\n",
    "alpha1 = 0.25; beta1 = 0.25\n",
    "alpha2 = 0.25; beta2 = 0.5\n",
    "\n",
    "#モデルパラメータの事前分布\n",
    "Deltabar = np.repeat(0.0, geo)\n",
    "ADelta = 0.01\n",
    "nu = geo + 1\n",
    "V = nu * np.diag(np.ones(geo))\n",
    "pi1 = 0.25\n",
    "pi2 = 0.1\n",
    "pi3 = 0.01\n",
    "\n",
    "#パラメータサンプリング時の誤差\n",
    "delta0 = np.repeat(0.0, geo)\n",
    "tau0 = np.diag(np.repeat(0.5, geo))\n",
    "omega0 = 2.5\n",
    "er0 = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##パラメータの真値\n",
    "#ノード構造の真値\n",
    "levels = 2\n",
    "k1 = 5\n",
    "k2 = np.array([4, 4, 5, 5, 6])\n",
    "\n",
    "#潜在変数の真値\n",
    "Ri1 = np.array(R1.copy(), dtype=\"int\")\n",
    "r1 = np.dot(Ri1, np.arange(k1))\n",
    "Ri2 = np.array(R2.copy(), dtype=\"int\")\n",
    "r2 = np.dot(Ri2, np.arange(np.max(k2)))\n",
    "r = np.hstack((r1[:, np.newaxis], r2[:, np.newaxis]))\n",
    "Zi = Z.copy()\n",
    "z = np.dot(Zi, np.arange(topic))\n",
    "\n",
    "#モデルパラメータの真値\n",
    "G1 = GT1.copy(); G2 = GT2.copy()\n",
    "theta1 = thetat1.copy(); theta2 = thetat2.copy()\n",
    "gamma_global = gammat_global.copy()\n",
    "gamma = gammat.copy()\n",
    "mu = mut.copy(); Cov = Covt.copy()\n",
    "phi = phit.copy()\n",
    "\n",
    "#location分布の真値\n",
    "mu_global = mut_global.copy()\n",
    "Cov_global = np.zeros((geo, geo, k1))\n",
    "for j in range(k1):\n",
    "    index = np.array(np.where(Ri1[:, j]==0)[0], dtype=\"int\")\n",
    "    er = y[index, ] - mu_global[j, ]\n",
    "    Cov_global[:, :, j] = np.dot(er.T, er) / index.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##初期値の設定\n",
    "#ノード構造の初期値\n",
    "levels = 2\n",
    "k1 = 3\n",
    "k2 = np.repeat(1, k1)\n",
    "\n",
    "#モデルパラメータの初期値\n",
    "alpha01 = 2.0; alpha02 = 2.5\n",
    "G1 = np.random.dirichlet(np.repeat(5.0, k1), 1).reshape(-1)\n",
    "G2 = [np.random.dirichlet(np.repeat(5.0, k2[j]), 1).reshape(-1)  for j in range(k1)]\n",
    "GT1 = G1.copy(); GT2 = G2.copy()\n",
    "theta1 = np.random.dirichlet(alpha01*G1, hh)\n",
    "theta2 = [np.random.dirichlet(alpha01*G2[j], hh) for j in range(k1)]\n",
    "gamma_global = np.random.dirichlet(np.repeat(5.0, topic), k1)\n",
    "gamma = [gamma_global[j, ] for j in range(k1)]\n",
    "mu_global = np.zeros((k1, geo))\n",
    "Cov_global = np.zeros((geo, geo, k1))\n",
    "for j in range(k1):\n",
    "    mu_global[j, ] = np.random.multivariate_normal(np.mean(y, axis=0), np.diag(np.repeat(25.0, geo)), 1)\n",
    "    Cov_global[:, :, j] = np.diag(np.repeat(0.25, geo))\n",
    "mu = [mu_global[j, ] for j in range(k1)]\n",
    "Cov = [Cov_global[:, :, np.array([j])] for j in range(k1)]\n",
    "phi = np.random.dirichlet(np.repeat(5.0, v), topic)\n",
    "\n",
    "#潜在ノードの初期値\n",
    "Ri1 = np.array(rmnom(theta1[u_id, ], N, k1, 1)[1], dtype=\"int8\")\n",
    "r1 = np.dot(Ri1, np.arange(k1))\n",
    "Ri2 = np.zeros((N, np.max(k2)), dtype=\"int8\")\n",
    "r2 = np.repeat(0, N)\n",
    "index_r1 = [j for j in range(k1)]\n",
    "for j in range(k1):\n",
    "    index = np.array(np.where(Ri1[:, j]==1)[0], dtype=\"int\")\n",
    "    n = index.shape[0]\n",
    "    Ri2[index, :k2[j]] = np.array(rmnom(theta2[j][u_id[index], ], n, k2[j], 1)[1], dtype=\"int8\")\n",
    "    r2[index] = np.dot(R2[index, :k2[j]], np.arange(k2[j]))\n",
    "\n",
    "#トピックの初期値\n",
    "out = rmnom(np.full((f, topic), 1/topic), f, topic, 1)\n",
    "Zi = np.array(out[1], dtype=\"int8\")\n",
    "z_vec = np.array(out[0], dtype=\"int16\")\n",
    "\n",
    "old_setting = np.seterr(divide='raise', invalid='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##nCRFのグローバルノードとローカルノードの頻度を定義\n",
    "#パラメータの格納用配列\n",
    "M1 = np.sum(Ri1, axis=0)\n",
    "M2 = [i for i in range(k1)]\n",
    "m1 = np.zeros((hh, k1), dtype=\"int\")\n",
    "m2 = [np.zeros((hh, k2[i]), dtype=\"int\") for i in range(k1)]\n",
    "\n",
    "#グローバルノードの頻度\n",
    "freq = np.dot(Ri2.T, Ri1).T\n",
    "for j in range(k1):\n",
    "    M2[j] = freq[j, ][:k2[j]]\n",
    "    \n",
    "#ローカルノードの頻度\n",
    "for i in range(hh):\n",
    "    index = u_list[i]\n",
    "    m1[i, ] = np.sum(Ri1[index, ], axis=0)\n",
    "    freq = np.dot(Ri2[index, ].T, Ri1[index, ]).T\n",
    "    for j in range(k1):\n",
    "        m2[j][i, ] = freq[j, ][:k2[j]]\n",
    "        \n",
    "#階層的事前分布を定義\n",
    "Prior1 = m1/(pt_vec+alpha1) + alpha1/(pt_vec+alpha1)*M1/(N+beta1); Prior1 = np.hstack((Prior1, 1-np.sum(Prior1, axis=1)[:, np.newaxis]))\n",
    "Prior2 = [j for j in range(k1)]\n",
    "for j in range(k1):\n",
    "    freq = np.sum(m2[j], axis=1)[:, np.newaxis]\n",
    "    Prior2[j] = m2[j]/(freq+alpha2) + alpha2/(freq+alpha2)*M2[j]/(np.sum(M2[j])+beta2)\n",
    "    Prior2[j] = np.hstack((Prior2[j], 1-np.sum(Prior2[j], axis=1)[:, np.newaxis]))\n",
    "    \n",
    "#文書ごとのトピック頻度を数える\n",
    "z_freq = np.zeros((N, topic), dtype=\"int\")\n",
    "for i in range(N):\n",
    "    z_freq[i, ] = np.dot(Zi[d_list[i], ].T, d_vec[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##パラメータの格納用配列\n",
    "#モデルパラメータの格納用配列\n",
    "MU1 = [j for j in range(int(R/keep))]\n",
    "MU2 = [j for j in range(int(R/keep))]\n",
    "COV1 = [j for j in range(int(R/keep))]\n",
    "COV2 = [j for j in range(int(R/keep))]\n",
    "GAMMA1 = [j for j in range(int(R/keep))]\n",
    "GAMMA2 = [j for j in range(int(R/keep))]\n",
    "PHI = np.zeros((topic, v, int(R/keep)))\n",
    "\n",
    "#潜在変数の格納用配列\n",
    "SEG1 = np.zeros((N, int(R/keep)), dtype=\"int8\")\n",
    "SEG2 = np.zeros((N, int(R/keep)), dtype=\"int\")\n",
    "TOPIC = np.zeros((f, topic), dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##学習データの真値の対数尤度\n",
    "#ノード構造の真値\n",
    "levels0 = 2\n",
    "k01 = 5\n",
    "k02 = np.array([4, 4, 5, 5, 6])\n",
    "\n",
    "#locationの対数尤度\n",
    "LL01 = 0\n",
    "for i in range(k01):\n",
    "    index = np.array(np.where(R1[:, i])[0], dtype=\"int\")\n",
    "    Lho_dmv = np.zeros((index.shape[0], k02[i]))\n",
    "    for j in range(k02[i]):\n",
    "        Lho_dmv[:, j] = dmv(y[index, ], mut[i][j, ], Covt[i][:, :, j], geo)\n",
    "    LL01 += np.sum(np.log(np.sum(thetat2[i][u_id[index], ] * Lho_dmv, axis=1)))\n",
    "print(LL01)\n",
    "\n",
    "#トピックモデルの対数尤度\n",
    "R_vec01 = R1[d_id, ]; R_vec02 = R2[d_id, ]\n",
    "r_vec02 = np.dot(R_vec02, np.arange(np.max(k02)))\n",
    "Lho_topic = np.zeros((f, topic))\n",
    "for j in range(k01):\n",
    "    index = np.array(np.where(R_vec01[:, j]==1)[0], dtype=\"int\")\n",
    "    Lho_topic[index, ] = gammat[j][r_vec02[index], ] * (phit.T)[wd[index], ]\n",
    "LL02 = np.sum(np.log(np.sum(Lho_topic, axis=1)))\n",
    "print(LL02)\n",
    "\n",
    "#対数尤度の和\n",
    "LL0 = LL01 + LL02\n",
    "print(LL0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####ギブスサンプリングでパラメータをサンプリング####\n",
    "for rp in range(R):\n",
    "    \n",
    "    ##level1のノードをサンプリング\n",
    "    #新しいパラメータをサンプリング\n",
    "    if k1 <= max_k1:\n",
    "        k_level1 = k1 + 1\n",
    "        target = np.argmax(np.random.multinomial(1, sample_rate, 1))\n",
    "        mu_new = np.vstack((mu_global, y[target, ] + np.random.multivariate_normal(delta0, tau0, 1)))\n",
    "        Cov_new = np.zeros((geo, geo, k1+1))\n",
    "        Cov_new[:, :, :k1] = Cov_global; Cov_new[:, :, k1] = np.diag(np.repeat(0.5, geo))\n",
    "        gamma0 = np.sum(Zi[d_list[target], ], axis=0) / w[target]\n",
    "        gamma_new = np.vstack((gamma_global, np.random.dirichlet(omega0*gamma0 + er0, 1)))\n",
    "    else:\n",
    "        k_level1 = mu_global.shape[0]\n",
    "        mu_new = mu_global.copy()\n",
    "        Cov_new = Cov_global.copy()\n",
    "        gamma_new = gamma_global.copy()\n",
    "\n",
    "    #同時分布の尤度を定義\n",
    "    Lho11 = np.zeros((N, k_level1))\n",
    "    for i in range(k_level1):\n",
    "        Lho11[:, i] = dmv(y, mu_new[i, ], Cov_new[:, :, i], geo)\n",
    "    Lho11[np.isnan(Lho11)] = 0\n",
    "    Lho12 = np.exp(np.dot(z_freq, np.log(gamma_new).T))\n",
    "    Lho1 = Prior1[u_id, ] * Lho11 * Lho12\n",
    "    \n",
    "    #多項分布からノードをサンプリング\n",
    "    Prob1 = Lho1 / np.sum(Lho1, axis=1)[:, np.newaxis]\n",
    "    out1 = rmnom(Prob1, N, k_level1, 1)\n",
    "    Ri1 = np.array(out1[1], dtype=\"int\")\n",
    "    \n",
    "    #出現があるノードのみ採択\n",
    "    index_k1 = np.array(np.where(np.sum(Ri1, axis=0) > 0)[0], dtype=\"int\")\n",
    "    Ri1 = Ri1[:, index_k1]\n",
    "    r1 = np.dot(Ri1, np.arange(index_k1.shape[0]))\n",
    "    if index_k1.shape[0] > k1:\n",
    "        k2 = np.append(k2, 1)\n",
    "    k1 = index_k1.shape[0]\n",
    "    \n",
    "        \n",
    "    ##nCRFのグローバルノードとローカルノードの頻度を定義\n",
    "    #パラメータの格納用配列\n",
    "    M1 = np.sum(Ri1, axis=0)\n",
    "    M2 = [i for i in range(k1)]\n",
    "    m1 = np.zeros((hh, k1), dtype=\"int\")\n",
    "    m2 = [np.zeros((hh, k2[i]), dtype=\"int\") for i in range(k1)]\n",
    "    index_r1 = [i for i in range(k1)]\n",
    "    n = np.repeat(0, k1)\n",
    "\n",
    "    #グローバルノードの頻度\n",
    "    freq = np.dot(Ri2.T, Ri1).T\n",
    "    for j in range(k1):\n",
    "        index_r1[j] = np.array(np.where(Ri1[:, j]==1)[0], dtype=\"int\")\n",
    "        n[j] = index_r1[j].shape[0]\n",
    "        M2[j] = freq[j, ][:k2[j]]\n",
    "\n",
    "    #ローカルノードの頻度\n",
    "    for i in range(hh):\n",
    "        index = u_list[i]\n",
    "        m1[i, ] = np.sum(Ri1[index, ], axis=0)\n",
    "        freq = np.dot(Ri2[index, ].T, Ri1[index, ]).T\n",
    "        for j in range(k1):\n",
    "            m2[j][i, ] = freq[j, ][:k2[j]]\n",
    "\n",
    "    #階層的事前分布を定義\n",
    "    alpha11 = alpha1/k1; beta11 = beta1/k1\n",
    "    alpha21 = M1/N * alpha2; beta21 = M1/N * beta2\n",
    "    Prior1 = m1/(pt_vec+alpha11) + alpha11/(pt_vec+alpha11)*M1/(N+beta11)\n",
    "    if k1 <= max_k1:\n",
    "        Prior1 = np.hstack((Prior1, 1-np.sum(Prior1, axis=1)[:, np.newaxis]))\n",
    "    Prior2 = [j for j in range(k1)]\n",
    "    for j in range(k1):\n",
    "        freq = np.sum(m2[j], axis=1)[:, np.newaxis]\n",
    "        Prior2[j] = m2[j]/(freq+alpha21[j]) + alpha21[j]/(freq+alpha21[j])*M2[j]/(np.sum(M2[j])+beta21[j])\n",
    "        Prior2[j] = np.hstack((Prior2[j], 1-np.sum(Prior2[j], axis=1)[:, np.newaxis]))\n",
    "\n",
    "\n",
    "    ##Level1のパラメータをサンプリング\n",
    "    #新しいモデルパラメータ\n",
    "    if k1 > mu_global.shape[0]:\n",
    "        flag = 1\n",
    "    else:\n",
    "        flag = 0\n",
    "\n",
    "    #ノードごとにパラメータを更新\n",
    "    for j in range(k1):\n",
    "        #多変量正規分布から期待値をサンプリング\n",
    "        index = index_r1[j]\n",
    "        y_target = y[index, ] \n",
    "        mu_par = np.sum(y_target, axis=0) / (n[j] + ADelta)\n",
    "        Sigma = np.kron(Cov_new[:, :, j], 1/n[j])\n",
    "        mu_new[j, ] = np.random.multivariate_normal(mu_par, Sigma, 1)\n",
    "\n",
    "        #逆ウィシャート分布から分散共分散行列をサンプリング\n",
    "        er = y_target - mu_new[j, ]\n",
    "        IW_R = np.dot(er.T, er) + V\n",
    "        Sn = n[j] + nu\n",
    "        Cov_new[:, :, j] = scipy.stats.invwishart.rvs(Sn, IW_R, 1)\n",
    "\n",
    "        #ディリクレ分布からトピック分布をサンプリング\n",
    "        wsum = np.sum(z_freq[index, ], axis=0) + pi1\n",
    "        gamma_new[j, ] = np.random.dirichlet(wsum, 1)\n",
    "\n",
    "    #パラメータをコピー\n",
    "    index_target = np.arange(k1)\n",
    "    mu_global = mu_new[index_target, ]\n",
    "    Cov_global = Cov_new[:, :, index_target]\n",
    "    gamma_global = gamma_new[index_target, ]\n",
    "\n",
    "\n",
    "    ##Level2のノードをサンプリング\n",
    "    #新しいパラメータの設定とパラメータの格納用配列を定義\n",
    "    if flag==1:\n",
    "        mu.append(mu_global[np.array([k1-1]), ])\n",
    "        Cov.append(Cov_global[:, :, k1-1].reshape(geo, geo, 1))\n",
    "        gamma.append(gamma_global[np.array([k1-1]), ])\n",
    "    Ri2 = np.zeros((N, np.max(k2)+1), dtype=\"int\")\n",
    "    r2 = np.repeat(0, N)\n",
    "\n",
    "\n",
    "    ##Level2のノードをサンプリング\n",
    "    #パラメータの格納用配列\n",
    "    Lho_dmv = np.zeros((N, np.max(k2)))\n",
    "    Ri2 = np.zeros((N, np.max(k2)+1), dtype=\"int\")\n",
    "\n",
    "    #新しいパラメータをサンプリング\n",
    "    for i in range(k1):\n",
    "        index = index_r1[i]\n",
    "        target = index[np.argmax(np.random.multinomial(1, np.repeat(1/n[i], n[i]), 1))]\n",
    "        mu_new = np.vstack((mu[i], y[target, ] + np.random.multivariate_normal(delta0, tau0, 1)))\n",
    "        Cov_new = np.zeros((geo, geo, k2[i]+1))\n",
    "        Cov_new[:, :, :k2[i]] = Cov[i]; Cov_new[:, :, k2[i]] = np.diag(np.repeat(0.5, geo))\n",
    "        gamma0 = np.sum(Zi[d_list[target], ], axis=0) / w[target]\n",
    "        gamma_new = np.vstack((gamma[i], np.random.dirichlet(gamma0 + er0, 1)))\n",
    "\n",
    "        #同時分布の尤度を定義\n",
    "        Lho21 = np.zeros((n[i], k2[i]+1))\n",
    "        for j in range(k2[i]+1):\n",
    "            Lho21[:, j] = dmv(y[index, ], mu_new[j, ], Cov_new[:, :, j], geo)\n",
    "        Lho21[np.isnan(Lho21)] = 0\n",
    "        Lho22 = np.exp(np.dot(z_freq[index, ], np.log(gamma_new).T))\n",
    "        Lho2 = Prior2[i][u_id[index], ] * Lho21 * Lho22\n",
    "\n",
    "        #多項分布からノードをサンプリング\n",
    "        Prob2 = Lho2 / np.sum(Lho2, axis=1)[:, np.newaxis]\n",
    "        out2 = rmnom(Prob2, n[i], k2[i]+1, 1)\n",
    "        Nord2 = np.array(out2[1], dtype=\"int\")\n",
    "        \n",
    "        #出現があるノードのみ採択\n",
    "        index_k2 = np.array(np.where(np.sum(Nord2, axis=0) > 0)[0], dtype=\"int\")\n",
    "        k2[i] = index_k2.shape[0]\n",
    "        Ri2[index, :k2[i]] = Nord2[:, index_k2]\n",
    "        mu[i] = mu_new[index_k2, ]\n",
    "        Cov[i] = Cov_new[:, :, index_k2]\n",
    "        gamma[i] = gamma_new[index_k2, ]\n",
    "        \n",
    "\n",
    "    #ローカルノードの頻度を更新\n",
    "    k2 = k2[np.arange(k1)]\n",
    "    Ri2 = Ri2[:, np.arange(np.max(k2))]\n",
    "    r2 = np.dot(Ri2, np.arange(np.max(k2)))\n",
    "    freq = np.dot(Ri2.T, Ri1).T\n",
    "    for j in range(k1):\n",
    "        M2[j] = freq[j, ][:k2[j]]\n",
    "\n",
    "\n",
    "    ##ノードごとにlocation分布のパラメータをサンプリング\n",
    "    #多変量正規分布から期待値をサンプリング\n",
    "    for i in range(k1):\n",
    "        index = index_r1[i]\n",
    "        for j in range(k2[i]):\n",
    "            y_target = y[index, ] * Ri2[index, j][:, np.newaxis]\n",
    "            mu_par = np.sum(y_target, axis=0) / (M2[i][j] + ADelta)\n",
    "            Sigma = np.kron(Cov[i][:, :, j], 1/M2[i][j])\n",
    "            mu[i][j, ] = np.random.multivariate_normal(mu_par, Sigma, 1)\n",
    "\n",
    "            #逆ウィシャート分布から分散共分散行列をサンプリング\n",
    "            er = y_target - mu[i][j, ]*Ri2[index, j][:, np.newaxis]\n",
    "            IW_R = np.dot(er.T, er) + V\n",
    "            Sn = M2[i][j, ] + nu\n",
    "            Cov[i][:, :, j] = scipy.stats.invwishart.rvs(Sn, IW_R, 1)\n",
    "\n",
    "\n",
    "    ##ノードごとにトピックをサンプリング\n",
    "    #ノード割当を単語idに割り当てる\n",
    "    R_vec1 = Ri1[d_id, ]; R_vec2 = Ri2[d_id, ]\n",
    "    r_vec2 = np.dot(R_vec2, np.arange(np.max(k2)))\n",
    "\n",
    "    #トピックの割当確率を定義\n",
    "    Lho_topic = np.zeros((f, topic))\n",
    "    index_r2 = [j for j in range(k1)]\n",
    "    for j in range(k1):\n",
    "        index_r2[j] = np.array(np.where(R_vec1[:, j]==1)[0], dtype=\"int\")\n",
    "        Lho_topic[index_r2[j], ] = gamma[j][r_vec2[index_r2[j]], ] * (phi.T)[wd[index_r2[j]], ]\n",
    "    Prob = Lho_topic / np.sum(Lho_topic, axis=1)[:, np.newaxis]\n",
    "\n",
    "    #多項分布からトピックをサンプリング\n",
    "    out = rmnom(Prob, f, topic, 1)\n",
    "    Zi = np.array(out[1], dtype=\"int\")\n",
    "    z = np.array(out[0], dtype=\"int\")\n",
    "    \n",
    "    #文書ごとのトピック頻度を数える\n",
    "    z_freq = np.zeros((N, topic), dtype=\"int\")\n",
    "    for i in range(N):\n",
    "        z_freq[i, ] = np.dot(Zi[d_list[i], ].T, d_vec[i])\n",
    "\n",
    "\n",
    "    ##トピックモデルのパラメータをサンプリング\n",
    "    #トピック分布をサンプリング\n",
    "    for i in range(k1):\n",
    "        wsum = np.dot(Zi.T, R_vec2[:, :k2[i]] * R_vec1[:, i][:, np.newaxis]).T + pi2\n",
    "        for j in range(k2[i]):\n",
    "            gamma[i][j, ] = np.random.dirichlet(wsum[j, ], 1).reshape(-1)\n",
    "\n",
    "    #単語分布をサンプリング\n",
    "    vsum = np.zeros((topic, v))\n",
    "    for j in range(v):\n",
    "        vsum[:, j] = np.dot(Zi[wd_list[j], ].T, wd_vec[j])\n",
    "    for j in range(topic):\n",
    "        phi[j, ] = np.random.dirichlet(vsum[j, ] + pi3, 1).reshape(-1)\n",
    "\n",
    "\n",
    "    ##サンプリング結果の格納と表示\n",
    "    #サンプリング結果の格納\n",
    "    if rp%keep==0:\n",
    "        mkeep = int(rp/keep)\n",
    "        MU1[mkeep] = mu_global\n",
    "        MU2[mkeep] = mu\n",
    "        COV1[mkeep] = Cov_global\n",
    "        COV2[mkeep] = Cov\n",
    "        GAMMA1[mkeep] = gamma_global\n",
    "        GAMMA2[mkeep] = gamma\n",
    "        PHI[:, :, mkeep] = phi\n",
    "        SEG1[:, mkeep] = r1\n",
    "        SEG2[:, mkeep] = r2\n",
    "        \n",
    "    #トピック割当はバーンイン期間を超えたら格納\n",
    "    if rp%keep==0 & rp >= burnin:\n",
    "        TOPIC = TOPIC + Zi\n",
    "\n",
    "    if rp%disp==0:\n",
    "        #学習データの対数尤度\n",
    "        Lho_dmv = np.zeros((N, np.max(k2)))\n",
    "        for i in range(k1):\n",
    "            index = index_r1[i]\n",
    "            for j in range(k2[i]):\n",
    "                Lho_dmv[index, j] = Prior2[i][u_id[index], j] * dmv(y[index, ], mu[i][j, ], Cov[i][:, :, j], geo)\n",
    "        LL1 = np.sum(np.log(np.sum(Lho_dmv[np.sum(Lho_dmv, axis=1) > 0, ], axis=1)))\n",
    "        LL2 = np.sum(np.log(np.sum(Lho_topic, axis=1)))\n",
    "        LL = LL1 + LL2\n",
    "\n",
    "        #サンプリング結果の表示\n",
    "        print(rp)\n",
    "        print(k1)\n",
    "        print(k2)\n",
    "        print(M1)\n",
    "        print(np.round([LL1, LL2, LL, LL01, LL02, LL0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
