{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Switching Bi-LDA model#####\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot  as plt\n",
    "import numpy.matlib\n",
    "import gensim\n",
    "import itertools\n",
    "from numpy.random import *\n",
    "from scipy import optimize\n",
    "from scipy import sparse\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##多項分布の乱数を生成する関数\n",
    "def rmnom(pr, n, k, no):\n",
    "    z_id = np.argmax((np.cumsum(pr, axis=1) >= np.random.uniform(0, 1, n)[:, np.newaxis]), axis=1)\n",
    "    Z = sparse.coo_matrix((np.repeat(1, n), (no, np.array(z_id))), shape=(n, k))   #スパース行列の設定\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####データの発生####\n",
    "##データの設定\n",
    "#文書の設定\n",
    "k1 = 20   #ユーザーアイテム\n",
    "k2 = 20   #アイテムトピック\n",
    "s = 3\n",
    "hh = 5000   #レビュアー数\n",
    "item = 2000   #アイテム数\n",
    "v1 = 500   #ユーザートピックの語彙数\n",
    "v2 = 500   #アイテムトピックの語彙数\n",
    "v3 = 250   #一般語の語彙数\n",
    "v = v1 + v2 + v3   #総語彙数\n",
    "index_v1 = np.arange(v1)\n",
    "index_v2 = np.arange(v1, v1+v2)\n",
    "index_v3 = np.arange(v1+v2, v)\n",
    "pt = np.random.poisson(np.random.gamma(10.0, 1/0.5, hh), hh)   #ユーザーあたりの文書数\n",
    "d = np.sum(pt)   #総文書数\n",
    "\n",
    "#文章の設定\n",
    "w = np.random.poisson(np.random.gamma(20.0, 1/0.25, d), d)   #文書あたりの単語数\n",
    "f = np.sum(w)   #総単語数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##文書のIDとインデックスを設定\n",
    "#IDを設定\n",
    "user_id = np.repeat(np.arange(hh), pt)\n",
    "pt_id = np.array(list(itertools.chain(*[np.array(range(pt[i]), dtype=\"int\") for i in range(hh)])))\n",
    "\n",
    "#インデックスの設定\n",
    "index = np.arange(d)\n",
    "user_index = [i for i in range(hh)]\n",
    "for i in range(hh):\n",
    "    user_index[i] = index[user_id==i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##アイテムの割当を生成\n",
    "#セグメント割当を生成\n",
    "topic = 30\n",
    "phi = np.random.dirichlet(np.repeat(0.5, item), topic)\n",
    "theta = np.random.dirichlet(np.repeat(2.5, topic), hh)\n",
    "z = np.dot(np.array([np.random.multinomial(1, theta[i, :], 1) for i in range(hh)]).reshape(hh, topic), range(topic))\n",
    "\n",
    "#多項分布からアイテムを生成\n",
    "item_id = np.zeros(d, dtype='int')\n",
    "for i in range(hh):\n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "    item_id[user_index[i]] = np.dot(np.random.multinomial(1, phi[z[i], :], pt[i]), range(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##単語のIDとインデックスを設定\n",
    "#IDの設定\n",
    "u_id = np.repeat(user_id, w)\n",
    "v_id = np.repeat(item_id, w)\n",
    "d_id = np.repeat(np.arange(d), w)\n",
    "t_id = np.array(list(itertools.chain(*[np.array(range(w[i]), dtype=\"int\") for i in range(d)])))\n",
    "\n",
    "#インデックスの設定\n",
    "index = np.arange(f)\n",
    "u_index = [i for i in range(hh)]\n",
    "v_index = [j for j in range(item)]\n",
    "for i in range(hh):\n",
    "    u_index[i] = index[u_id==i]\n",
    "for j in range(item):\n",
    "    v_index[j] = index[v_id==j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##パラメータの事前分布の設定\n",
    "#トピック分布の事前分布の設定\n",
    "alpha1 = np.array([4.5, 4.0, 2.0])   #スイッチング変数の事前分布\n",
    "alpha21 = np.repeat(0.2, k1)\n",
    "alpha22 = np.repeat(0.15, k2)\n",
    "\n",
    "#単語分布の事前分布の設定\n",
    "beta1 = np.repeat(0.0001, v); beta2 = np.repeat(0.0001, v); beta3 = np.repeat(0.0001, v)\n",
    "beta1[index_v1] = 0.025; beta2[index_v2] = 0.025; beta3[index_v3] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##すべての単語が出現するまでデータの生成を続ける\n",
    "rp = 0\n",
    "while True:\n",
    "    rp = rp + 1\n",
    "    print(rp)\n",
    "\n",
    "    ##ディリクレ分布からパラメータを生成\n",
    "    #トピック分布を生成\n",
    "    Lambda = np.random.dirichlet(alpha1, hh) \n",
    "    theta1 = np.random.dirichlet(alpha21, hh)\n",
    "    theta2 = np.random.dirichlet(alpha22, hh)\n",
    "    Lambdat = Lambda; thetat1 = theta1; thetat2 = theta2\n",
    "\n",
    "    #単語分布を生成\n",
    "    phi = np.random.dirichlet(beta1, k1)\n",
    "    gamma = np.random.dirichlet(beta2, k2)\n",
    "    omega = np.random.dirichlet(beta3, 1).reshape(-1)\n",
    "\n",
    "    #出現確率が低い単語を入れ替える\n",
    "    index = np.array(range(v1))[np.max(phi[:, index_v1], axis=0) <= (k1*k2)/f]\n",
    "    for j in range(index.shape[0]):\n",
    "        phi[np.argmax(np.random.multinomial(1, np.repeat(1/k1, k1), 1)), index[j]] = (k1*k2)/f\n",
    "    index = v1 + np.array(range(v2))[np.max(gamma[:, index_v2], axis=0) <= (k1*k2)/f]\n",
    "    for j in range(index.shape[0]):\n",
    "        gamma[np.argmax(np.random.multinomial(1, np.repeat(1/k2, k2), 1)), index[j]] = (k1*k2)/f\n",
    "    phit = phi; gammat = gamma; omegat = omega\n",
    "\n",
    "    ##文書ごとにデータを生成\n",
    "    #データの格納用配列\n",
    "    WX = np.zeros((d, v))\n",
    "    wd_list = [i for i in range(d)]\n",
    "    y_list = [i for i in range(d)]\n",
    "    z1_list = [i for i in range(d)]\n",
    "    z2_list = [i for i in range(d)]\n",
    "\n",
    "    for i in range(d):\n",
    "        #ユーザーとアイテムを抽出\n",
    "        index = np.arange(w[i])\n",
    "        get_user = user_id[i]\n",
    "        get_item = item_id[i]\n",
    "\n",
    "        #多項分布からスイッチグ変数を生成\n",
    "        y = np.random.multinomial(1, Lambda[get_user, ], w[i])\n",
    "\n",
    "        #ユーザートピックを生成\n",
    "        z1 = np.random.multinomial(1, theta1[get_user, ], w[i]) * y[:, 0].reshape(w[i], 1)\n",
    "        z1_vec = np.dot(z1, np.arange(k1))\n",
    "\n",
    "        #アイテムトピックを生成\n",
    "        z2 = np.random.multinomial(1, theta2[get_item, ], w[i]) * y[:, 1].reshape(w[i], 1)\n",
    "        z2_vec = np.dot(z2, np.arange(k2))\n",
    "\n",
    "        #トピックから単語分布を決定\n",
    "        Prob = np.repeat(omega, w[i]).reshape(w[i], v, order=\"F\")\n",
    "        if np.sum(y[:, 0]) > 0:\n",
    "            index_z1 = index[y[:, 0]==1]\n",
    "            Prob[index_z1, ] = phi[z1_vec[index_z1], ]\n",
    "        if np.sum(y[:, 1]) > 0:\n",
    "            index_z2 = index[y[:, 1]==1]\n",
    "            Prob[index_z2, ] = gamma[z2_vec[index_z2], ]\n",
    "\n",
    "        #多項分布から単語を生成\n",
    "        word = np.array(rmnom(Prob, w[i], v, np.arange(w[i])).todense(), dtype=\"int\")\n",
    "        word_vec = np.dot(word, np.arange(v))\n",
    "\n",
    "        #データを格納\n",
    "        WX[i, ] = np.sum(word, axis=0)\n",
    "        y_list[i] = y\n",
    "        z1_list[i] = z1\n",
    "        z2_list[i] = z2\n",
    "        wd_list[i] = word_vec\n",
    "        \n",
    "    #break条件\n",
    "    if np.min(np.sum(WX, axis=0)) > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##生成したデータを変換\n",
    "#リストを変換\n",
    "wd = np.array(list(itertools.chain(*[wd_list[i] for i in range(d)])))\n",
    "y = np.array(list(itertools.chain(*[y_list[i] for i in range(d)])))\n",
    "Z1 = np.array(list(itertools.chain(*[z1_list[i] for i in range(d)])))\n",
    "Z2 = np.array(list(itertools.chain(*[z2_list[i] for i in range(d)])))\n",
    "del wd_list; del y_list; del z1_list; del z2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#スパース行列に変換\n",
    "sparse_data = sparse.coo_matrix((np.repeat(1, f), (np.arange(f), wd)), shape=(f, v)).tocsr()\n",
    "sparse_data_T = sparse_data.T\n",
    "user_dt = sparse.coo_matrix((np.repeat(1, f), (u_id, np.arange(f))), shape=(hh, f)).tocsr()\n",
    "item_dt = sparse.coo_matrix((np.repeat(1, f), (v_id, np.arange(f))), shape=(item, f)).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####マルコフ連鎖モンテカルロ法でSwitching Bi-LDA modelを推定####\n",
    "#トピック尤度と負担率を計算する関数\n",
    "def LLho(theta, phi, d_id, wd, f, k):\n",
    "    Lho = theta[d_id, ] * (phi.T)[wd, ]\n",
    "    topic_rate = Lho / np.sum(Lho, axis=1).reshape(f, 1)\n",
    "    return Lho, topic_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##アルゴリズムの設定\n",
    "R = 2000   #サンプリング回数\n",
    "keep = 2   #2回に1回の割合でサンプリング結果を格納\n",
    "disp = 10\n",
    "iter = 0\n",
    "burnin = int(500/keep)\n",
    "\n",
    "##事前分布の設定\n",
    "#トピック分布の事前分布\n",
    "alpha1 = 0.1\n",
    "alpha21 = 0.1\n",
    "alpha22 = 0.1\n",
    "\n",
    "#単語分布の事前分布\n",
    "beta1 = 0.0001\n",
    "beta2 = 0.0001\n",
    "beta3 = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##データの設定\n",
    "#トピック割当確率の格納用配列\n",
    "Zeros1 = np.zeros((f, k1), dtype=\"int\") \n",
    "Zeros2 = np.zeros((f, k2), dtype=\"int\") \n",
    "\n",
    "#尤度の和を計算するためのベクトル\n",
    "index_f = np.arange(f)\n",
    "vec_s = np.repeat(1, s)\n",
    "vec_k1 = np.repeat(1, k1)\n",
    "vec_k2 = np.repeat(1, k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##パラメータの真値\n",
    "#トピック分布の真値\n",
    "Lambda = Lambdat\n",
    "theta1 = thetat1\n",
    "theta2 = thetat2\n",
    "\n",
    "#単語分布の真値\n",
    "phi = phit \n",
    "gamma = gammat\n",
    "omega = omegat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##パラメータの初期値\n",
    "#トピック分布の初期値\n",
    "np.random.dirichlet(np.repeat(2.5, s), hh)\n",
    "theta1 = np.random.dirichlet(np.repeat(2.5, k1), hh)\n",
    "theta2 = np.random.dirichlet(np.repeat(2.5, k2), item)\n",
    "\n",
    "#単語分布の初期値\n",
    "phi = np.random.dirichlet(np.repeat(2.5, v), k1)\n",
    "gamma = np.random.dirichlet(np.repeat(2.5, v), k2)\n",
    "omega = np.random.dirichlet(np.repeat(2.5, v), 1).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##パラメータの格納用配列\n",
    "#モデルパラメータの格納用配列\n",
    "LAMBDA = np.zeros((hh, s, int(R/keep)))\n",
    "THETA1 = np.zeros((hh, k1, int(R/keep)))\n",
    "THETA2 = np.zeros((item, k2, int(R/keep)))\n",
    "PHI = np.zeros((k1, v, int(R/keep)))\n",
    "GAMMA = np.zeros((k2, v, int(R/keep)))\n",
    "OMEGA = np.zeros((int(R/keep), v))\n",
    "\n",
    "#トピックの格納用配列\n",
    "SEG_S = np.zeros((f, s))\n",
    "SEG1 = np.zeros((f, k1))\n",
    "SEG2 = np.zeros((f, k2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##対数尤度の基準値\n",
    "#ユニグラムモデルの対数尤度\n",
    "LLst = np.sum(np.dot(sparse_data, sparse.csr_matrix(np.log(np.sum(WX, axis=0) / f)).T).todense())\n",
    "print(LLst)\n",
    "\n",
    "#真値の対数尤度\n",
    "LLbest_user = np.sum(np.log(np.dot(thetat1[u_id, ] * (phit.T)[wd, ], vec_k1)[y[:, 0]==1]))\n",
    "LLbest_item = np.sum(np.log(np.dot(thetat2[v_id, ] * (gammat.T)[wd, ], vec_k2)[y[:, 1]==1]))\n",
    "LLbest_normal = np.sum(np.log(omegat[wd][y[:, s-1]==1]))\n",
    "LLbest = LLbest_user + LLbest_item + LLbest_normal\n",
    "print(LLbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####ギブスサンプリングでパラメータをサンプリング####\n",
    "for rp in range(R):\n",
    "    \n",
    "    ##期待尤度からスイッチング変数をサンプリング\n",
    "    #トピック尤度を設定\n",
    "    Lho1 = theta1[u_id, ] * (phi.T)[wd, ]\n",
    "    Lho2 = theta2[v_id, ] * (gamma.T)[wd, ]\n",
    "    Lho3 = omega[wd]\n",
    "\n",
    "    #期待尤度からスイッチング確率を設定\n",
    "    Lho = np.concatenate((np.dot(Lho1, vec_k1), np.dot(Lho2, vec_k2), Lho3)).reshape(f, s, order=\"F\")\n",
    "    Posterior = Lambda[u_id, ] * Lho\n",
    "    Switching_Prob = Posterior / np.dot(Posterior, vec_s)[:, np.newaxis] \n",
    "\n",
    "    #ベルヌーイ分布からスイッチング変数をサンプリング\n",
    "    Sparse_S = rmnom(Switching_Prob, f, s, np.arange(f)).tocsr()\n",
    "    S = np.array(Sparse_S.todense(), dtype=\"int\")\n",
    "    s_vec = np.dot(S, np.arange(s))\n",
    "\n",
    "\n",
    "    ##ディリクリ分布から混合率をサンプリング\n",
    "    #ディリクリ分布のパラメータ\n",
    "    ssum = np.array(np.dot(user_dt, Sparse_S).todense()) + alpha1\n",
    "\n",
    "    #パラメータをサンプリング\n",
    "    Lambda = np.zeros((hh, s))\n",
    "    for i in range(hh):\n",
    "        Lambda[i, ] = np.random.dirichlet(ssum[i, ], 1).reshape(-1)\n",
    "\n",
    "    ##ユーザートピックをサンプリング\n",
    "    #トピックの割当確率を設定\n",
    "    index_z1 = np.where(s_vec==0)[0]\n",
    "    n1 = index_z1.shape[0]\n",
    "    Topic_par = Lho1[index_z1, ]\n",
    "    Topic_rate = Topic_par / np.dot(Topic_par, vec_k1)[:, np.newaxis] \n",
    "\n",
    "    #多項分布よりトピックをサンプリング\n",
    "    Zi1 = Zeros1\n",
    "    Zi1[index_z1, ] = np.array(rmnom(Topic_rate, n1, k1, np.arange(n1)).todense(), dtype=\"int\")\n",
    "    z1_vec = np.dot(Zi1, np.arange(k1))\n",
    "    Sparse_Zi1 = sparse.coo_matrix((np.repeat(1, n1), (index_f[index_z1], z1_vec[index_z1])), shape=(f, k1)).tocsr()\n",
    "\n",
    "\n",
    "    ##アイテムトピックをサンプリング\n",
    "    #トピックの割当確率を設定\n",
    "    index_z2 = np.where(s_vec==1)[0]\n",
    "    n2 = index_z2.shape[0]\n",
    "    Topic_par = Lho2[index_z2, ]\n",
    "    Topic_rate = Topic_par / np.dot(Topic_par, vec_k2)[:, np.newaxis] \n",
    "\n",
    "    #多項分布よりトピックをサンプリング\n",
    "    Zi2 = Zeros2\n",
    "    Zi2[index_z2, ] = np.array(rmnom(Topic_rate, n2, k2, np.arange(n2)).todense(), dtype=\"int\")\n",
    "    z2_vec = np.dot(Zi2, np.arange(k2))\n",
    "    Sparse_Zi2 = sparse.coo_matrix((np.repeat(1, n2), (index_f[index_z2], z2_vec[index_z2])), shape=(f, k2)).tocsr()\n",
    "\n",
    "\n",
    "    ##ユーザーとアイテムのトピック分布のパラメータをサンプリング\n",
    "    #ディリクリ分布のパラメータ\n",
    "    wsum1 = np.array(np.dot(user_dt, Sparse_Zi1).todense()) + alpha21\n",
    "    wsum2 = np.array(np.dot(item_dt, Sparse_Zi2).todense()) + alpha22\n",
    "\n",
    "    #パラメータをサンプリング\n",
    "    theta1 = np.zeros((hh, k1)); theta2 = np.zeros((item, k2))\n",
    "    for i in range(hh):\n",
    "        theta1[i, ] = np.random.dirichlet(wsum1[i, ], 1)\n",
    "    for i in range(item):\n",
    "        theta2[i, ] = np.random.dirichlet(wsum2[i, ], 1)\n",
    "\n",
    "\n",
    "    ##単語分布のパラメータをサンプリング\n",
    "    #ディリクリ分布のパラメータ\n",
    "    vsum1 = np.array(np.dot(sparse_data_T, Sparse_Zi1).todense()).T + beta1\n",
    "    vsum2 = np.array(np.dot(sparse_data_T, Sparse_Zi2).todense()).T + beta2\n",
    "    vsum3 = np.array(np.dot(sparse_data_T, Sparse_S[:, s-1]).todense()).reshape(-1) + beta3\n",
    "\n",
    "    #パラメータをサンプリング\n",
    "    phi = np.zeros((k1, v)); gamma = np.zeros((k2, v))\n",
    "    for j in range(k1):\n",
    "        phi[j, ] = np.random.dirichlet(vsum1[j, ], 1)\n",
    "    for j in range(k2):\n",
    "        gamma[j, ] = np.random.dirichlet(vsum2[j, ], 1)\n",
    "    omega = np.random.dirichlet(vsum3, 1).reshape(-1)\n",
    "\n",
    "\n",
    "    ##パラメータの格納とサンプリング結果の表示\n",
    "    #サンプリング結果の格納\n",
    "    if rp%keep==0:\n",
    "        mkeep = rp//keep\n",
    "        LAMBDA[:, :, mkeep] = Lambda\n",
    "        THETA1[:, :, mkeep] = theta1\n",
    "        THETA2[:, :, mkeep] = theta2\n",
    "        PHI[:, :, mkeep] = phi\n",
    "        GAMMA[:, :, mkeep] = gamma\n",
    "        OMEGA[mkeep, :] = omega\n",
    "\n",
    "    #トピック割当はバーンイン期間を超えたら格納\n",
    "    if rp%keep==0 & rp >= burnin:\n",
    "        SEG_S = SEG_S + S\n",
    "        SEG1 = SEG1 + Zi1\n",
    "        SEG2 = SEG2 + Zi2\n",
    "\n",
    "    if rp%disp==0:\n",
    "        #対数尤度の更新\n",
    "        LL_user = np.sum(np.log(np.dot(Lho1, vec_k1)[index_z1, ]))\n",
    "        LL_item = np.sum(np.log(np.dot(Lho2, vec_k2)[index_z2, ]))\n",
    "        LL_normal = np.sum(np.log(Lho3[S[:, s-1]==1]))\n",
    "        LL = LL_user + LL_item + LL_normal\n",
    "\n",
    "        #サンプリング結果を確認\n",
    "        print(rp)\n",
    "        print(np.round(np.hstack((np.array([LL]), np.array([LLst]), np.array([LLbest]))), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
