{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMM_LDA\n",
    "# ライブラリをインポート\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot  as plt\n",
    "import numpy.matlib\n",
    "import gensim\n",
    "import itertools\n",
    "from numpy.random import *\n",
    "from scipy import optimize\n",
    "from scipy import sparse\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多項分布の乱数を生成する関数\n",
    "def rmnom(pr, n, k, pattern):\n",
    "    if pattern==1:\n",
    "        z_id = np.array(np.argmax(np.cumsum(pr, axis=1) >= np.random.uniform(0, 1, n)[:, np.newaxis], axis=1), dtype=\"int\")\n",
    "        Z = np.diag(np.repeat(1, k))[z_id, ]\n",
    "        return z_id, Z\n",
    "    z_id = np.array(np.argmax((np.cumsum(pr, axis=1) >= np.random.uniform(0, 1, n)[:, np.newaxis]), axis=1), dtype=\"int\")\n",
    "    return z_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力データの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの設定\n",
    "k1 = 8   # syntax数\n",
    "k2 = 15   # トピック数\n",
    "d = 3000   # 文書数\n",
    "v1 = 800   # トピックに関係のある語彙数\n",
    "v2 = 500   # syntaxに関係のある語彙数\n",
    "v = v1 + v2   # 総語彙数\n",
    "w = np.random.poisson(np.random.gamma(42.5, 1/0.15, d))   # 文書あたりの単語数\n",
    "f = np.sum(w)   # 総単語数\n",
    "vec_k1 = np.repeat(1, k1)\n",
    "vec_k2 = np.repeat(1, k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDとインデックスの設定\n",
    "# IDの設定\n",
    "d_id = np.repeat(np.arange(d), w)\n",
    "pt_id = np.array(list(itertools.chain(*[np.array(range(w[i]), dtype=\"int\") for i in range(d)])))\n",
    "\n",
    "#インデックスの設定\n",
    "index = np.arange(f)\n",
    "d_list = [i for i in range(d)]\n",
    "d_vec = [i for i in range(d)]\n",
    "for i in range(d):\n",
    "    d_list[i] = index[d_id==i]\n",
    "    d_vec[i] = np.repeat(1, w[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの事前分布の設定\n",
    "# ディリクレ分布の事前分布\n",
    "alpha01 = np.append(np.arange(2.5, 0.5, -(2.5-0.5)/(k1-1)), 0.5)\n",
    "alpha02 = np.full((k1, k1), 0.5)\n",
    "alpha02[np.delete(np.arange(k1), k1-1), k1-1] = 7.5; alpha02[k1-1, k1-1] = 3.0\n",
    "alpha11 = np.repeat(0.15, k2)\n",
    "alpha21 = np.append(np.repeat(0.05, v1), np.repeat(0.00025, v2))\n",
    "\n",
    "# syntaxの事前分布\n",
    "alloc = np.dot(np.random.multinomial(1, np.random.dirichlet(np.repeat(5.0, k1-1), 1)[-1], v2), np.arange(k1-1))\n",
    "alpha22 = np.hstack((np.full((k1-1, v1), 0.0001), np.full((k1-1, v2), 0.0025)))\n",
    "for j in range(k1-1):\n",
    "    index = np.where(alloc==j)[0] + v1\n",
    "    alpha22[j, index] = 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 応答変数の生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# モデルに基づき単語を生成\n",
    "rp = 0\n",
    "while True:\n",
    "    rp = rp + 1\n",
    "    print(rp)\n",
    "    \n",
    "    # ディリクレ分布よりパラメータを生成\n",
    "    pi1 = np.random.dirichlet(alpha01, 1).reshape(-1)\n",
    "    pi2 = np.zeros((k1, k1))\n",
    "    for j in range(k1):\n",
    "        pi2[j, ] = np.random.dirichlet(alpha02[j, ], 1)\n",
    "    theta = np.random.dirichlet(alpha11, d)\n",
    "    phi = np.random.dirichlet(alpha21, k2)\n",
    "    psi = np.zeros((k1-1, v))\n",
    "    for j in range(k1-1):\n",
    "        psi[j, ] = np.random.dirichlet(alpha22[j, ], 1)\n",
    "    pit1 = pi1.copy(); pit2 = pi2.copy(); thetat = theta.copy()\n",
    "\n",
    "    # 単語出現確率が低いトピックを入れ替える\n",
    "    index1 = np.where(np.max(psi, axis=0) < (k1*10)/f)[0]; index1 = index1[index1 >= v1] \n",
    "    index2 = np.where(np.max(phi, axis=0) < (k2*10)/f)[0]; index2 = index2[index2 < v1]\n",
    "    for j in range(index1.shape[0]):\n",
    "        psi[np.argmax(np.random.multinomial(1, np.repeat(1/(k1-1), k1-1), 1)), index1[j]] = (k1*10)/f\n",
    "    psi = psi / np.sum(psi, axis=1)[:, np.newaxis]\n",
    "    for j in range(index2.shape[0]):\n",
    "        phi[np.argmax(np.random.multinomial(1, np.repeat(1/k2, k2), 1)), index2[j]] = (k2*10)/f\n",
    "    phi = phi / np.sum(phi, axis=1)[:, np.newaxis]\n",
    "    psit = psi.copy(); phit = phi.copy()\n",
    "\n",
    "    # HMM-LDAに基づき単語を生成\n",
    "    WX = np.array(np.zeros((d, v)), dtype=\"int\")\n",
    "    wd_list = [i for i in range(d)]\n",
    "    Z1_list = [i for i in range(d)]\n",
    "    Z2_list = [i for i in range(d)]\n",
    "\n",
    "    for i in range(d):\n",
    "        z1 = np.array(np.zeros((w[i], k1)), dtype=\"int\")\n",
    "        z2 = np.array(np.zeros((w[i], k2)), dtype=\"int\")\n",
    "        z2_vec = np.repeat(0, w[i])\n",
    "        words = np.array(np.zeros((w[i], v)), dtype=\"int\")\n",
    "\n",
    "        for j in range(w[i]):\n",
    "            if j==0:\n",
    "                # 文書の先頭の単語のsyntaxを生成\n",
    "                z1[j, ] = np.random.multinomial(1, pi1, 1)\n",
    "            else:\n",
    "                # 先頭以降はマルコフ推移に基づきsyntaxを生成\n",
    "                z1[j, ] = np.random.multinomial(1, pi2[np.argmax(z1[j-1, ]), ], 1)\n",
    "        z1_vec = np.dot(z1, np.arange(k1))\n",
    "\n",
    "        # トピック分布を生成\n",
    "        index_topic = np.where(z1_vec==k1-1)[0]\n",
    "        z2[index_topic, ] = np.random.multinomial(1, theta[i, ], index_topic.shape[0])\n",
    "        z2_vec[index_topic] = np.dot(z2[index_topic, ], np.arange(k2)) + 1\n",
    "\n",
    "        # 多項分布から単語を生成\n",
    "        index_syntax = np.delete(np.arange(w[i]), index_topic)\n",
    "        for j in range(index_syntax.shape[0]):\n",
    "            words[index_syntax[j], ] = np.random.multinomial(1, psi[z1_vec[index_syntax[j]], ], 1)\n",
    "        for j in range(index_topic.shape[0]):\n",
    "            words[index_topic[j], ] = np.random.multinomial(1, phi[(z2_vec-1)[index_topic[j]], ], 1)\n",
    "\n",
    "        #データを格納\n",
    "        wd_list[i] = np.dot(words, np.arange(v))\n",
    "        WX[i, ] = np.sum(words, axis=0)\n",
    "        Z1_list[i] = z1\n",
    "        Z2_list[i] = z2\n",
    "\n",
    "    if np.min(np.sum(WX, axis=0)) > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成したデータを変換\n",
    "# リストを変換\n",
    "wd = np.array(list(itertools.chain(*[wd_list[i] for i in range(d)])))\n",
    "Z1 = np.array(list(itertools.chain(*[Z1_list[i] for i in range(d)])))\n",
    "Z2 = np.array(list(itertools.chain(*[Z2_list[i] for i in range(d)])))\n",
    "del wd_list; del Z1_list; del Z2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スパース行列を定義\n",
    "sparse_data = sparse.coo_matrix((np.repeat(1, f), (np.arange(f), wd)), shape=(f, v)).tocsr()\n",
    "sparse_data_T = sparse_data.T\n",
    "d_dt = sparse.coo_matrix((np.repeat(1, f), (d_id, np.arange(f))), shape=(d, f)).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語インデックスを作成\n",
    "w_list = [j for j in range(v)]\n",
    "w_vec = [j for j in range(v)]\n",
    "for j in range(v):\n",
    "    w_list[j] = np.array(np.where(wd==j)[0], dtype=\"int\")\n",
    "    w_vec[j] = np.repeat(1, w_list[j].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM-LDAを推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アルゴリズムを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# マルコフ連鎖モンテカルロ法でHMM-LDAを推定\n",
    "# トピック尤度と負担率を計算する関数\n",
    "def LLho(theta, phi, d_id, wd, f, k):\n",
    "    Lho = theta[d_id, ] * (phi.T)[wd, ]\n",
    "    topic_rate = Lho / np.sum(Lho, axis=1).reshape(f, 1)\n",
    "    return Lho, topic_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インデックスの設定\n",
    "# 先頭と後尾のインデックスを作成\n",
    "max_word = np.max(pt_id) + 1\n",
    "index_t11 = np.array(np.where(pt_id==0)[0], dtype=\"int\")\n",
    "index_t12 = np.repeat(0, d)\n",
    "for i in range(d):\n",
    "    index_t12[i] = np.max(d_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中間のインデックスを作成\n",
    "d_id0 = np.append(d_id, d)\n",
    "index_list_t21 = [j for j in range(max_word-1)]\n",
    "index_list_t22 = [j for j in range(max_word-1)]\n",
    "for j in range(1, max_word):\n",
    "    index_list_t21[j-1] = np.array(np.where(pt_id==j)[0], dtype=\"int\") - 1\n",
    "    index_list_t22[j-1] = np.array(np.where(pt_id==j)[0], dtype=\"int\")\n",
    "index_t21 = np.sort(np.array(list(itertools.chain(*[index_list_t21[j] for j in range(max_word-1)]))))\n",
    "index_t22 = np.sort(np.array(list(itertools.chain(*[index_list_t22[j] for j in range(max_word-1)]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アルゴリズムの設定\n",
    "R = 1000   # サンプリング回数\n",
    "keep = 2   # 2回に1回の割合でサンプリング結果を格納\n",
    "disp = 50\n",
    "iter = 0\n",
    "burnin = int(500/keep)\n",
    "\n",
    "# 事前分布の設定\n",
    "alpha01 = 0.2\n",
    "alpha02 = 0.1\n",
    "alpha03 = 0.1\n",
    "beta01 = 0.1\n",
    "beta02 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの真値\n",
    "# トピック分布とマルコフ推移行列の真値\n",
    "theta = thetat.copy()\n",
    "pi1 = pit1.copy()\n",
    "pi2 = pit2.copy()\n",
    "\n",
    "# 単語分布の真値\n",
    "psi = psit.copy()\n",
    "phi = phit.copy()\n",
    "\n",
    "# HMMの潜在変数の真値\n",
    "Zi1 = Z1.copy()\n",
    "z1 = np.dot(Zi1, np.arange(k1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの初期値\n",
    "# トピック分布とマルコフ推移行列の初期値\n",
    "theta = np.random.dirichlet(np.repeat(100.0, k2), d)\n",
    "pi1 = np.random.dirichlet(np.repeat(100.0, k1), 1)\n",
    "pi2 = np.random.dirichlet(np.append(np.repeat(30, k1-1), 100.0), k1)\n",
    "\n",
    "# 単語分布の初期値\n",
    "psi = np.random.dirichlet(np.repeat(100.0, v), k1-1)\n",
    "phi = np.random.dirichlet(np.repeat(100.0, v), k2)\n",
    "\n",
    "# HMMの潜在変数の初期値\n",
    "Zi1 = np.random.multinomial(1, np.repeat(1/k1, k1), f)\n",
    "z1 = np.dot(Z1, np.arange(k1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの格納用配列\n",
    "# モデルパラメータの格納用配列\n",
    "THETA = np.zeros((d, k2, int(R/keep)))\n",
    "PI1 = np.zeros((int(R/keep), k1))\n",
    "PI2 = np.zeros((k1, k1, int(R/keep)))\n",
    "PSI = np.zeros((k1-1, v, int(R/keep)))\n",
    "PHI = np.zeros((k2, v, int(R/keep)))\n",
    "\n",
    "# トピックの格納用配列\n",
    "SEG1 = np.zeros((f, k1))\n",
    "SEG2 = np.zeros((f, k2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5677335.84063493 -4053001.76190603]\n"
     ]
    }
   ],
   "source": [
    "# 対数尤度の基準値\n",
    "# ユニグラムモデルの対数尤度\n",
    "par = np.sum(WX, axis=0) / f\n",
    "LLst = np.sum(np.dot(WX, np.log(par)))\n",
    "\n",
    "# 真値での対数尤度\n",
    "z1 = np.dot(Z1, np.arange(k1))\n",
    "index_topic = np.array(np.where(z1==k1-1)[0], dtype=\"int\")\n",
    "index_syntax = np.delete(np.arange(f), index_topic)\n",
    "LLbest1 = np.sum(np.log(np.sum(Z1[index_syntax, :k1-1] * (psit.T)[wd[index_syntax], ], axis=1)))\n",
    "LLbest2 = np.sum(np.log(np.sum((thetat[d_id, ] * (phit.T)[wd, ])[index_topic, ], axis=1)))\n",
    "LLbest = LLbest1 + LLbest2\n",
    "print(np.array([LLst, LLbest]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメータを推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[-5674398.7 -5677335.8 -4053001.8]\n",
      "50\n",
      "[-4609443.4 -5677335.8 -4053001.8]\n",
      "100\n",
      "[-4206784.4 -5677335.8 -4053001.8]\n",
      "150\n",
      "[-4162548.9 -5677335.8 -4053001.8]\n",
      "200\n",
      "[-4154573.  -5677335.8 -4053001.8]\n",
      "250\n",
      "[-4144238.4 -5677335.8 -4053001.8]\n",
      "300\n",
      "[-4142069.9 -5677335.8 -4053001.8]\n",
      "350\n",
      "[-4119758.4 -5677335.8 -4053001.8]\n",
      "400\n",
      "[-4119839.2 -5677335.8 -4053001.8]\n",
      "450\n",
      "[-4120482.7 -5677335.8 -4053001.8]\n",
      "500\n",
      "[-4114161.1 -5677335.8 -4053001.8]\n",
      "550\n",
      "[-4112156.  -5677335.8 -4053001.8]\n",
      "600\n",
      "[-4114614.5 -5677335.8 -4053001.8]\n",
      "650\n",
      "[-4113964.3 -5677335.8 -4053001.8]\n",
      "700\n",
      "[-4115507.1 -5677335.8 -4053001.8]\n",
      "750\n",
      "[-4112388.6 -5677335.8 -4053001.8]\n",
      "800\n",
      "[-4112489.8 -5677335.8 -4053001.8]\n",
      "850\n",
      "[-4110735.3 -5677335.8 -4053001.8]\n",
      "900\n",
      "[-4108119.8 -5677335.8 -4053001.8]\n",
      "950\n",
      "[-4112474.3 -5677335.8 -4053001.8]\n"
     ]
    }
   ],
   "source": [
    "# ギブスサンプリングでパラメータをサンプリング\n",
    "for rp in range(R):\n",
    "    \n",
    "    # 単語ごとの尤度と混合率を設定\n",
    "    # syntaxとトピックモデルの尤度\n",
    "    Lho1 = (psi.T)[wd, ]   # syntaxごとの尤度\n",
    "    Lho2 = theta[d_id, ] * (phi.T)[wd, ]\n",
    "    Lho_mu2 = np.dot(Lho2, vec_k2)   # トピックモデルの期待尤度\n",
    "    Lho = np.hstack((Lho1, Lho_mu2[:, np.newaxis]))   # 尤度の結合\n",
    "\n",
    "    # HMMの混合率と推移確率\n",
    "    pi_dt1 = np.full((f, k1), 1/k1); pi_dt2 = pi_dt1.copy()\n",
    "    pi_dt1[index_t11, ] = np.full((d, k1), pi1)   # 文書の先頭の混合率\n",
    "    pi_dt1[index_t22, ] = pi2[z1[index_t21], ]   # 1単語前の混合率\n",
    "    pi_dt2[index_t21, ]= (pi2.T)[z1[index_t22], ]   # 1単語後の混合率\n",
    "\n",
    "    # 多項分布からHMMの潜在変数をサンプリング\n",
    "    # 潜在変数の割当確率\n",
    "    Posterior = pi_dt1 * pi_dt2 * Lho   # 結合分布\n",
    "    Prob = Posterior / np.dot(Posterior, vec_k1)[:, np.newaxis]\n",
    "\n",
    "    # 潜在変数をサンププリング\n",
    "    Zi1 = rmnom(Prob, f, k1, 1)[1]\n",
    "    z1 = np.dot(Zi1, np.arange(k1))\n",
    "    n1 = np.sum(Zi1[:, :k1-1])\n",
    "    n2 = np.sum(Zi1[:, k1-1])\n",
    "    index_syntax = np.where(z1!=k1-1)[0].astype(\"int\")\n",
    "    index_topic = np.where(z1==k1-1)[0].astype(\"int\")\n",
    "\n",
    "\n",
    "    # HMMのパラメータをサンプリング\n",
    "    # ディリクレ分布から推移確率のパラメータをサンプリング\n",
    "    rf11 = np.sum(Zi1[index_t11, ], axis=0) + alpha01\n",
    "    rf12 = np.dot(Zi1[index_t21, ].T, Zi1[index_t22, ]) + alpha02\n",
    "    pi1 = np.random.dirichlet(rf11, 1).reshape(-1)\n",
    "    pi2 = np.zeros((k1, k1))\n",
    "    for j in range(k1):\n",
    "        pi2[j, ] = np.random.dirichlet(rf12[j, ], 1).reshape(-1)\n",
    "\n",
    "    # トピックモデルのパラメータをサンプリング\n",
    "    # トピックをサンプリング\n",
    "    Prob = Lho2[index_topic, ] / np.dot(Lho2[index_topic, ], vec_k2)[:, np.newaxis]\n",
    "    Zi2 = np.array(np.zeros((f, k2)), dtype=\"int\")\n",
    "    Zi2[index_topic, ] = rmnom(Prob, n2, k2, 1)[1]\n",
    "    \n",
    "    # トピック分布のパラメータをサンプリング\n",
    "    theta = np.zeros((d, k2))\n",
    "    for i in range(d):\n",
    "        wsum = np.dot(Zi2[d_list[i]].T, d_vec[i]) + alpha02\n",
    "        theta[i, ] = np.random.dirichlet(wsum, 1).reshape(-1)\n",
    "\n",
    "        \n",
    "    # 単語分布をサンプリング\n",
    "    # ディリクレ分布から単語分布のパラメータをサンプリング\n",
    "    vf1 = np.zeros((k1-1, v)); vf2 = np.zeros((k2, v))\n",
    "    psi = np.zeros((k1-1, v)); phi = np.zeros((k2, v))\n",
    "    for j in range(v):\n",
    "        vf1[:, j] = np.dot(Zi1[w_list[j], :k1-1].T, w_vec[j]) + beta01\n",
    "        vf2[:, j] = np.dot(Zi2[w_list[j], ].T, w_vec[j]) + beta02\n",
    "    for j in range(k1-1):\n",
    "        psi[j, ] = np.random.dirichlet(vf1[j, ], 1).reshape(-1)\n",
    "    for j in range(k2):\n",
    "        phi[j, ] = np.random.dirichlet(vf2[j, ], 1).reshape(-1)\n",
    "\n",
    "\n",
    "    # パラメータの格納とサンプリング結果の表示\n",
    "    # サンプリング結果の格納\n",
    "    if rp%keep==0:\n",
    "        mkeep = rp//keep\n",
    "        THETA[:, :, mkeep] = theta\n",
    "        PI1[mkeep, ] = pi1\n",
    "        PI2[:, :, mkeep] = pi2\n",
    "        PHI[:, :, mkeep] = phi\n",
    "        PSI[:, :, mkeep] = psi\n",
    "\n",
    "    # トピック割当はバーンイン期間を超えたら格納\n",
    "    if rp%keep==0 & rp >= burnin:\n",
    "        SEG1 = SEG1 + Zi1\n",
    "        SEG2 = SEG2 + Zi2\n",
    "\n",
    "    if rp%disp==0:\n",
    "        # 対数尤度の更新\n",
    "        LL1 = np.sum(np.log(np.sum(Zi1[index_syntax, :k1-1] * (psi.T)[wd[index_syntax], ], axis=1)))\n",
    "        LL2 = np.sum(np.log(np.sum((theta[d_id, ] * (phi.T)[wd, ])[index_topic, ], axis=1)))\n",
    "        LL = LL1 + LL2\n",
    "\n",
    "        #サンプリング結果を確認\n",
    "        print(rp)\n",
    "        print(np.round(np.array([LL, LLst, LLbest]), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
