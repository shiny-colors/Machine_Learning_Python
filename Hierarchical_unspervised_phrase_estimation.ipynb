{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリの読み込み\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot  as plt\n",
    "import scipy.linalg\n",
    "import itertools\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizers\n",
    "from scipy.stats import norm\n",
    "from numpy.random import *\n",
    "from scipy import optimize\n",
    "\n",
    "#np.random.seed(9837)\n",
    "#torch.manual_seed(9837)\n",
    "pd.set_option(\"display.max_rows\", 250)\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多項分布の乱数を生成する関数\n",
    "def rmnom(pr, n, k, pattern):\n",
    "    if pattern==1:\n",
    "        z_id = np.array(np.argmax(np.cumsum(pr, axis=1) >= np.random.uniform(0, 1, n)[:, np.newaxis], axis=1), dtype=\"int\")\n",
    "        Z = np.diag(np.repeat(1, k))[z_id, ]\n",
    "        return z_id, Z\n",
    "    z_id = np.array(np.argmax((np.cumsum(pr, axis=1) >= np.random.uniform(0, 1, n)[:, np.newaxis]), axis=1), dtype=\"int\")\n",
    "    return z_id\n",
    "\n",
    "# ディリクリ分布の乱数を生成する関数\n",
    "def Dirichlet(alpha, n):\n",
    "    x = torch.Tensor(np.random.dirichlet(alpha, n))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力データの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの設定\n",
    "# パラメータ数を定義\n",
    "syntax1 = 7\n",
    "syntax2 = np.repeat(7, syntax1)\n",
    "k = 15\n",
    "d = 5000\n",
    "v1 = 800\n",
    "v2 = 200\n",
    "v = v1 + v2\n",
    "\n",
    "# 文書データの統計量を生成\n",
    "min_word = 2\n",
    "max_word = 50\n",
    "pt = np.random.poisson(np.random.gamma(10.0, 1.0, d), d)\n",
    "pt[pt < 5] = 5\n",
    "L = np.sum(pt)\n",
    "ph = np.random.poisson(np.random.gamma(17.5, 0.5, L), L)\n",
    "ph[ph < 2] = 2\n",
    "M = np.sum(ph)\n",
    "w = np.random.poisson(np.random.gamma(75.0, 0.05, M), M)\n",
    "w[w < min_word] = min_word\n",
    "N = np.sum(w)\n",
    "\n",
    "# 行列演算ベクトルを定義\n",
    "k_vec = np.repeat(1.0, k)\n",
    "index_k = np.arange(k)\n",
    "index_v1 = np.arange(v1)\n",
    "index_v2 = np.arange(v2) + v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idとインデックスを定義\n",
    "# 文書idを定義\n",
    "d_id1 = np.repeat(np.repeat(np.arange(d), pt), ph)\n",
    "sentence_id1 = np.repeat(np.arange(L), ph)\n",
    "pt_id1 = np.hstack(([np.arange(ph[i]) for i in range(L)]))\n",
    "d_id2 = np.repeat(np.repeat(np.repeat(np.arange(d), pt), ph), w)\n",
    "sentence_id2 = np.repeat(np.repeat(np.arange(L), ph), w)\n",
    "phrase_id2 = np.repeat(np.arange(M), w)\n",
    "pt_id2 = np.hstack(([np.arange(w[i]) for i in range(M)]))\n",
    "\n",
    "# 文書のインデックスを定義\n",
    "d_list1 = []\n",
    "d_list2 = []\n",
    "sentence_list1 = []\n",
    "sentence_list2 = []\n",
    "for i in range(d):\n",
    "    d_list1.append(np.where(d_id1==i)[0].astype(\"int\"))\n",
    "    d_list2.append(np.where(d_id2==i)[0].astype(\"int\"))\n",
    "for i in range(L):\n",
    "    sentence_list1.append(np.where(sentence_id1==i)[0].astype(\"int\"))\n",
    "    sentence_list2.append(np.where(sentence_id2==i)[0].astype(\"int\"))\n",
    "    \n",
    "# 語順のインデックスを定義\n",
    "max_pt1 = np.max(pt_id1) + 1\n",
    "max_pt2 = np.max(pt_id2) + 1\n",
    "pt_list11 = [j for j in range(max_pt1)]\n",
    "pt_list10 = [j for j in range(max_pt1)]\n",
    "pt_list21 = [j for j in range(max_pt2)]\n",
    "pt_list20 = [j for j in range(max_pt2)]\n",
    "pt_n1 = np.repeat(0, max_pt1)\n",
    "pt_n2 = np.repeat(0, max_pt2)\n",
    "for j in range(max_pt1):\n",
    "    pt_list11[j] = np.array(np.where(pt_id1==j)[0], dtype=\"int\")\n",
    "    if j > 0:\n",
    "        pt_list10[j] = pt_list11[j] - 1\n",
    "    pt_n1[j] = pt_list11[j].shape[0]\n",
    "for j in range(max_pt2):\n",
    "    pt_list21[j] = np.array(np.where(pt_id2==j)[0], dtype=\"int\")\n",
    "    if j > 0:\n",
    "        pt_list20[j] = pt_list21[j] - 1\n",
    "    pt_n2[j] = pt_list21[j].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 機能語を生成\n",
    "# フレーズのインデックスを定義\n",
    "phrase_list = []\n",
    "for i in range(M):\n",
    "    if i==0:\n",
    "        phrase_list.append(np.arange(w[i]))\n",
    "    else:\n",
    "        phrase_list.append(np.max(phrase_list[i-1]) + np.arange(w[i]) + 1)\n",
    "        \n",
    "# 機能語の位置を定義\n",
    "weights = 1.0\n",
    "function_flag = np.repeat(0, N)\n",
    "for i in range(M):\n",
    "    x = np.arange(w[i])[::-1][:3]\n",
    "    logit = np.exp(weights * x)\n",
    "    prob = logit / np.sum(logit)\n",
    "    index = x[np.random.multinomial(1, prob, 1).reshape(-1)==1]\n",
    "    function_flag[phrase_list[i][index]] = 1\n",
    "function_index = np.where(function_flag==1)[0].astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメータと応答変数を生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事前分布の定義\n",
    "# HMMの事前分布を定義\n",
    "alpha1 = np.repeat(0.5, syntax1)\n",
    "alpha21 = np.array([0.3, 3.0])\n",
    "alpha22 = np.array([1.75, 1/1.75])\n",
    "beta1 = [np.repeat(0.5, syntax2[j]) for j in range(syntax1)]\n",
    "beta2 = [np.repeat(0.2, syntax2[j]) for j in range(syntax1)]\n",
    "\n",
    "# 単語分布の事前分布\n",
    "gamma1 = [np.repeat(0.02, v1) for j in range(syntax1)]\n",
    "gamma2 = [np.repeat(0.02, v2) for j in range(syntax1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータを生成\n",
    "# 推移確率のパラメータを生成\n",
    "theta1 = np.random.gamma(alpha21[0], alpha21[1], syntax1*syntax1).reshape(syntax1, syntax1)\n",
    "theta2 = np.random.gamma(alpha22[0], alpha22[1], v2*syntax1).reshape(v2, syntax1)\n",
    "pi1 = np.random.dirichlet(alpha1, 1)\n",
    "pi2 = np.zeros((syntax1, syntax1, v2))\n",
    "for j in range(v2):\n",
    "    logit = theta1 * theta2[j, ]\n",
    "    pi2[:, :, j] = logit / np.sum(logit, axis=1)[:, np.newaxis]\n",
    "psi1 = [np.random.dirichlet(beta1[j], 1).reshape(-1) for j in range(syntax1)]\n",
    "psi2 = [np.random.dirichlet(beta2[j], syntax2[j]) for j in range(syntax1)]\n",
    "thetat1 = theta1.copy(); thetat2 = theta2.copy()\n",
    "pit1 = pi1.copy(); pit2 = pi2.copy(); psit1 = psi1.copy(); psit2 = psi2.copy()\n",
    "\n",
    "# 単語分布のパラメータを生成\n",
    "phi1 = []; phi2 = []; phi = []\n",
    "for j in range(syntax1):\n",
    "    phi1.append(np.random.dirichlet(gamma1[j], syntax2[j]))\n",
    "    phi2.append(np.random.dirichlet(gamma2[j], syntax2[j]))\n",
    "    phi.append(np.hstack((phi1[j], phi2[j])))\n",
    "phit = phi.copy(); phit1 = phi1.copy(); phit2 = phi2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 応答変数を生成\n",
    "# 生成したデータの格納用配列\n",
    "Z1 = np.zeros((M, syntax1), dtype=\"int\")\n",
    "Z2 = np.zeros((N, np.max(syntax2)), dtype=\"int\")\n",
    "z1 = np.repeat(0, M)\n",
    "z2 = np.repeat(0, N)\n",
    "word_id = np.repeat(0, N)\n",
    "function_word = np.repeat(0, M)\n",
    "\n",
    "# フレーズごとに潜在変数と単語を生成\n",
    "for i in range(M):\n",
    "    if i%10000==0:\n",
    "        print(i)\n",
    "    \n",
    "    # 上位階層の潜在変数を生成\n",
    "    if pt_id1[i]==0:\n",
    "        Z1[i, ] = np.random.multinomial(1, pi1.reshape(-1), 1).reshape(-1)\n",
    "        z1[i] = np.argmax(Z1[i, ])\n",
    "    else:\n",
    "        Z1[i, ] = np.random.multinomial(1, pi2[z1[i-1], :, function_word[i-1]], 1).reshape(-1)\n",
    "        z1[i] = np.argmax(Z1[i, ])\n",
    "\n",
    "    # 下位階層の潜在変数と単語を生成\n",
    "    # 上位階層に対応するパラメータを抽出\n",
    "    index = phrase_list[i]\n",
    "    psi01 = psi1[z1[i]]; psi02 = psi2[z1[i]]\n",
    "    phi01 = phi1[z1[i]]; phi02 = phi2[z1[i]]\n",
    "\n",
    "    # 単語単位で潜在変数と対応する単語を生成\n",
    "    for j in range(w[i]):\n",
    "\n",
    "        # 1単語目の応答変数を生成\n",
    "        if j==0:\n",
    "            # 下位階層の潜在変数を生成    \n",
    "            Z2[index[j], ] = np.random.multinomial(1, psi01, 1)\n",
    "            z2[index[j]] = np.argmax(Z2[index[j], ])\n",
    "\n",
    "            # 単語を生成\n",
    "            if function_flag[index[j]]==0:\n",
    "                word_id[index[j]] = np.argmax(np.random.multinomial(1, phi01[z2[index[j]], ], 1).reshape(-1))\n",
    "            else:\n",
    "                function_word[i] = np.argmax(np.random.multinomial(1, phi02[z2[index[j]], ], 1).reshape(-1))\n",
    "                word_id[index[j]] = function_word[i] + v1\n",
    "\n",
    "        # 2単語目以降の応答変数を生成\n",
    "        if j > 0:\n",
    "            # 下位階層の潜在変数を生成\n",
    "            Z2[index[j], ] = np.random.multinomial(1, psi02[z2[index[j-1]], ], 1)\n",
    "            z2[index[j]] = np.argmax(Z2[index[j], ])\n",
    "\n",
    "            # 単語を生成\n",
    "            if function_flag[index[j]]==0:\n",
    "                word_id[index[j]] = np.argmax(np.random.multinomial(1, phi01[z2[index[j]], ], 1).reshape(-1))\n",
    "            else:\n",
    "                function_word[i] = np.argmax(np.random.multinomial(1, phi02[z2[index[j]], ], 1).reshape(-1))\n",
    "                word_id[index[j]] = function_word[i] + v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一部データに教師をつける\n",
    "q = 3\n",
    "supervised_prob = 0.5\n",
    "target_syntax = np.random.choice(np.arange(syntax1), q, replace=False)\n",
    "index = np.where(np.in1d(z1, target_syntax))[0].astype(\"int\")\n",
    "y = np.repeat(0, M)\n",
    "y[index] = np.random.binomial(1, supervised_prob, index.shape[0])\n",
    "index_y0 = np.where(y==0)[0].astype(\"int\")\n",
    "index_y1 = np.where(y==1)[0].astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical unsupervised phrase estimationを推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アルゴリズムの設定\n",
    "R = 1000\n",
    "keep = 2\n",
    "burnin = 500\n",
    "skeep = int(burnin/keep)\n",
    "iters = 0\n",
    "disp = 50\n",
    "serial_no = np.arange(N)\n",
    "syntax_vec1 = np.repeat(1, syntax1)\n",
    "syntax_vec2 = [np.repeat(1, syntax2[i]) for i in range(syntax1)]\n",
    "phrase_matrix = scipy.sparse.csr_matrix((np.repeat(1, N), (phrase_id2, np.arange(N))), shape=(M, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インデックスの定義\n",
    "# 単語のインデックスを定義\n",
    "word_list1 = [i for i in range(v1)]\n",
    "word_list2 = [i for i in range(v2)]\n",
    "word_vec1 = [i for i in range(v1)]\n",
    "word_vec2 = [i for i in range(v2)]\n",
    "for i in range(v1):\n",
    "    word_list1[i] = np.where(word_id==i)[0].astype(\"int\")\n",
    "    word_vec1[i] = np.repeat(1, word_list1[i].shape[0])\n",
    "for i in range(v2):\n",
    "    word_list2[i] = np.where(word_id==v1+i)[0].astype(\"int\")\n",
    "    word_vec2[i] = np.repeat(1, word_list2[i].shape[0])\n",
    "    \n",
    "# 先頭と末尾のインデックスを定義\n",
    "index_p11 = np.where(pt_id1==0)[0].astype(\"int\")\n",
    "index_q11 = np.where(pt_id2==0)[0].astype(\"int\")\n",
    "index_p12 = np.repeat(0, L)\n",
    "index_q12 = np.repeat(0, M)\n",
    "for i in range(L):\n",
    "    index_p12[i] = np.max(sentence_list1[i])\n",
    "for i in range(M):    \n",
    "    index_q12[i] = np.max(phrase_list[i])\n",
    "    \n",
    "# 中間のインデックスを定義\n",
    "index_list_p21 = [j for j in range(max_pt1-1)]\n",
    "index_list_p22 = [j for j in range(max_pt1-1)]\n",
    "index_list_q21 = [j for j in range(max_pt2-1)]\n",
    "index_list_q22 = [j for j in range(max_pt2-1)]\n",
    "for j in range(1, max_pt1):\n",
    "    index_list_p21[j-1] = np.where(pt_id1==j)[0].astype(\"int\") - 1\n",
    "    index_list_p22[j-1] = np.where(pt_id1==j)[0].astype(\"int\")\n",
    "for j in range(1, max_pt2):\n",
    "    index_list_q21[j-1] = np.where(pt_id2==j)[0].astype(\"int\") - 1\n",
    "    index_list_q22[j-1] = np.where(pt_id2==j)[0].astype(\"int\")\n",
    "index_p21 = np.sort(np.hstack((index_list_p21)))\n",
    "index_p22 = np.sort(np.hstack((index_list_p22)))\n",
    "index_q21 = np.sort(np.hstack((index_list_q21)))\n",
    "index_q22 = np.sort(np.hstack((index_list_q22)))\n",
    "\n",
    "# 機能語のインデックスを定義\n",
    "new_function = function_word.copy()\n",
    "new_function[index_p12] = np.max(v2)\n",
    "function_list1 = [j for j in range(v2)]\n",
    "function_list2 = [j for j in range(v2)]\n",
    "for j in range(v2):\n",
    "    function_list1[j] = np.where(new_function==j)[0].astype(\"int\") \n",
    "    function_list2[j] = function_list1[j] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事前分布の定義\n",
    "# HMMの事前分布を定義\n",
    "alpha1 = np.repeat(0.5, syntax1)\n",
    "alpha21 = np.array([0.5, 0.5])\n",
    "alpha22 = np.array([1.0, 1.0])\n",
    "beta1 = 0.2\n",
    "beta2 = 0.2\n",
    "\n",
    "# 単語分布の事前分布\n",
    "gamma1 = 0.1\n",
    "gamma2 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの真値を定義\n",
    "# 推移確率のパラメータの真値\n",
    "theta1 = thetat1.copy()\n",
    "theta2 = thetat2.copy()\n",
    "pi1 = pit1.copy()\n",
    "pi2 = pit2.copy()\n",
    "psi1 = psit1.copy()\n",
    "psi2 = psit2.copy()\n",
    "\n",
    "# 単語分布のパラメータの真値\n",
    "phi1 = phit1.copy()\n",
    "phi2 = phit2.copy()\n",
    "phi = [np.hstack((phi1[j], phi2[j])) for j in range(syntax1)]\n",
    "\n",
    "# 潜在変数の真値\n",
    "Zi1 = Z1.copy()\n",
    "Zi2 = Z2.copy()\n",
    "z1 = np.dot(Zi1, np.arange(syntax1))\n",
    "z2 = np.dot(Zi2, np.arange(np.max(syntax2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの初期値\n",
    "# 推移確率のパラメータの初期値\n",
    "theta1 = np.random.gamma(0.5, 0.5, syntax1*syntax1).reshape(syntax1, syntax1)\n",
    "theta2 = np.random.gamma(0.5, 0.5, v2*syntax1).reshape(v2, syntax1)\n",
    "pi1 = np.random.dirichlet(np.repeat(1.0, syntax1), 1).reshape(-1)\n",
    "pi2 = np.zeros((syntax1, syntax1, v2))\n",
    "for j in range(v2):\n",
    "    logit = theta1 * theta2[j, ]\n",
    "    pi2[:, :, j] = logit / np.sum(logit, axis=1)[:, np.newaxis]\n",
    "psi1 = [np.random.dirichlet(np.repeat(5.0, syntax2[j]) , 1).reshape(-1) for j in range(syntax1)]\n",
    "psi2 = [np.random.dirichlet(np.repeat(5.0, syntax2[j]), syntax2[j]) for j in range(syntax1)]\n",
    "\n",
    "# 単語分布のパラメータの初期値\n",
    "phi1 = []; phi2 = []; phi = []\n",
    "for j in range(syntax1):\n",
    "    phi1.append(np.random.dirichlet(np.repeat(5.0, v1), syntax2[j]))\n",
    "    phi2.append(np.random.dirichlet(np.repeat(5.0, v2), syntax2[j]))\n",
    "    phi.append(np.hstack((phi1[j], phi2[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの格納用配列\n",
    "# バーンインのインデックスを定義\n",
    "RS = np.arange(skeep, int(R/keep))\n",
    "rs = RS.shape[0]\n",
    "\n",
    "# 推移確率とトピック分布の格納用配列\n",
    "THETA1 = np.zeros((syntax1, syntax1, rs))\n",
    "THETA2 = np.zeros((v2, syntax1, rs))\n",
    "PSI1 = []\n",
    "PSI2 = []\n",
    "\n",
    "# モデルパラメータの格納用配列\n",
    "PHI1 = []\n",
    "PHI2 = []\n",
    "PHI = []\n",
    "\n",
    "# 潜在変数の格納用配列\n",
    "SEG1 = np.zeros((rs, M), dtype=\"int8\")\n",
    "SEG2 = np.zeros((rs, N), dtype=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対数尤度の基準値\n",
    "# ユニグラムモデルの対数尤度\n",
    "freq = np.unique(word_id, return_counts=True)\n",
    "par1 = np.repeat(0.0, v1)\n",
    "par2 = np.repeat(0.0, v2)\n",
    "par1[freq[0][freq[0] < v1]] = freq[1][freq[0] < v1]\n",
    "par2[freq[0][freq[0] >= v1] - v1] = freq[1][freq[0] >= v1]\n",
    "LLst1 = np.sum(np.log((par1 / np.sum(par1))[word_id[word_id < v1]]))\n",
    "LLst2 = np.sum(np.log((par2 / np.sum(par2))[word_id[word_id >= v1] - v1]))\n",
    "LLst = LLst1 + LLst2\n",
    "print(np.round([LLst1, LLst2, LLst], 1))\n",
    "\n",
    "# 真値での対数尤度\n",
    "LLbest = 0.0; LLbest1 = 0.0; LLbest2 = 0.0\n",
    "syntax_long = Z1[phrase_id2, ]\n",
    "for j in range(syntax1):\n",
    "    index = np.where(syntax_long[:, j])[0].astype(\"int\")\n",
    "    LLho = np.log(np.dot(Z2[index, ] * (phit[j].T)[word_id[index], ], syntax_vec2[j]))\n",
    "    LLbest1 += np.sum(LLho[word_id[index] < v1])\n",
    "    LLbest2 += np.sum(LLho[word_id[index] >= v1])\n",
    "    LLbest += np.sum(LLho)\n",
    "print(np.round([LLbest1, LLbest2, LLbest], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメータを推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ギブスサンプリングでパラメータをサンプリング\n",
    "start_time = time.time()\n",
    "for rp in range(R):\n",
    "    \n",
    "    # 上位階層のsyntaxごとに下位階層のsyntaxを生成\n",
    "    # 上位階層のパラメータの格納用配列\n",
    "    Syntax = np.zeros((N, np.max(syntax2), syntax1), dtype=\"int\")\n",
    "    Lho = np.zeros((N, syntax1))\n",
    "\n",
    "    # syntaxに応じた下位階層のsyntaxを生成\n",
    "    for i in range(syntax1):\n",
    "\n",
    "        # 潜在変数の格納用配列\n",
    "        Posterior2 = np.zeros((N, syntax2[i]))\n",
    "        Zi2 = np.zeros((N, syntax2[i]), dtype=\"int\")\n",
    "        z2 = np.repeat(0, N)\n",
    "\n",
    "        # 下位階層の尤度を定義\n",
    "        phi_long = (phi[i].T)[word_id, ]\n",
    "\n",
    "        # 語順に応じてsyntaxを生成\n",
    "        for j in range(max_pt2):\n",
    "\n",
    "            # フレーズの先頭のsyntaxを生成\n",
    "            index = pt_list21[j]\n",
    "            if j==0:\n",
    "                # 事後分布から潜在確率を定義\n",
    "                prior = psi1[i]\n",
    "                Posterior2 = prior * phi_long[index, ]\n",
    "                Prob2 = Posterior2 / np.dot(Posterior2, syntax_vec2[i])[:, np.newaxis]\n",
    "\n",
    "                # 多項分布からsyntaxを生成\n",
    "                res = rmnom(Prob2, pt_n2[j], syntax2[i], 1)\n",
    "                z2[index] = res[0]\n",
    "                Zi2[index, :syntax2[i]] = res[1]\n",
    "\n",
    "                # 上位階層の尤度を定義\n",
    "                Lho[index, i] = np.dot(res[1] * Posterior2, syntax_vec2[i])\n",
    "\n",
    "            # フレーズの2単語目以降のsyntaxを生成\n",
    "            else:\n",
    "                # 事後分布から潜在確率を定義\n",
    "                prior = psi2[i][z2[pt_list20[j]], ]\n",
    "                Posterior2 = prior * phi_long[index]\n",
    "                Prob2 = Posterior2 / np.dot(Posterior2, syntax_vec2[i])[:, np.newaxis]\n",
    "\n",
    "                # 多項分布からsyntaxを生成\n",
    "                res = rmnom(Prob2, pt_n2[j], syntax2[i], 1)\n",
    "                z2[index] = res[0]\n",
    "                Zi2[index, :syntax2[i]] = res[1]\n",
    "\n",
    "                # 上位階層の尤度を定義\n",
    "                Lho[index, i] = np.dot(res[1] * Posterior2, syntax_vec2[i])\n",
    "\n",
    "        # 潜在変数を格納\n",
    "        Syntax[:, :, i] = Zi2\n",
    "\n",
    "\n",
    "    # 事後分布から上位階層のsyntaxを生成\n",
    "    # 推移確率の事前分布を定義\n",
    "    pi_dt1 = np.full((M, syntax1), 1/syntax1); pi_dt2 = pi_dt1.copy()\n",
    "    pi_dt1[index_p11, ] = np.full((L, syntax1), pi1)   # フレーズの先頭の混合率\n",
    "    pi_dt1[index_p22, ] = pi2[z1[index_p21], :, function_word[index_p21]]   # 1フレーズ前の混合率\n",
    "    pi_dt2[index_p21, ] = (pi2.T)[function_word[index_p22], z1[index_p22], ]   # 1フレーズ後の混合率\n",
    "\n",
    "    # syntaxごとの事後分布を定義\n",
    "    LL = np.dot(phrase_matrix, scipy.sparse.csr_matrix(np.log(Lho))).toarray()\n",
    "    Posterior1 = pi_dt1 * pi_dt2 * np.exp(LL - np.max(LL, axis=1)[:, np.newaxis])\n",
    "\n",
    "    # 多項分布からsyntaxを生成\n",
    "    Prob1 = Posterior1 / np.dot(Posterior1, syntax_vec1)[:, np.newaxis]\n",
    "    res = rmnom(Prob1, M, syntax1, 1)\n",
    "    Zi1 = res[1]\n",
    "    z1 = res[0]\n",
    "\n",
    "    # 上位階層のsyntaxに対応する下位階層のsyntaxを取得\n",
    "    syntax_long1 = Zi1[phrase_id2, ]\n",
    "    Zi2 = Syntax[serial_no, :, z1[phrase_id2]]\n",
    "    z2 = np.dot(Zi2, np.arange(np.max(syntax2)))\n",
    "\n",
    "\n",
    "    ## 事前分布のパラメータを更新\n",
    "    # 推移確率の初期パラメータを更新\n",
    "    rf1 = np.sum(Zi1[index_p11, ], axis=0) + alpha1\n",
    "    rf2 = np.dot(syntax_long1[index_q11, ].T, Zi2[index_q11, ]) + beta1\n",
    "    pi1 = np.random.dirichlet(rf1, 1).reshape(-1)\n",
    "    for j in range(syntax1):\n",
    "        psi1[j] = np.random.dirichlet(rf2[j, ], 1).reshape(-1)\n",
    "\n",
    "    # 上位階層の推移確率のパラメータを更新\n",
    "    # グローバルパラメータの格納用配列\n",
    "    r1 = np.zeros((syntax1, syntax1))\n",
    "    s1 = np.zeros((syntax1, syntax1))\n",
    "\n",
    "    # 機能語ごとにパラメータを更新\n",
    "    for i in range(v2):\n",
    "\n",
    "        # データを定義\n",
    "        index1 = function_list1[i]\n",
    "        index2 = function_list2[i]\n",
    "        y = np.dot(Zi1[index1, ].T, Zi1[index2, ])\n",
    "        y_row = np.sum(y, axis=1)[:, np.newaxis]\n",
    "\n",
    "        # ローカルパラメータを更新\n",
    "        r2  = np.sum(y, axis=0) + beta2\n",
    "        s2 = np.sum(y_row * theta1, axis=0) + beta2\n",
    "        theta2[i, ] = np.random.gamma(r2, 1/s2, syntax1)\n",
    "\n",
    "        # ローカル単位の頻度の和を更新\n",
    "        r1 += y\n",
    "        s1 += y_row * theta2[i, ]\n",
    "\n",
    "    # グローバルパラメータを更新\n",
    "    r1 = r1 + beta2\n",
    "    s1 = s1 + beta2\n",
    "    theta1 = np.random.gamma(r1, 1/s1)\n",
    "\n",
    "    # パラメータを推移確率に変換\n",
    "    pi2 = np.zeros((syntax1, syntax1, v2))\n",
    "    for j in range(v2):\n",
    "        logit = theta1 * theta2[j, ]\n",
    "        pi2[:, :, j] = logit / np.sum(logit, axis=1)[:, np.newaxis]\n",
    "\n",
    "    # 下位階層の推移確率のパラメータを更新\n",
    "    # データの定義\n",
    "    target_z1 = Zi2[index_q21, ]\n",
    "    target_z2 = Zi2[index_q22, ]\n",
    "    target_syntax = syntax_long1[index_q22, ]\n",
    "\n",
    "    # 上位階層に応じて下位階層の推移確率を更新\n",
    "    for j in range(syntax1):\n",
    "        rf = np.dot((target_syntax[:, j][:, np.newaxis] * target_z1).T, target_syntax[:, j][:, np.newaxis] * target_z2) + beta2\n",
    "        psi2[j] = np.array([np.random.dirichlet(rf[g, ], 1).reshape(-1) for g in range(syntax2[j])])\n",
    "\n",
    "\n",
    "    # 単語分布のパラメータを更新\n",
    "    # ディリクリ分布のパラメータの格納用配列\n",
    "    wsum1 = [np.zeros((syntax2[j], v1)) for j in range(syntax1)]\n",
    "    wsum2 = [np.zeros((syntax2[j], v2)) for j in range(syntax1)]\n",
    "\n",
    "    # 一般語の単語分布を更新\n",
    "    for i in range(v1):\n",
    "        # データを定義\n",
    "        index = word_list1[i]\n",
    "        target_z = Zi2[index, ].T\n",
    "        target_syntax = syntax_long1[index, ]\n",
    "\n",
    "        # ディリクレ分布のパラメータを定義\n",
    "        for j in range(syntax1):\n",
    "            wsum1[j][:, i] = np.dot(target_syntax[:, j] * target_z, word_vec1[i]) + gamma1\n",
    "\n",
    "    # 機能語の単語分布を更新\n",
    "    for i in range(v2):\n",
    "        # データを定義\n",
    "        index = word_list2[i]\n",
    "        target_z = Zi2[index, ].T\n",
    "        target_syntax = syntax_long1[index, ]\n",
    "\n",
    "        # ディリクレ分布から新しいパラメータを更新\n",
    "        for j in range(syntax1):\n",
    "            wsum2[j][:, i] = np.dot(target_syntax[:, j] * target_z, word_vec2[i]) + gamma2\n",
    "\n",
    "    # ディリクリ分布から新しいパラメータを更新\n",
    "    for i in range(syntax1):\n",
    "        phi1[i] = np.array([np.random.dirichlet(wsum1[i][j, ], 1).reshape(-1) for j in range(syntax2[i])])\n",
    "        phi2[i] = np.array([np.random.dirichlet(wsum2[i][j, ], 1).reshape(-1) for j in range(syntax2[i])])\n",
    "        phi[i] = np.hstack((phi1[i], phi2[i]))\n",
    "\n",
    "\n",
    "    # サンプリング結果の保存と表示\n",
    "    # パラメータの格納\n",
    "    if (rp%keep==0) & (rp >= burnin):\n",
    "        mkeep = int(rp/keep) - skeep\n",
    "\n",
    "        # モデルパラメータの格納\n",
    "        THETA1[mkeep, ] = theta1\n",
    "        THETA2[:, :, mkeep] = theta2\n",
    "        PSI1.append(psi1)\n",
    "        PSI2.append(psi2)\n",
    "        PHI1.append(phi1)\n",
    "        PHI2.append(phi2)\n",
    "        PHI.append(phi)\n",
    "\n",
    "        # 潜在変数の格納\n",
    "        SEG1[mkeep, ] = z1\n",
    "        SEG2[mkeep, ] = z2 \n",
    "\n",
    "    # 対数尤度の更新と結果の表示\n",
    "    if rp%disp==0:\n",
    "        # 経過時間を取得\n",
    "        intermediate_time = time.time()\n",
    "        elapsed_time = (intermediate_time - start_time) / 60\n",
    "\n",
    "        # 対数尤度の更新\n",
    "        LL = 0.0; LL1 = 0.0; LL2 = 0.0\n",
    "        syntax_long = Zi1[phrase_id2, ]\n",
    "        for j in range(syntax1):\n",
    "            index = np.where(syntax_long[:, j])[0].astype(\"int\")\n",
    "            LLho = np.log(np.dot(Zi2[index, ] * (phi[j].T)[word_id[index], ], syntax_vec2[j]))\n",
    "            LL1 += np.sum(LLho[word_id[index] < v1])\n",
    "            LL2 += np.sum(LLho[word_id[index] >= v1])\n",
    "            LL += np.sum(LLho)\n",
    "\n",
    "        #サンプリング結果を確認\n",
    "        print(rp)\n",
    "        print(\"経過時間: {}\".format(elapsed_time))\n",
    "        print(np.round([LL, LLst, LLbest], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
