{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Joint_hierarchical_structured_topic_model#####\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot  as plt\n",
    "import numpy.matlib\n",
    "import scipy.linalg\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from scipy import sparse\n",
    "from scipy.stats import norm\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from numpy.random import *\n",
    "from scipy import optimize\n",
    "from scipy.special import psi as psi\n",
    "\n",
    "#np.random.seed(98537)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##多項分布の乱数を生成する関数\n",
    "def rmnom(pr, n, k, no, pattern):\n",
    "    z_id = np.argmax((np.cumsum(pr, axis=1) >= np.random.uniform(0, 1, n)[:, np.newaxis]), axis=1)\n",
    "    if pattern==1:\n",
    "        Z = sparse.coo_matrix((np.repeat(1, n), (no, np.array(z_id))), shape=(n, k))   #スパース行列の設定\n",
    "        return z_id, Z\n",
    "    return z_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####データの生成####\n",
    "##データの設定\n",
    "#データのパラメータ\n",
    "types = 2\n",
    "k = 20\n",
    "d = 10000 \n",
    "s = np.random.poisson(5.0, d); s[s < 2] = 2\n",
    "n = np.sum(s)\n",
    "v1 = 1000\n",
    "v2 = 500\n",
    "a = 500\n",
    "k_vec = np.repeat(1, k)\n",
    "\n",
    "#文書idと単語頻度を生成\n",
    "s_id = np.repeat(np.arange(d), s)\n",
    "s_list = [i for i in range(d)]\n",
    "for i in range(d):\n",
    "    s_list[i] = np.array(np.where(s_id==i)[0], dtype=\"int\")\n",
    "w21 = np.random.poisson(np.random.gamma(15.0, 1/0.5, n)); w21[w21 < 5] = 5\n",
    "w22 = np.random.poisson(np.random.gamma(7.5, 1/0.5, n)); w22[w22 < 5] = 5\n",
    "w11 = np.array([np.sum(w21[s_list[i]]) for i in range(d)])\n",
    "w12 = np.array([np.sum(w22[s_list[i]]) for i in range(d)])\n",
    "f1 = np.sum(w11)\n",
    "f2 = np.sum(w12)\n",
    "\n",
    "#補助文書idを生成\n",
    "x = np.random.poisson(15.0, d); x[x < 2] = 2\n",
    "x_id = np.repeat(np.arange(d), x)\n",
    "g = np.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##単語idとインデックスの設定\n",
    "#単語idを設定\n",
    "d_id11 = np.repeat(np.arange(d), w11)\n",
    "d_id12 = np.repeat(np.arange(d), w12)\n",
    "d_id21 = np.repeat(np.arange(n), w21)\n",
    "d_id22 = np.repeat(np.arange(n), w22)\n",
    "\n",
    "#インデックスを作成\n",
    "d_list11 = [i for i in range(d)]; d_dt11 = [i for i in range(d)]\n",
    "d_list12 = [i for i in range(d)]; d_dt12 = [i for i in range(d)]\n",
    "d_list21 = [i for i in range(n)]; d_dt21 = [i for i in range(n)]\n",
    "d_list22 = [i for i in range(n)]; d_dt22 = [i for i in range(n)]\n",
    "for i in range(d):\n",
    "    d_list11[i] = np.array(np.where(d_id11==i)[0], dtype=\"int\")\n",
    "    d_list12[i] = np.array(np.where(d_id12==i)[0], dtype=\"int\")\n",
    "    d_dt11[i] = np.repeat(1, w11[i])\n",
    "    d_dt12[i] = np.repeat(1, w12[i])\n",
    "for i in range(n):\n",
    "    d_list21[i] = np.array(np.where(d_id21==i)[0], dtype=\"int\")\n",
    "    d_list22[i] = np.array(np.where(d_id22==i)[0], dtype=\"int\")\n",
    "    d_dt21[i] = np.repeat(1, w21[i])\n",
    "    d_dt22[i] = np.repeat(1, w22[i])\n",
    "    \n",
    "#タグidを設定\n",
    "a_id = np.repeat(np.arange(d), x)\n",
    "a_list = [i for i in range(d)]\n",
    "a_dt = [i for i in range(d)]\n",
    "for i in range(d):\n",
    "    a_list[i] = np.array(np.where(a_id==i), dtype=\"int\")\n",
    "    a_dt[i] = np.repeat(1, x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####応答変数を生成####\n",
    "rp = 0\n",
    "while True:\n",
    "    rp = rp + 1\n",
    "    print(rp)\n",
    "    \n",
    "    ##パラメータを生成\n",
    "    #トピック分布のパラメータを生成\n",
    "    weights = 3.0\n",
    "    theta = np.random.dirichlet(np.repeat(0.2, k), d)\n",
    "    theta1 = np.array([np.random.dirichlet(weights*theta[s_id[i], ], 1).reshape(-1) for i in range(n)])\n",
    "    theta2 = np.array([np.random.dirichlet(weights*theta[s_id[i], ], 1).reshape(-1) for i in range(n)])\n",
    "    thetat = theta.copy(); thetat1 = theta1.copy(); thetat2 = theta2.copy()\n",
    "    \n",
    "    #単語分布のパラメータを生成\n",
    "    phi1 = np.random.dirichlet(np.repeat(0.05, v1), k)\n",
    "    phi2 = np.random.dirichlet(np.repeat(0.05, v2), k)\n",
    "    omega = np.random.dirichlet(np.repeat(0.05, a), k)\n",
    "\n",
    "    #出現確率が低い単語を入れ替える\n",
    "    index = np.where(np.max(phi1, axis=0) <= (k*k)/f1)[0]\n",
    "    for j in range(index.shape[0]):\n",
    "        phi1[np.argmax(np.random.multinomial(1, np.repeat(1/k, k), 1)), index[j]] = (k*k)/f1\n",
    "    index = np.where(np.max(phi2, axis=0) <= (k*k)/f2)[0]\n",
    "    for j in range(index.shape[0]):\n",
    "        phi2[np.argmax(np.random.multinomial(1, np.repeat(1/k, k), 1)), index[j]] = (k*k)/f2\n",
    "    phit1 = phi1.copy(); phit2 = phi2.copy(); omegat = omega.copy()\n",
    "\n",
    "    ##トピックから単語を生成\n",
    "    #多項分布からトピックを生成\n",
    "    Z1 = np.array(rmnom(theta1[d_id21, ], f1, k, np.arange(f1), 1)[1].todense(), dtype=\"int8\")\n",
    "    Z2 = np.array(rmnom(theta2[d_id22, ], f2, k, np.arange(f2), 1)[1].todense(), dtype=\"int8\")\n",
    "    z_vec1 = np.dot(Z1, np.arange(k))\n",
    "    z_vec2 = np.dot(Z2, np.arange(k))\n",
    "\n",
    "    #トピックから単語を生成\n",
    "    word_data1 = np.zeros((f1, v1), dtype=\"int8\")\n",
    "    word_data2 = np.zeros((f2, v2), dtype=\"int8\")\n",
    "    word1 = np.repeat(0, f1)\n",
    "    word2 = np.repeat(0, f2)\n",
    "    for i in range(n):\n",
    "        out1 = rmnom(phi1[z_vec1[d_list21[i]], ], w21[i], v1, np.arange(w21[i]), 1)\n",
    "        out2 = rmnom(phi2[z_vec2[d_list22[i]], ], w22[i], v2, np.arange(w22[i]), 1)\n",
    "        word_data1[d_list21[i], ] = np.array(out1[1].todense(), dtype=\"int8\")\n",
    "        word_data2[d_list22[i], ] = np.array(out2[1].todense(), dtype=\"int8\")\n",
    "        word1[d_list21[i]] = np.array(out1[0], dtype=\"int\")\n",
    "        word2[d_list22[i]] = np.array(out2[0], dtype=\"int\")\n",
    "\n",
    "    ##トピックからタグを生成\n",
    "    #多項分布からトピックを生成\n",
    "    gamma = np.array([np.sum(Z1[d_list11[i], ], axis=0) / w11[i] for i in range(d)])\n",
    "    S = np.array(rmnom(gamma[a_id, ], g, k, np.arange(g), 1)[1].todense(), dtype=\"int8\")\n",
    "    s_vec = np.dot(S, np.arange(k))\n",
    "\n",
    "    #トピックからタグを生成\n",
    "    out = rmnom(omega[s_vec, ], g, a, np.arange(g), 1)\n",
    "    tag_data = np.array(out[1].todense(), dtype=\"int8\")\n",
    "    tag = np.array(out[0], dtype=\"int\")\n",
    "\n",
    "    #break条件\n",
    "    freq1 = np.min(np.sum(word_data1, axis=0)) \n",
    "    freq2 = np.min(np.sum(word_data2, axis=0)) \n",
    "    freq3 = np.min(np.sum(tag_data, axis=0)) \n",
    "    if (freq1 > 0) & (freq2 > 0) & (freq3 > 0):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##トピック分布間の関連性と単語分布の可視化\n",
    "#トピック分布間のtf-idfを計算\n",
    "normalize1 = np.sqrt(np.sum(np.power(theta[s_id, ], 2), axis=1)) * np.sqrt(np.sum(np.power(theta1, 2), axis=1))\n",
    "inner_prod1 = np.sum(theta[s_id, ] * theta1, axis=1)\n",
    "tf_idf1 = inner_prod1 / normalize1\n",
    "normalize2 = np.sqrt(np.sum(np.power(theta[s_id, ], 2), axis=1)) * np.sqrt(np.sum(np.power(theta2, 2), axis=1))\n",
    "inner_prod2 = np.sum(theta[s_id, ] * theta2, axis=1)\n",
    "tf_idf2 = inner_prod2 / normalize2\n",
    "normalize3 = np.sqrt(np.sum(np.power(theta1, 2), axis=1)) * np.sqrt(np.sum(np.power(theta2, 2), axis=1))\n",
    "inner_prod3 = np.sum(theta1 * theta2, axis=1)\n",
    "tf_idf3 = inner_prod3 / normalize3\n",
    "del normalize1; normalize2; normalize3, inner_prod1, inner_prod2, inner_prod3\n",
    "\n",
    "#tf-idfと単語分布を可視化\n",
    "dt = [tf_idf1, tf_idf2, tf_idf3, np.max(phi1, axis=0), np.max(phi2, axis=0), np.max(omega, axis=0)]\n",
    "fig_range = np.array([[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, np.max(phi1), np.max(phi2), np.max(omega)]])\n",
    "colorlist = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]\n",
    "legend = [\"グローバル分布と名詞分布のtf-idf分布\", \"グローバル分布と動詞分布のtf-idf分布\", \n",
    "          \"ローカル分布同士のtf-idf分布\", \"名詞分布のパラメータ\", \"動詞分布のパラメータ\", \"タグ分布のパラメータ\"]\n",
    "fig = plt.figure(figsize=(12.5, 6.5))\n",
    "for j in range(len(dt)):\n",
    "    ax = fig.add_subplot(2, 3, j+1)\n",
    "    ax.hist(dt[j],  bins=25, range=(fig_range[0, j], fig_range[1, j]), color=colorlist[j])\n",
    "    plt.title(legend[j], fontsize=12.5)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####マルコフ連鎖モンテカルロ法でパラメータをサンプリング#####\n",
    "#トピック尤度と負担率を計算する関数\n",
    "def LLho(theta, phi, d_id, wd, f, k):\n",
    "    Lho = theta[d_id, ] * (phi.T)[wd, ]\n",
    "    topic_rate = Lho / np.sum(Lho, axis=1)[:, np.newaxis]\n",
    "    return Lho, topic_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##アルゴリズムの設定\n",
    "R = 2000   #サンプリング回数\n",
    "keep = 2   #2回に1回の割合でサンプリング結果を格納\n",
    "disp = 10\n",
    "iter = 0\n",
    "burnin = int(500/keep)\n",
    "no1 = np.arange(f1)\n",
    "no2 = np.arange(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##単語とタグのインデックスを作成\n",
    "#単語インデックスを作成\n",
    "word_list1 = [i for i in range(v1)]; word_dt1 = [i for i in range(v1)]\n",
    "word_list2 = [i for i in range(v2)]; word_dt2 = [i for i in range(v2)]\n",
    "for i in range(v1):\n",
    "    word_list1[i] = np.array(np.where(word1==i)[0], dtype=\"int\")\n",
    "    word_dt1[i] = np.repeat(1, word_list1[i].shape[0])\n",
    "for i in range(v2):\n",
    "    word_list2[i] = np.array(np.where(word2==i)[0], dtype=\"int\")\n",
    "    word_dt2[i] = np.repeat(1, word_list2[i].shape[0])\n",
    "    \n",
    "#タグインデックスを作成\n",
    "tag_list = [i for i in range(a)]\n",
    "tag_dt = [i for i in range(a)]\n",
    "for i in range(a):\n",
    "    tag_list[i] = np.array(np.where(tag==i)[0], dtype=\"int\")\n",
    "    tag_dt[i] = np.repeat(1, tag_list[i].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##事前分布の設定\n",
    "alpha01 = 0.1\n",
    "beta01 = 0.1\n",
    "beta02 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##パラメータの真値\n",
    "#ハイパーパラメータの初期値\n",
    "Delta1 = np.array(np.full((n, k), 0.25), dtype=\"float32\")\n",
    "Delta2 = np.array(np.full((n, k), 0.25), dtype=\"float32\")\n",
    "delta_n1 = w21.copy(); delta_n1[delta_n1 < 5] = 5\n",
    "delta_n2 = w22.copy(); delta_n2[delta_n2 < 5] = 5\n",
    "er = 0.0001\n",
    "\n",
    "#トピック分布の真値\n",
    "theta = thetat.copy()\n",
    "theta1 = thetat1.copy()\n",
    "theta2 = thetat2.copy()\n",
    "\n",
    "#単語分布のパラメータを生成\n",
    "phi1 = phit1.copy()\n",
    "phi2 = phit2.copy()\n",
    "omega = omegat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##初期値の設定\n",
    "#ハイパーパラメータの初期値\n",
    "Delta1 = np.array(np.full((n, k), 0.25), dtype=\"float32\")\n",
    "Delta2 = np.array(np.full((n, k), 0.25), dtype=\"float32\")\n",
    "delta_n1 = w21.copy(); delta_n1[delta_n1 < 5] = 5\n",
    "delta_n2 = w22.copy(); delta_n2[delta_n2 < 5] = 5\n",
    "er = 0.0001\n",
    "\n",
    "#トピック分布の初期値\n",
    "theta = np.random.dirichlet(np.repeat(2.5, k), d)\n",
    "theta1 = np.random.dirichlet(np.repeat(2.5, k), n)\n",
    "theta2 = np.random.dirichlet(np.repeat(2.5, k), n)\n",
    "\n",
    "#単語分布の初期値\n",
    "phi1 = np.random.dirichlet(np.repeat(2.5, v1), k)\n",
    "phi2 = np.random.dirichlet(np.repeat(2.5, v2), k)\n",
    "omega = np.random.dirichlet(np.repeat(2.5, a), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##パラメータの格納用配列\n",
    "#モデルパラメータの格納用配列\n",
    "THETA = np.zeros((d, k, int(R/keep)))\n",
    "THETA1 = np.zeros((n, k, int(R/keep)))\n",
    "THETA2 = np.zeros((n, k, int(R/keep)))\n",
    "PHI1 = np.zeros((k, v1, int(R/keep)))\n",
    "PHI2 = np.zeros((k, v2, int(R/keep)))\n",
    "OMEGA = np.zeros((k, a, int(R/keep)))\n",
    "\n",
    "#トピックの格納用配列\n",
    "SEG11 = np.zeros((f1, k))\n",
    "SEG12 = np.zeros((f2, k))\n",
    "SEG2 = np.zeros((g, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##対数尤度の基準値\n",
    "#ユニグラムモデルの対数尤度\n",
    "LLst11 = np.sum(np.dot(word_data1, np.log(np.mean(word_data1, axis=0))))\n",
    "LLst12 = np.sum(np.dot(word_data2, np.log(np.mean(word_data2, axis=0))))\n",
    "LLst2 = np.sum(np.dot(tag_data, np.log(np.mean(tag_data, axis=0))))\n",
    "LLst1 = LLst11 + LLst12\n",
    "LLst = LLst1 + LLst2\n",
    "print(np.round(np.array([LLst11, LLst12, LLst1, LLst2, LLst]), 1))\n",
    "\n",
    "#真値での対数尤度\n",
    "LLbest11 = np.sum(np.log(np.sum(thetat1[d_id21, ] * phit1.T[word1, ], axis=1)))\n",
    "LLbest12 = np.sum(np.log(np.sum(thetat2[d_id22, ] * phit2.T[word2, ], axis=1)))\n",
    "LLbest2 = np.sum(np.log(np.sum(gamma[x_id, ] * omegat.T[tag, ], axis=1)))\n",
    "LLbest1 = LLbest11 + LLbest12\n",
    "LLbest = LLbest1 + LLbest2\n",
    "print(np.round(np.array([LLbest11, LLbest12, LLbest1, LLbest2, LLbest]), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####ギブスサンプリングでパラメータをサンプリング####\n",
    "for rp in range(R):\n",
    "    \n",
    "    ##単語トピックを生成\n",
    "    #トピック選択確率を定義 \n",
    "    Lho11 = theta1[d_id21, ] * phi1.T[word1, ]\n",
    "    Lho12 = theta2[d_id22, ] * phi2.T[word2, ]\n",
    "    topic_prob1 = Lho11 / np.dot(Lho11, k_vec)[:, np.newaxis]\n",
    "    topic_prob2 = Lho12 / np.dot(Lho12, k_vec)[:, np.newaxis]\n",
    "\n",
    "    #多項分布からトピックを生成\n",
    "    Zi1 = np.array(rmnom(topic_prob1, f1, k, no1, 1)[1].todense(), dtype=\"int8\")\n",
    "    Zi2 = np.array(rmnom(topic_prob2, f2, k, no2, 1)[1].todense(), dtype=\"int8\")\n",
    "\n",
    "\n",
    "    ##ディリクレ分布からパラメータをサンプリング\n",
    "    #グローバルトピック分布をサンプリング\n",
    "    y1 = np.zeros((d, k), dtype=\"int\")\n",
    "    y2 = np.zeros((d, k), dtype=\"int\")\n",
    "    for i in range(d):\n",
    "        z1 = Zi1[d_list11[i], ]; z2 = Zi2[d_list12[i], ]\n",
    "        alpha1 = np.dot(d_dt11[i], z1); y1[i, ] = alpha1.copy()\n",
    "        alpha2 = np.dot(d_dt12[i], z2); y2[i, ] = alpha2.copy()\n",
    "        alpha = alpha1 + alpha2 + alpha01\n",
    "        theta[i, ] = np.random.dirichlet(alpha, 1).reshape(-1)\n",
    "\n",
    "    #ハイパーパラメータを更新\n",
    "    delta_vec = np.dot(Delta1, k_vec)\n",
    "    delta1 = psi(theta[s_id, ] + Delta1) - psi(Delta1)\n",
    "    delta2 = (psi(delta_n1 + delta_vec) - psi(delta_vec))[:, np.newaxis]\n",
    "    new_Delta1 = Delta1 * (delta1 / delta2) + er\n",
    "    Delta1 = new_Delta1.copy()\n",
    "    \n",
    "    delta_vec = np.dot(Delta2, k_vec)\n",
    "    delta1 = psi(theta[s_id, ] + Delta2) - psi(Delta2)\n",
    "    delta2 = (psi(delta_n2 + delta_vec) - psi(delta_vec))[:, np.newaxis]\n",
    "    new_Delta2 = Delta2 * (delta1 / delta2) + er\n",
    "    Delta2 = new_Delta2.copy()\n",
    "        \n",
    "    #ローカルトピック分布をサンプリング\n",
    "    for i in range(n):\n",
    "        alpha1 = np.dot(d_dt21[i], Zi1[d_list21[i], ]) + new_Delta1[i, ]\n",
    "        alpha2 = np.dot(d_dt22[i], Zi2[d_list22[i], ]) + new_Delta2[i, ]\n",
    "        theta1[i, ] = np.random.dirichlet(alpha1, 1).reshape(-1)\n",
    "        theta2[i, ] = np.random.dirichlet(alpha2, 1).reshape(-1)\n",
    "    \n",
    "        \n",
    "    #単語分布をサンプリング\n",
    "    x_freq1 = np.zeros((k, v1)); x_freq2 = np.zeros((k, v2))\n",
    "    for i in range(v1):\n",
    "        x_freq1[:, i] = np.dot(word_dt1[i], Zi1[word_list1[i], ]) \n",
    "        if i < v2:\n",
    "            x_freq2[:, i] = np.dot(word_dt2[i], Zi2[word_list2[i], ]) \n",
    "    for j in range(k):\n",
    "        phi1[j, ] = np.random.dirichlet(x_freq1[j, ] + beta01, 1).reshape(-1)\n",
    "        phi2[j, ] = np.random.dirichlet(x_freq2[j, ] + beta01, 1).reshape(-1)\n",
    "\n",
    "\n",
    "    ##タグトピックを生成\n",
    "    #トピック選択確率を定義 \n",
    "    theta_mu = y1 / w11[:, np.newaxis]\n",
    "    Lho2 = theta_mu[x_id, ] * (omega.T)[tag, ]\n",
    "    topic_prob = Lho2 / np.dot(Lho2, k_vec)[:, np.newaxis]\n",
    "\n",
    "    #多項分布からトピックを生成\n",
    "    Si = np.array(rmnom(topic_prob, g, k, np.arange(g), 1)[1].todense(), dtype=\"int8\")\n",
    "\n",
    "    ##ディリクレ分布からパラメータをサンプリング\n",
    "    #タグ分布をサンプリング\n",
    "    x_freq = np.zeros((k, a))\n",
    "    for i in range(a):\n",
    "        x_freq[:, i] = np.dot(tag_dt[i], Si[tag_list[i], ]) \n",
    "    for j in range(k):\n",
    "        omega[j, ] = np.random.dirichlet(x_freq[j, ] + beta02, 1).reshape(-1)\n",
    "\n",
    "\n",
    "    ##サンプリング結果の格納用と表示\n",
    "    if rp%keep==0:\n",
    "        #サンプリング結果を格納\n",
    "        mkeep = int(rp/keep)\n",
    "        THETA[:, :, mkeep] = theta\n",
    "        THETA1[:, :, mkeep] = theta1\n",
    "        THETA2[:, :, mkeep] = theta2\n",
    "        PHI1[:, :, mkeep] = phi1\n",
    "        PHI2[:, :, mkeep] =phi2\n",
    "        OMEGA[:, :, mkeep] = omega\n",
    "        \n",
    "        #トピック割当はバーンイン期間を超えたら格納\n",
    "        if (rp%keep==0) & (rp >= burnin):\n",
    "            SEG11 = SEG11 + Zi1\n",
    "            SEG12 = SEG12 + Zi2\n",
    "            SEG2 = SEG2 + Si\n",
    "\n",
    "    if rp%disp==0: \n",
    "        #対数尤度を更新\n",
    "        LLho11 = np.sum(np.log(np.sum(Lho11, axis=1)))\n",
    "        LLho12 = np.sum(np.log(np.sum(Lho12, axis=1)))\n",
    "        LLho2 = np.sum(np.log(np.sum(Lho2, axis=1)))\n",
    "        LLho1 = LLho11 + LLho12\n",
    "        LLho = LLho1 + LLho2\n",
    "\n",
    "        #サンプリング結果を表示\n",
    "        print(rp)\n",
    "        print(np.round([LLho11, LLho12, LLho1, LLho2, LLho], 1))\n",
    "        print(np.round([LLst11, LLst12, LLst1, LLst2, LLst], 1))\n",
    "        print(np.round([LLbest11, LLbest12, LLbest1, LLbest2, LLbest], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
